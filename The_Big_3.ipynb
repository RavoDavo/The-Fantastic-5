{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f201a1dc",
   "metadata": {},
   "source": [
    "\n",
    "Created on Tue May 10 16:37:41 2022\n",
    "\n",
    "@author: David Da Costa & Theodore Psillos\n",
    "\n",
    "EEE4120F Machine Learning Project\n",
    "Image Classification \n",
    "\n",
    "**Classifying Lion, Leopard or Elephant**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "85e7efb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Packages\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "#import math\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import random\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import keras\n",
    "from tensorflow.keras import models , layers\n",
    "from keras.regularizers import l2\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3d8a6675",
   "metadata": {},
   "outputs": [],
   "source": [
    "#animals = [\"Lion\", \"Rhinos\",\"Elephant\",\"Buffelo\", \"Leopard\"] #Categories to classify\n",
    "animals = [\"Lion\",\"Elephant\", \"Leopard\"]\n",
    "DIR = (\"Data/\") #Datapath Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1c393a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_size =60 #Setting the image shape\n",
    "training_data = []\n",
    "for animal in animals:\n",
    "    path = os.path.join(DIR,animal)\n",
    "    animal_num = animals.index(animal)\n",
    "    for image in os.listdir(path):\n",
    "        try: \n",
    "            img_arr = cv2.imread(os.path.join(path,image),cv2.IMREAD_GRAYSCALE)\n",
    "            new_array = cv2.resize(img_arr, (new_size,new_size))#Make images new size\n",
    "            training_data.append([new_array,animal_num])\n",
    "        except Exception as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0d23b9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[134, 136, 137, ...,  62,  86, 101],\n",
       "        [129, 130, 131, ...,  56,  79,  92],\n",
       "        [116, 117, 117, ...,  54,  70,  74],\n",
       "        ...,\n",
       "        [ 28,  46,  11, ...,  51,  50,  41],\n",
       "        [ 17,  21,  32, ...,  52,  44,  42],\n",
       "        [ 22,  34,  40, ...,  46,  46,  51]], dtype=uint8),\n",
       " 0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data:  (2434, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1970: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = asarray(a).shape\n"
     ]
    }
   ],
   "source": [
    "display(training_data[0])\n",
    "print(\"Shape of training data: \",np.shape(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "57be1319",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(training_data) #shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "25dec699",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "34cac991",
   "metadata": {},
   "outputs": [],
   "source": [
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "X = np.array(X).reshape(-1, new_size, new_size, 1)\n",
    "y = np.array(y).reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "878c663f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[0], cmap = \"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "75a58fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function BufferedWriter.close>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_out = open(\"X.pickle\", \"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close\n",
    "\n",
    "pickle_out = open(\"y.pickle\", \"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "003efb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle_in = open(\"X.pickle\", \"rb\")\n",
    "#X = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dd74d863",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lion=0\n",
    "num_rhino=0\n",
    "num_elephant=0\n",
    "num_buffelo=0\n",
    "num_leopard=0\n",
    "#animals = [\"Lion\", \"Rhinos\",\"Elephant\",\"Buffelo\", \"Leopard\"] #Categories to classify\n",
    "for img,animal in training_data:\n",
    "    if animal ==0:\n",
    "        num_lion+=1\n",
    "        \n",
    "    if animal ==1:\n",
    "        num_elephant+=1\n",
    "    if animal ==2:\n",
    "        num_leopard +=1\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "399d6f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.DataFrame({'Player':[\"Salah\",\"Mane\",\"Diaz\",\"Bobby\"],'Count_pics':[num_salah, num_mane, num_diaz, num_bobby]})\n",
    "data = pd.DataFrame({'Animal':[\"Lion\",\"Elephant\",\"Leopard\"],'Count Pics':[num_lion,num_elephant , num_leopard]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e2b95012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "ax = sns.barplot(x=\"Animal\", y=\"Count Pics\", data=data)\n",
    "fig = ax.get_figure()\n",
    " \n",
    "fig.savefig('num_images.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed098a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count Pics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>811.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>35.118846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>778.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>793.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>808.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>828.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>848.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Count Pics\n",
       "count    3.000000\n",
       "mean   811.333333\n",
       "std     35.118846\n",
       "min    778.000000\n",
       "25%    793.000000\n",
       "50%    808.000000\n",
       "75%    828.000000\n",
       "max    848.000000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe259a16",
   "metadata": {},
   "source": [
    "Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "296fb44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_train,y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c63207d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test/255 #normalizing pixel value\n",
    "X_train = X_train/255 #normalizing pixel value\n",
    "X_test = np.array(X_test).reshape(-1, new_size, new_size, 1)\n",
    "y_test = np.array(y_test).reshape(-1,1)\n",
    "X_train = np.array(X_train).reshape(-1, new_size, new_size, 1)\n",
    "y_train = np.array(y_train).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2038b12b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244, 60, 60, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32ba81d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sie = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e5a823b6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 17s 421ms/step - loss: 1.0827 - accuracy: 0.4238 - val_loss: 0.9239 - val_accuracy: 0.5909\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 16s 431ms/step - loss: 0.8606 - accuracy: 0.6274 - val_loss: 0.8559 - val_accuracy: 0.5909\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 13s 351ms/step - loss: 0.7565 - accuracy: 0.6801 - val_loss: 0.7298 - val_accuracy: 0.7727\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 18s 498ms/step - loss: 0.7288 - accuracy: 0.7000 - val_loss: 0.8283 - val_accuracy: 0.6818\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 19s 541ms/step - loss: 0.7161 - accuracy: 0.7062 - val_loss: 0.7573 - val_accuracy: 0.7273\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 16s 436ms/step - loss: 0.6292 - accuracy: 0.7461 - val_loss: 0.7714 - val_accuracy: 0.7273\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 12s 327ms/step - loss: 0.5956 - accuracy: 0.7660 - val_loss: 0.9108 - val_accuracy: 0.6364\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 12s 338ms/step - loss: 0.5509 - accuracy: 0.7864 - val_loss: 0.8446 - val_accuracy: 0.6818\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 13s 363ms/step - loss: 0.5384 - accuracy: 0.7860 - val_loss: 0.6391 - val_accuracy: 0.8636\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 13s 350ms/step - loss: 0.4952 - accuracy: 0.8016 - val_loss: 0.8207 - val_accuracy: 0.7273\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 13s 355ms/step - loss: 0.4517 - accuracy: 0.8249 - val_loss: 0.8283 - val_accuracy: 0.6364\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 13s 350ms/step - loss: 0.4650 - accuracy: 0.8329 - val_loss: 0.8771 - val_accuracy: 0.6364\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 13s 347ms/step - loss: 0.3852 - accuracy: 0.8524 - val_loss: 1.0214 - val_accuracy: 0.6818\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 13s 375ms/step - loss: 0.3880 - accuracy: 0.8500 - val_loss: 0.9015 - val_accuracy: 0.5909\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 13s 351ms/step - loss: 0.3535 - accuracy: 0.8595 - val_loss: 0.9590 - val_accuracy: 0.5909\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 17s 464ms/step - loss: 0.3139 - accuracy: 0.8818 - val_loss: 0.9589 - val_accuracy: 0.7273\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 13s 346ms/step - loss: 0.3082 - accuracy: 0.8899 - val_loss: 1.0410 - val_accuracy: 0.6364\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 14s 379ms/step - loss: 0.3237 - accuracy: 0.8799 - val_loss: 1.1698 - val_accuracy: 0.6364\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 13s 349ms/step - loss: 0.2356 - accuracy: 0.9174 - val_loss: 1.2764 - val_accuracy: 0.5000\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 13s 358ms/step - loss: 0.2313 - accuracy: 0.9174 - val_loss: 0.9360 - val_accuracy: 0.6818\n",
      "Score for fold 1: loss of 1.1735681295394897; accuracy of 71.80327773094177%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 14s 339ms/step - loss: 1.1611 - accuracy: 0.3237 - val_loss: 1.1022 - val_accuracy: 0.3636\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 12s 327ms/step - loss: 1.0927 - accuracy: 0.3849 - val_loss: 1.0301 - val_accuracy: 0.6364\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 13s 361ms/step - loss: 0.9903 - accuracy: 0.5131 - val_loss: 1.0230 - val_accuracy: 0.4545\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 11s 307ms/step - loss: 0.9208 - accuracy: 0.5567 - val_loss: 0.8751 - val_accuracy: 0.6818\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 13s 360ms/step - loss: 0.8664 - accuracy: 0.5876 - val_loss: 0.8326 - val_accuracy: 0.7727\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 18s 483ms/step - loss: 0.8299 - accuracy: 0.6151 - val_loss: 0.8480 - val_accuracy: 0.6364\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 12s 329ms/step - loss: 0.8031 - accuracy: 0.6350 - val_loss: 0.8633 - val_accuracy: 0.6818\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 10s 278ms/step - loss: 0.8571 - accuracy: 0.6080 - val_loss: 0.8887 - val_accuracy: 0.6818\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 10s 283ms/step - loss: 0.7957 - accuracy: 0.6383 - val_loss: 0.8812 - val_accuracy: 0.7273\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 10s 276ms/step - loss: 0.7261 - accuracy: 0.6839 - val_loss: 0.9565 - val_accuracy: 0.6364\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 10s 286ms/step - loss: 0.6971 - accuracy: 0.7005 - val_loss: 0.8984 - val_accuracy: 0.6364\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 12s 329ms/step - loss: 0.6735 - accuracy: 0.7152 - val_loss: 0.9535 - val_accuracy: 0.6364\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 12s 344ms/step - loss: 0.6206 - accuracy: 0.7527 - val_loss: 0.9447 - val_accuracy: 0.6364\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 14s 376ms/step - loss: 0.6607 - accuracy: 0.7152 - val_loss: 0.9671 - val_accuracy: 0.5909\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 12s 328ms/step - loss: 0.6089 - accuracy: 0.7352 - val_loss: 0.9905 - val_accuracy: 0.5909\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 12s 325ms/step - loss: 0.5974 - accuracy: 0.7485 - val_loss: 0.9660 - val_accuracy: 0.6818\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 12s 346ms/step - loss: 0.5535 - accuracy: 0.7812 - val_loss: 1.1070 - val_accuracy: 0.6364\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 13s 349ms/step - loss: 0.5314 - accuracy: 0.7850 - val_loss: 1.0174 - val_accuracy: 0.6818\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 13s 347ms/step - loss: 0.5398 - accuracy: 0.7788 - val_loss: 1.1136 - val_accuracy: 0.6818\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 12s 337ms/step - loss: 0.5318 - accuracy: 0.7836 - val_loss: 1.1866 - val_accuracy: 0.6364\n",
      "Score for fold 2: loss of 0.8743667602539062; accuracy of 72.13114500045776%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 12s 295ms/step - loss: 1.1154 - accuracy: 0.3643 - val_loss: 0.9732 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 12s 345ms/step - loss: 0.9502 - accuracy: 0.5508 - val_loss: 0.8976 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 12s 344ms/step - loss: 0.8221 - accuracy: 0.6404 - val_loss: 0.8096 - val_accuracy: 0.6364\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 12s 324ms/step - loss: 0.7428 - accuracy: 0.6784 - val_loss: 0.8331 - val_accuracy: 0.7273\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 11s 305ms/step - loss: 0.6612 - accuracy: 0.7258 - val_loss: 0.9741 - val_accuracy: 0.6364\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 16s 444ms/step - loss: 0.6216 - accuracy: 0.7467 - val_loss: 0.8941 - val_accuracy: 0.6364\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 12s 341ms/step - loss: 0.6168 - accuracy: 0.7438 - val_loss: 1.0192 - val_accuracy: 0.5909\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 11s 311ms/step - loss: 0.5617 - accuracy: 0.7737 - val_loss: 1.0664 - val_accuracy: 0.7273\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 10s 274ms/step - loss: 0.6411 - accuracy: 0.7462 - val_loss: 0.8155 - val_accuracy: 0.6364\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 10s 274ms/step - loss: 0.5132 - accuracy: 0.8008 - val_loss: 0.9060 - val_accuracy: 0.6364\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 10s 274ms/step - loss: 0.4838 - accuracy: 0.8164 - val_loss: 1.0580 - val_accuracy: 0.6818\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 10s 291ms/step - loss: 0.4322 - accuracy: 0.8387 - val_loss: 0.8746 - val_accuracy: 0.7727\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 12s 324ms/step - loss: 0.3822 - accuracy: 0.8662 - val_loss: 0.8596 - val_accuracy: 0.6364\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 12s 322ms/step - loss: 0.3635 - accuracy: 0.8639 - val_loss: 0.9755 - val_accuracy: 0.8182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "36/36 [==============================] - 12s 330ms/step - loss: 0.3227 - accuracy: 0.8828 - val_loss: 1.1112 - val_accuracy: 0.6364\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 12s 324ms/step - loss: 0.3401 - accuracy: 0.8691 - val_loss: 1.0649 - val_accuracy: 0.7273\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 12s 332ms/step - loss: 0.2896 - accuracy: 0.8956 - val_loss: 1.0659 - val_accuracy: 0.7727\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 12s 330ms/step - loss: 0.2501 - accuracy: 0.9189 - val_loss: 1.1483 - val_accuracy: 0.7727\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 12s 327ms/step - loss: 0.2273 - accuracy: 0.9194 - val_loss: 1.4514 - val_accuracy: 0.7273\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 10s 277ms/step - loss: 0.2406 - accuracy: 0.9156 - val_loss: 1.2175 - val_accuracy: 0.7273\n",
      "Score for fold 3: loss of 0.9371119141578674; accuracy of 75.65789222717285%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 14s 345ms/step - loss: 1.0813 - accuracy: 0.4431 - val_loss: 0.9866 - val_accuracy: 0.2727\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 12s 334ms/step - loss: 0.9065 - accuracy: 0.5640 - val_loss: 0.8318 - val_accuracy: 0.5455\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 13s 347ms/step - loss: 0.7926 - accuracy: 0.6456 - val_loss: 0.8546 - val_accuracy: 0.6364\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 11s 317ms/step - loss: 0.7133 - accuracy: 0.7116 - val_loss: 0.8656 - val_accuracy: 0.5909\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 10s 273ms/step - loss: 0.6636 - accuracy: 0.7324 - val_loss: 0.8642 - val_accuracy: 0.6364\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 10s 267ms/step - loss: 0.6653 - accuracy: 0.7263 - val_loss: 1.1577 - val_accuracy: 0.4545\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 10s 272ms/step - loss: 0.5859 - accuracy: 0.7628 - val_loss: 1.1015 - val_accuracy: 0.6364\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 10s 272ms/step - loss: 0.5316 - accuracy: 0.7941 - val_loss: 0.9030 - val_accuracy: 0.5909\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 13s 357ms/step - loss: 0.4704 - accuracy: 0.8202 - val_loss: 0.8321 - val_accuracy: 0.8182\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 11s 296ms/step - loss: 0.4454 - accuracy: 0.8245 - val_loss: 1.0390 - val_accuracy: 0.7273\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 716s 20s/step - loss: 0.4746 - accuracy: 0.8164 - val_loss: 1.0613 - val_accuracy: 0.6364\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 16s 448ms/step - loss: 0.3566 - accuracy: 0.8790 - val_loss: 0.8956 - val_accuracy: 0.8182\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 13s 362ms/step - loss: 0.2951 - accuracy: 0.8871 - val_loss: 1.0838 - val_accuracy: 0.7727\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 12s 347ms/step - loss: 0.2241 - accuracy: 0.9274 - val_loss: 1.4668 - val_accuracy: 0.7273\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 13s 357ms/step - loss: 0.2084 - accuracy: 0.9284 - val_loss: 1.0462 - val_accuracy: 0.7727\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 14s 395ms/step - loss: 0.3603 - accuracy: 0.8610 - val_loss: 0.9287 - val_accuracy: 0.7727\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 13s 362ms/step - loss: 0.1860 - accuracy: 0.9398 - val_loss: 1.1896 - val_accuracy: 0.7273\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 17s 464ms/step - loss: 0.1176 - accuracy: 0.9673 - val_loss: 1.2259 - val_accuracy: 0.7273\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 17s 464ms/step - loss: 0.1001 - accuracy: 0.9730 - val_loss: 1.4715 - val_accuracy: 0.7273\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 10s 287ms/step - loss: 0.0683 - accuracy: 0.9815 - val_loss: 2.1749 - val_accuracy: 0.5455\n",
      "Score for fold 4: loss of 1.4816337823867798; accuracy of 71.05262875556946%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 13s 325ms/step - loss: 1.0973 - accuracy: 0.4217 - val_loss: 0.9067 - val_accuracy: 0.4545\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 12s 324ms/step - loss: 0.9081 - accuracy: 0.5930 - val_loss: 0.6134 - val_accuracy: 0.7273\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 12s 323ms/step - loss: 0.7426 - accuracy: 0.7035 - val_loss: 0.6636 - val_accuracy: 0.6364\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 12s 325ms/step - loss: 0.6760 - accuracy: 0.7320 - val_loss: 0.7477 - val_accuracy: 0.6818\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 10s 275ms/step - loss: 0.6589 - accuracy: 0.7329 - val_loss: 0.9237 - val_accuracy: 0.6364\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 9s 252ms/step - loss: 0.6013 - accuracy: 0.7524 - val_loss: 0.8101 - val_accuracy: 0.6818\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 9s 261ms/step - loss: 0.5469 - accuracy: 0.7794 - val_loss: 0.8779 - val_accuracy: 0.5909\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 9s 254ms/step - loss: 0.5291 - accuracy: 0.7799 - val_loss: 0.9418 - val_accuracy: 0.6364\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 9s 258ms/step - loss: 0.4793 - accuracy: 0.8121 - val_loss: 0.6109 - val_accuracy: 0.7727\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 9s 258ms/step - loss: 0.4563 - accuracy: 0.8259 - val_loss: 0.8291 - val_accuracy: 0.7727\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 9s 252ms/step - loss: 0.4040 - accuracy: 0.8525 - val_loss: 0.8332 - val_accuracy: 0.7727\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 10s 271ms/step - loss: 0.3732 - accuracy: 0.8572 - val_loss: 0.8369 - val_accuracy: 0.7273\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 11s 304ms/step - loss: 0.3311 - accuracy: 0.8752 - val_loss: 1.1059 - val_accuracy: 0.6818\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 12s 332ms/step - loss: 0.3021 - accuracy: 0.8904 - val_loss: 1.0449 - val_accuracy: 0.6818\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 12s 332ms/step - loss: 0.2863 - accuracy: 0.8918 - val_loss: 1.1920 - val_accuracy: 0.6818\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 12s 320ms/step - loss: 0.2517 - accuracy: 0.9009 - val_loss: 1.2987 - val_accuracy: 0.6818\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 12s 341ms/step - loss: 0.2419 - accuracy: 0.9056 - val_loss: 1.3693 - val_accuracy: 0.7273\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 12s 332ms/step - loss: 0.2108 - accuracy: 0.9184 - val_loss: 1.1727 - val_accuracy: 0.6818\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 12s 348ms/step - loss: 0.1726 - accuracy: 0.9407 - val_loss: 1.3466 - val_accuracy: 0.7273\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 13s 349ms/step - loss: 0.1406 - accuracy: 0.9535 - val_loss: 2.2611 - val_accuracy: 0.6364\n",
      "Score for fold 5: loss of 1.1975940465927124; accuracy of 69.07894611358643%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 15s 392ms/step - loss: 1.1210 - accuracy: 0.3990 - val_loss: 0.9310 - val_accuracy: 0.7273\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 12s 338ms/step - loss: 0.9262 - accuracy: 0.5470 - val_loss: 0.8277 - val_accuracy: 0.6818\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 17s 476ms/step - loss: 0.8353 - accuracy: 0.6319 - val_loss: 0.8566 - val_accuracy: 0.6818\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 13s 370ms/step - loss: 0.7645 - accuracy: 0.6660 - val_loss: 0.9325 - val_accuracy: 0.6364\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 16s 430ms/step - loss: 0.6944 - accuracy: 0.7187 - val_loss: 0.7551 - val_accuracy: 0.7727\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.6194 - accuracy: 0.75 - 17s 473ms/step - loss: 0.6194 - accuracy: 0.7533 - val_loss: 0.7916 - val_accuracy: 0.7727\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 16s 457ms/step - loss: 0.5885 - accuracy: 0.7676 - val_loss: 0.9942 - val_accuracy: 0.6364\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 13s 368ms/step - loss: 0.5823 - accuracy: 0.7657 - val_loss: 0.9355 - val_accuracy: 0.6364\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 15s 416ms/step - loss: 0.5086 - accuracy: 0.7998 - val_loss: 0.9043 - val_accuracy: 0.6818\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 13s 370ms/step - loss: 0.5043 - accuracy: 0.8003 - val_loss: 0.8038 - val_accuracy: 0.7273\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 14s 398ms/step - loss: 0.4961 - accuracy: 0.8069 - val_loss: 0.9888 - val_accuracy: 0.7273\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 14s 401ms/step - loss: 0.4247 - accuracy: 0.8363 - val_loss: 0.9182 - val_accuracy: 0.7273\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 14s 379ms/step - loss: 0.3899 - accuracy: 0.8477 - val_loss: 1.0544 - val_accuracy: 0.6818\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 14s 395ms/step - loss: 0.3754 - accuracy: 0.8596 - val_loss: 1.3603 - val_accuracy: 0.5455\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 13s 373ms/step - loss: 0.3425 - accuracy: 0.8771 - val_loss: 1.0244 - val_accuracy: 0.6818\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 13s 367ms/step - loss: 0.3569 - accuracy: 0.8572 - val_loss: 0.8046 - val_accuracy: 0.7727\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 14s 402ms/step - loss: 0.3343 - accuracy: 0.8752 - val_loss: 0.7931 - val_accuracy: 0.7273\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 14s 393ms/step - loss: 0.2967 - accuracy: 0.8838 - val_loss: 1.0560 - val_accuracy: 0.6364\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 10s 281ms/step - loss: 0.2483 - accuracy: 0.9089 - val_loss: 0.9142 - val_accuracy: 0.7273\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 9s 250ms/step - loss: 0.2259 - accuracy: 0.9250 - val_loss: 1.0061 - val_accuracy: 0.6818\n",
      "Score for fold 6: loss of 1.127761721611023; accuracy of 66.77631735801697%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 14s 340ms/step - loss: 1.0647 - accuracy: 0.4246 - val_loss: 0.8600 - val_accuracy: 0.7727\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 12s 340ms/step - loss: 0.8931 - accuracy: 0.6086 - val_loss: 0.7433 - val_accuracy: 0.7273\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 11s 319ms/step - loss: 0.7478 - accuracy: 0.6954 - val_loss: 0.7664 - val_accuracy: 0.6818\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 10s 268ms/step - loss: 0.7017 - accuracy: 0.7125 - val_loss: 0.7163 - val_accuracy: 0.8636\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 10s 277ms/step - loss: 0.6297 - accuracy: 0.7481 - val_loss: 0.8684 - val_accuracy: 0.6818\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 12s 323ms/step - loss: 0.6065 - accuracy: 0.7576 - val_loss: 0.9627 - val_accuracy: 0.7273\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 11s 309ms/step - loss: 0.5764 - accuracy: 0.7718 - val_loss: 0.8381 - val_accuracy: 0.7273\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 10s 283ms/step - loss: 0.4670 - accuracy: 0.8202 - val_loss: 0.8901 - val_accuracy: 0.8182\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 10s 290ms/step - loss: 0.4157 - accuracy: 0.8472 - val_loss: 1.0635 - val_accuracy: 0.7273\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 15s 415ms/step - loss: 0.3695 - accuracy: 0.8634 - val_loss: 0.9746 - val_accuracy: 0.7727\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 14s 384ms/step - loss: 0.3370 - accuracy: 0.8805 - val_loss: 1.0029 - val_accuracy: 0.8182\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 13s 366ms/step - loss: 0.2777 - accuracy: 0.8952 - val_loss: 1.3147 - val_accuracy: 0.7273\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 12s 344ms/step - loss: 0.2838 - accuracy: 0.8933 - val_loss: 1.1289 - val_accuracy: 0.7727\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 11s 318ms/step - loss: 0.2080 - accuracy: 0.9293 - val_loss: 1.4385 - val_accuracy: 0.6818\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 14s 388ms/step - loss: 0.1648 - accuracy: 0.9407 - val_loss: 1.4565 - val_accuracy: 0.7273\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 12s 333ms/step - loss: 0.1339 - accuracy: 0.9568 - val_loss: 1.9262 - val_accuracy: 0.6364\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 11s 311ms/step - loss: 0.1057 - accuracy: 0.9687 - val_loss: 1.6968 - val_accuracy: 0.6818\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 12s 338ms/step - loss: 0.1110 - accuracy: 0.9696 - val_loss: 1.6308 - val_accuracy: 0.7273\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 12s 332ms/step - loss: 0.1159 - accuracy: 0.9630 - val_loss: 1.9259 - val_accuracy: 0.6818\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 13s 357ms/step - loss: 0.0893 - accuracy: 0.9711 - val_loss: 1.6054 - val_accuracy: 0.6818\n",
      "Score for fold 7: loss of 1.1187909841537476; accuracy of 74.34210777282715%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 15s 366ms/step - loss: 1.1287 - accuracy: 0.3482 - val_loss: 0.9413 - val_accuracy: 0.3182\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 12s 339ms/step - loss: 0.9781 - accuracy: 0.5076 - val_loss: 0.8967 - val_accuracy: 0.5455\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 10s 286ms/step - loss: 0.8762 - accuracy: 0.5987 - val_loss: 0.7168 - val_accuracy: 0.7727\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 10s 268ms/step - loss: 0.7836 - accuracy: 0.6750 - val_loss: 0.6871 - val_accuracy: 0.8182\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 11s 318ms/step - loss: 0.7380 - accuracy: 0.6898 - val_loss: 0.8276 - val_accuracy: 0.6364\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 13s 349ms/step - loss: 0.7200 - accuracy: 0.7021 - val_loss: 0.6635 - val_accuracy: 0.8182\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 13s 355ms/step - loss: 0.6669 - accuracy: 0.7230 - val_loss: 0.8274 - val_accuracy: 0.5455\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 11s 297ms/step - loss: 0.6415 - accuracy: 0.7514 - val_loss: 0.6998 - val_accuracy: 0.7727\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 10s 287ms/step - loss: 0.5856 - accuracy: 0.7718 - val_loss: 0.9523 - val_accuracy: 0.6364\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 11s 312ms/step - loss: 0.5746 - accuracy: 0.7775 - val_loss: 0.9023 - val_accuracy: 0.6818\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 12s 341ms/step - loss: 0.5404 - accuracy: 0.7913 - val_loss: 0.9501 - val_accuracy: 0.6364\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 13s 356ms/step - loss: 0.5437 - accuracy: 0.7927 - val_loss: 0.9561 - val_accuracy: 0.6364\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 12s 346ms/step - loss: 0.4996 - accuracy: 0.8102 - val_loss: 0.8747 - val_accuracy: 0.5909\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 12s 339ms/step - loss: 0.4715 - accuracy: 0.8212 - val_loss: 0.8473 - val_accuracy: 0.8636\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 11s 307ms/step - loss: 0.4630 - accuracy: 0.8259 - val_loss: 0.9081 - val_accuracy: 0.6364\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 11s 303ms/step - loss: 0.4520 - accuracy: 0.8340 - val_loss: 0.9032 - val_accuracy: 0.8182\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 12s 331ms/step - loss: 0.4175 - accuracy: 0.8420 - val_loss: 0.8493 - val_accuracy: 0.7727\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 12s 340ms/step - loss: 0.3837 - accuracy: 0.8563 - val_loss: 1.0720 - val_accuracy: 0.7273\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 12s 338ms/step - loss: 0.3599 - accuracy: 0.8738 - val_loss: 0.8815 - val_accuracy: 0.7273\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 13s 348ms/step - loss: 0.3394 - accuracy: 0.8705 - val_loss: 0.9423 - val_accuracy: 0.7273\n",
      "Score for fold 8: loss of 0.9120530486106873; accuracy of 67.43420958518982%\n"
     ]
    }
   ],
   "source": [
    "inputs = np.concatenate((X_train, X_test), axis=0)\n",
    "targets = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "num_folds = 8\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "fold_no = 1\n",
    "acc_per_fold1 = []\n",
    "loss_per_fold1 = []\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "    model = Sequential()\n",
    "\n",
    "        \n",
    "    model.add(Conv2D(128, kernel_size = (3, 3)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "\n",
    "    model.add(Conv2D(64, kernel_size = (3, 3)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "    \n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    history = model.fit(inputs[train],targets[train],epochs = 20,batch_size = 60, validation_split = 0.01)\n",
    "    scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold1.append(scores[1] * 100)\n",
    "    loss_per_fold1.append(scores[0])\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "06a57ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 8s 178ms/step - loss: 7.2497 - accuracy: 0.5686 - val_loss: 0.9934 - val_accuracy: 0.4091\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 7s 178ms/step - loss: 0.5990 - accuracy: 0.8049 - val_loss: 1.4402 - val_accuracy: 0.2727\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 6s 178ms/step - loss: 0.2482 - accuracy: 0.9165 - val_loss: 0.9398 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 9s 238ms/step - loss: 0.1406 - accuracy: 0.9516 - val_loss: 0.8614 - val_accuracy: 0.6364\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 6s 163ms/step - loss: 0.0883 - accuracy: 0.9758 - val_loss: 0.8753 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 5s 142ms/step - loss: 0.0640 - accuracy: 0.9834 - val_loss: 0.8639 - val_accuracy: 0.6364\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 7s 201ms/step - loss: 0.0501 - accuracy: 0.9877 - val_loss: 0.8190 - val_accuracy: 0.6818\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 8s 228ms/step - loss: 0.0458 - accuracy: 0.9905 - val_loss: 0.6689 - val_accuracy: 0.7727\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.0471 - accuracy: 0.9915 - val_loss: 0.6800 - val_accuracy: 0.7273\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 4s 112ms/step - loss: 0.0545 - accuracy: 0.9867 - val_loss: 0.6812 - val_accuracy: 0.7727\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 4s 120ms/step - loss: 0.0462 - accuracy: 0.9896 - val_loss: 0.8546 - val_accuracy: 0.7273\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 4s 102ms/step - loss: 0.0584 - accuracy: 0.9872 - val_loss: 0.6928 - val_accuracy: 0.7273\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 4s 101ms/step - loss: 0.0308 - accuracy: 0.9938 - val_loss: 0.5238 - val_accuracy: 0.8182\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.0565 - accuracy: 0.9858 - val_loss: 0.8311 - val_accuracy: 0.6364\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 4s 113ms/step - loss: 0.0295 - accuracy: 0.9938 - val_loss: 0.7435 - val_accuracy: 0.6364\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 7s 190ms/step - loss: 0.0338 - accuracy: 0.9938 - val_loss: 0.6521 - val_accuracy: 0.7727\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 5s 130ms/step - loss: 0.0317 - accuracy: 0.9934 - val_loss: 0.9455 - val_accuracy: 0.6818\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 4s 122ms/step - loss: 0.0289 - accuracy: 0.9943 - val_loss: 0.7924 - val_accuracy: 0.7727\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 4s 124ms/step - loss: 0.0371 - accuracy: 0.9938 - val_loss: 0.7566 - val_accuracy: 0.7273\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 5s 137ms/step - loss: 0.0393 - accuracy: 0.9934 - val_loss: 0.6188 - val_accuracy: 0.8182\n",
      "Score for fold 1: loss of 1.484151840209961; accuracy of 70.49180269241333%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 8s 190ms/step - loss: 4.5749 - accuracy: 0.5752 - val_loss: 1.0726 - val_accuracy: 0.3182\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 4s 111ms/step - loss: 0.5213 - accuracy: 0.8040 - val_loss: 1.0587 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 3s 84ms/step - loss: 0.2662 - accuracy: 0.9108 - val_loss: 0.9697 - val_accuracy: 0.6818\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 4s 120ms/step - loss: 0.1403 - accuracy: 0.9578 - val_loss: 0.9479 - val_accuracy: 0.6818\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 5s 146ms/step - loss: 0.0950 - accuracy: 0.9796 - val_loss: 0.9307 - val_accuracy: 0.4545\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 4s 113ms/step - loss: 0.0716 - accuracy: 0.9858 - val_loss: 0.8915 - val_accuracy: 0.5455\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 4s 103ms/step - loss: 0.0525 - accuracy: 0.9891 - val_loss: 0.8283 - val_accuracy: 0.5909\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 5s 145ms/step - loss: 0.0557 - accuracy: 0.9896 - val_loss: 0.8127 - val_accuracy: 0.6364\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.0361 - accuracy: 0.9948 - val_loss: 0.8202 - val_accuracy: 0.6364\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.0389 - accuracy: 0.9948 - val_loss: 0.7433 - val_accuracy: 0.7727\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 5s 141ms/step - loss: 0.0336 - accuracy: 0.9943 - val_loss: 0.7530 - val_accuracy: 0.7273\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 4s 103ms/step - loss: 0.0341 - accuracy: 0.9953 - val_loss: 0.7479 - val_accuracy: 0.6364\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 4s 106ms/step - loss: 0.0312 - accuracy: 0.9953 - val_loss: 0.7249 - val_accuracy: 0.7727\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 4s 109ms/step - loss: 0.0936 - accuracy: 0.9858 - val_loss: 1.0839 - val_accuracy: 0.6818\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 5s 144ms/step - loss: 0.0701 - accuracy: 0.9934 - val_loss: 0.9131 - val_accuracy: 0.7273\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 4s 113ms/step - loss: 0.0407 - accuracy: 0.9953 - val_loss: 0.9186 - val_accuracy: 0.6818\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.0344 - accuracy: 0.9948 - val_loss: 0.8609 - val_accuracy: 0.7727\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 6s 170ms/step - loss: 0.0337 - accuracy: 0.9938 - val_loss: 1.4832 - val_accuracy: 0.6364\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 4s 110ms/step - loss: 0.0315 - accuracy: 0.9953 - val_loss: 1.1632 - val_accuracy: 0.6818\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 4s 96ms/step - loss: 0.0320 - accuracy: 0.9953 - val_loss: 1.1760 - val_accuracy: 0.7727\n",
      "Score for fold 2: loss of 1.508742094039917; accuracy of 69.18032765388489%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 6s 117ms/step - loss: 8.6527 - accuracy: 0.5493 - val_loss: 1.0474 - val_accuracy: 0.4545\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.6026 - accuracy: 0.7837 - val_loss: 1.1560 - val_accuracy: 0.3182\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 4s 104ms/step - loss: 0.2505 - accuracy: 0.9108 - val_loss: 1.0180 - val_accuracy: 0.4545\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 4s 100ms/step - loss: 0.1424 - accuracy: 0.9564 - val_loss: 1.0091 - val_accuracy: 0.3636\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.0830 - accuracy: 0.9753 - val_loss: 0.9699 - val_accuracy: 0.3636\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0614 - accuracy: 0.9886 - val_loss: 1.0020 - val_accuracy: 0.3636\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.0602 - accuracy: 0.9862 - val_loss: 0.9863 - val_accuracy: 0.4091\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 4s 103ms/step - loss: 0.0475 - accuracy: 0.9919 - val_loss: 0.8919 - val_accuracy: 0.5455\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.0427 - accuracy: 0.9929 - val_loss: 0.8392 - val_accuracy: 0.5909\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 3s 96ms/step - loss: 0.0513 - accuracy: 0.9905 - val_loss: 0.8232 - val_accuracy: 0.6818\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0458 - accuracy: 0.9929 - val_loss: 0.8175 - val_accuracy: 0.5909\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 5s 140ms/step - loss: 0.0528 - accuracy: 0.9910 - val_loss: 0.7546 - val_accuracy: 0.7273\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.0393 - accuracy: 0.9929 - val_loss: 0.8503 - val_accuracy: 0.6364\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 4s 108ms/step - loss: 0.0496 - accuracy: 0.9929 - val_loss: 0.6931 - val_accuracy: 0.7727\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 4s 115ms/step - loss: 0.0430 - accuracy: 0.9934 - val_loss: 0.9424 - val_accuracy: 0.6818\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 4s 105ms/step - loss: 0.0406 - accuracy: 0.9934 - val_loss: 1.0053 - val_accuracy: 0.6364\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 5s 131ms/step - loss: 0.0458 - accuracy: 0.9929 - val_loss: 1.1447 - val_accuracy: 0.6818\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.0444 - accuracy: 0.9929 - val_loss: 0.9897 - val_accuracy: 0.6364\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.0529 - accuracy: 0.9919 - val_loss: 1.3005 - val_accuracy: 0.6818\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.0609 - accuracy: 0.9881 - val_loss: 1.1540 - val_accuracy: 0.6818\n",
      "Score for fold 3: loss of 1.2983649969100952; accuracy of 65.78947305679321%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 6s 118ms/step - loss: 6.0733 - accuracy: 0.5650 - val_loss: 1.2694 - val_accuracy: 0.1818\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.6092 - accuracy: 0.7690 - val_loss: 1.1893 - val_accuracy: 0.1818\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 4s 98ms/step - loss: 0.2969 - accuracy: 0.8952 - val_loss: 1.0381 - val_accuracy: 0.3182\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 8s 215ms/step - loss: 0.1607 - accuracy: 0.9516 - val_loss: 1.0634 - val_accuracy: 0.3636\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 7s 202ms/step - loss: 0.1040 - accuracy: 0.9715 - val_loss: 0.9689 - val_accuracy: 0.4545\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 8s 211ms/step - loss: 0.0758 - accuracy: 0.9824 - val_loss: 0.9564 - val_accuracy: 0.4091\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 5s 125ms/step - loss: 0.0554 - accuracy: 0.9867 - val_loss: 0.9318 - val_accuracy: 0.6364\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0461 - accuracy: 0.9929 - val_loss: 0.9225 - val_accuracy: 0.5909\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 4s 117ms/step - loss: 0.0497 - accuracy: 0.9924 - val_loss: 0.8892 - val_accuracy: 0.5909\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.0474 - accuracy: 0.9919 - val_loss: 0.8674 - val_accuracy: 0.5909\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 6s 161ms/step - loss: 0.0455 - accuracy: 0.9924 - val_loss: 0.8141 - val_accuracy: 0.6818\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 6s 168ms/step - loss: 0.0339 - accuracy: 0.9934 - val_loss: 0.7910 - val_accuracy: 0.6364\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.0368 - accuracy: 0.9924 - val_loss: 0.8612 - val_accuracy: 0.6818\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 3s 96ms/step - loss: 0.0285 - accuracy: 0.9948 - val_loss: 0.9659 - val_accuracy: 0.6818\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.0320 - accuracy: 0.9938 - val_loss: 0.9828 - val_accuracy: 0.8182\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 4s 102ms/step - loss: 0.0447 - accuracy: 0.9915 - val_loss: 0.9428 - val_accuracy: 0.7273\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 4s 114ms/step - loss: 0.0368 - accuracy: 0.9929 - val_loss: 0.9986 - val_accuracy: 0.6818\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0383 - accuracy: 0.9934 - val_loss: 1.1827 - val_accuracy: 0.7273\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 4s 100ms/step - loss: 0.0251 - accuracy: 0.9948 - val_loss: 1.2402 - val_accuracy: 0.7727\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 5s 126ms/step - loss: 0.0442 - accuracy: 0.9924 - val_loss: 1.2258 - val_accuracy: 0.7273\n",
      "Score for fold 4: loss of 1.1290225982666016; accuracy of 69.07894611358643%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 12s 268ms/step - loss: 8.7734 - accuracy: 0.5631 - val_loss: 0.9906 - val_accuracy: 0.5455\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 11s 293ms/step - loss: 0.7201 - accuracy: 0.7766 - val_loss: 1.2026 - val_accuracy: 0.1818\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 11s 321ms/step - loss: 0.2458 - accuracy: 0.9070 - val_loss: 0.9846 - val_accuracy: 0.5455\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 9s 237ms/step - loss: 0.1240 - accuracy: 0.9663 - val_loss: 0.9911 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 8s 222ms/step - loss: 0.0790 - accuracy: 0.9777 - val_loss: 0.9375 - val_accuracy: 0.5455\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 8s 213ms/step - loss: 0.0536 - accuracy: 0.9867 - val_loss: 0.9543 - val_accuracy: 0.5455\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 8s 231ms/step - loss: 0.0479 - accuracy: 0.9905 - val_loss: 0.8849 - val_accuracy: 0.5909\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 6s 178ms/step - loss: 0.0421 - accuracy: 0.9929 - val_loss: 0.9087 - val_accuracy: 0.5455\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 4s 103ms/step - loss: 0.0801 - accuracy: 0.9806 - val_loss: 0.8598 - val_accuracy: 0.6364\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 4s 114ms/step - loss: 0.0565 - accuracy: 0.9924 - val_loss: 0.8503 - val_accuracy: 0.5455\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 4s 107ms/step - loss: 0.0455 - accuracy: 0.9929 - val_loss: 0.7711 - val_accuracy: 0.6818\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 5s 127ms/step - loss: 0.0454 - accuracy: 0.9924 - val_loss: 0.8835 - val_accuracy: 0.5455\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 6s 154ms/step - loss: 0.0341 - accuracy: 0.9948 - val_loss: 0.7844 - val_accuracy: 0.7273\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 5s 130ms/step - loss: 0.0384 - accuracy: 0.9943 - val_loss: 0.8990 - val_accuracy: 0.6818\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 5s 135ms/step - loss: 0.0366 - accuracy: 0.9938 - val_loss: 0.9620 - val_accuracy: 0.7273\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 4s 104ms/step - loss: 0.0346 - accuracy: 0.9924 - val_loss: 1.1129 - val_accuracy: 0.6364\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 4s 109ms/step - loss: 0.0256 - accuracy: 0.9957 - val_loss: 1.0675 - val_accuracy: 0.6818\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 4s 108ms/step - loss: 0.0415 - accuracy: 0.9948 - val_loss: 1.4834 - val_accuracy: 0.5909\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 4s 119ms/step - loss: 0.0365 - accuracy: 0.9934 - val_loss: 1.2484 - val_accuracy: 0.7273\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 5s 150ms/step - loss: 0.0982 - accuracy: 0.9877 - val_loss: 1.7971 - val_accuracy: 0.4545\n",
      "Score for fold 5: loss of 1.9422645568847656; accuracy of 58.55262875556946%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 8s 173ms/step - loss: 8.5845 - accuracy: 0.5512 - val_loss: 0.9109 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 5s 141ms/step - loss: 0.8665 - accuracy: 0.7756 - val_loss: 1.0391 - val_accuracy: 0.3636\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 6s 159ms/step - loss: 0.2762 - accuracy: 0.9004 - val_loss: 0.9951 - val_accuracy: 0.3636\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 5s 124ms/step - loss: 0.1583 - accuracy: 0.9507 - val_loss: 0.9251 - val_accuracy: 0.6364\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 4s 104ms/step - loss: 0.0942 - accuracy: 0.9730 - val_loss: 1.0042 - val_accuracy: 0.3636\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 4s 123ms/step - loss: 0.0595 - accuracy: 0.9853 - val_loss: 0.9087 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 5s 129ms/step - loss: 0.0638 - accuracy: 0.9867 - val_loss: 0.9131 - val_accuracy: 0.4545\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 4s 105ms/step - loss: 0.0585 - accuracy: 0.9919 - val_loss: 0.8940 - val_accuracy: 0.5455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.0446 - accuracy: 0.9934 - val_loss: 0.8918 - val_accuracy: 0.4545\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.0435 - accuracy: 0.9919 - val_loss: 0.7914 - val_accuracy: 0.6364\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 4s 104ms/step - loss: 0.0515 - accuracy: 0.9910 - val_loss: 0.7493 - val_accuracy: 0.7273\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 4s 107ms/step - loss: 0.1081 - accuracy: 0.9772 - val_loss: 0.8484 - val_accuracy: 0.6364\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 5s 129ms/step - loss: 0.0838 - accuracy: 0.9910 - val_loss: 0.9893 - val_accuracy: 0.5909\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 4s 102ms/step - loss: 0.0631 - accuracy: 0.9929 - val_loss: 0.9877 - val_accuracy: 0.5909\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 5s 151ms/step - loss: 0.0534 - accuracy: 0.9929 - val_loss: 1.0325 - val_accuracy: 0.7273\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 6s 162ms/step - loss: 0.0503 - accuracy: 0.9929 - val_loss: 1.0692 - val_accuracy: 0.7273\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 8s 221ms/step - loss: 0.0314 - accuracy: 0.9953 - val_loss: 1.1212 - val_accuracy: 0.6818\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 7s 195ms/step - loss: 0.0307 - accuracy: 0.9938 - val_loss: 1.2969 - val_accuracy: 0.7273\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 4s 109ms/step - loss: 0.0298 - accuracy: 0.9948 - val_loss: 1.3909 - val_accuracy: 0.7273\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 4s 119ms/step - loss: 0.0693 - accuracy: 0.9834 - val_loss: 1.5599 - val_accuracy: 0.7273\n",
      "Score for fold 6: loss of 1.412825107574463; accuracy of 63.81579041481018%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 6s 138ms/step - loss: 10.3514 - accuracy: 0.5446 - val_loss: 0.9982 - val_accuracy: 0.4545\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 6s 158ms/step - loss: 0.8159 - accuracy: 0.7685 - val_loss: 0.9357 - val_accuracy: 0.5909\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 5s 141ms/step - loss: 0.2989 - accuracy: 0.8838 - val_loss: 0.9541 - val_accuracy: 0.4091\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 3s 95ms/step - loss: 0.1285 - accuracy: 0.9654 - val_loss: 0.8515 - val_accuracy: 0.7727\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 4s 102ms/step - loss: 0.0962 - accuracy: 0.9806 - val_loss: 0.8326 - val_accuracy: 0.6818\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 3s 96ms/step - loss: 0.0731 - accuracy: 0.9862 - val_loss: 0.8535 - val_accuracy: 0.5455\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0448 - accuracy: 0.9924 - val_loss: 0.7922 - val_accuracy: 0.8182\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 5s 129ms/step - loss: 0.0456 - accuracy: 0.9915 - val_loss: 0.7347 - val_accuracy: 0.7727\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.0344 - accuracy: 0.9938 - val_loss: 0.6703 - val_accuracy: 0.7727\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 5s 150ms/step - loss: 0.0401 - accuracy: 0.9934 - val_loss: 0.6806 - val_accuracy: 0.7273\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 4s 100ms/step - loss: 0.0581 - accuracy: 0.9953 - val_loss: 0.6674 - val_accuracy: 0.7273\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 4s 118ms/step - loss: 0.0547 - accuracy: 0.9938 - val_loss: 0.6535 - val_accuracy: 0.6818\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.0423 - accuracy: 0.9948 - val_loss: 0.6556 - val_accuracy: 0.7727\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.0373 - accuracy: 0.9948 - val_loss: 0.6354 - val_accuracy: 0.8182\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 3s 97ms/step - loss: 0.0370 - accuracy: 0.9943 - val_loss: 0.5892 - val_accuracy: 0.8182\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 4s 112ms/step - loss: 0.0372 - accuracy: 0.9934 - val_loss: 0.6343 - val_accuracy: 0.8182\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.0323 - accuracy: 0.9943 - val_loss: 0.6498 - val_accuracy: 0.8182\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.0331 - accuracy: 0.9953 - val_loss: 0.6545 - val_accuracy: 0.8636\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 3s 96ms/step - loss: 0.0241 - accuracy: 0.9948 - val_loss: 0.6644 - val_accuracy: 0.9091\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 4s 116ms/step - loss: 0.0436 - accuracy: 0.9929 - val_loss: 0.6707 - val_accuracy: 0.8636\n",
      "Score for fold 7: loss of 1.2252559661865234; accuracy of 71.05262875556946%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 7s 156ms/step - loss: 7.8145 - accuracy: 0.5579 - val_loss: 1.1726 - val_accuracy: 0.5455\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 6s 167ms/step - loss: 0.7192 - accuracy: 0.7898 - val_loss: 0.9708 - val_accuracy: 0.6818\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 4s 116ms/step - loss: 0.2486 - accuracy: 0.9160 - val_loss: 0.9177 - val_accuracy: 0.5455\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 4s 108ms/step - loss: 0.1534 - accuracy: 0.9497 - val_loss: 0.8747 - val_accuracy: 0.7273\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 3s 96ms/step - loss: 0.0837 - accuracy: 0.9772 - val_loss: 0.7919 - val_accuracy: 0.6818\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 3s 96ms/step - loss: 0.0567 - accuracy: 0.9886 - val_loss: 0.8042 - val_accuracy: 0.8182\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 4s 108ms/step - loss: 0.0556 - accuracy: 0.9872 - val_loss: 0.7557 - val_accuracy: 0.8182\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 3s 95ms/step - loss: 0.0450 - accuracy: 0.9919 - val_loss: 0.6858 - val_accuracy: 0.8182\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0368 - accuracy: 0.9919 - val_loss: 0.7425 - val_accuracy: 0.7727\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 3s 94ms/step - loss: 0.0407 - accuracy: 0.9934 - val_loss: 0.6578 - val_accuracy: 0.8182\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 4s 105ms/step - loss: 0.0403 - accuracy: 0.9924 - val_loss: 0.7155 - val_accuracy: 0.7727\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 4s 101ms/step - loss: 0.0396 - accuracy: 0.9934 - val_loss: 0.7216 - val_accuracy: 0.7727\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 4s 107ms/step - loss: 0.0715 - accuracy: 0.9872 - val_loss: 0.6407 - val_accuracy: 0.8636\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 4s 102ms/step - loss: 0.0557 - accuracy: 0.9929 - val_loss: 0.7603 - val_accuracy: 0.8182\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.0462 - accuracy: 0.9915 - val_loss: 0.7345 - val_accuracy: 0.8182\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 4s 124ms/step - loss: 0.0667 - accuracy: 0.9919 - val_loss: 1.0169 - val_accuracy: 0.7727\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 4s 110ms/step - loss: 0.0559 - accuracy: 0.9934 - val_loss: 0.9447 - val_accuracy: 0.6818\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 4s 103ms/step - loss: 0.0411 - accuracy: 0.9957 - val_loss: 1.1856 - val_accuracy: 0.7727\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 4s 102ms/step - loss: 0.0485 - accuracy: 0.9934 - val_loss: 1.0700 - val_accuracy: 0.7727\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 4s 122ms/step - loss: 0.0394 - accuracy: 0.9934 - val_loss: 1.4094 - val_accuracy: 0.6818\n",
      "Score for fold 8: loss of 1.158364176750183; accuracy of 70.72368264198303%\n"
     ]
    }
   ],
   "source": [
    "num_folds = 8\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "inputs = np.concatenate((X_train, X_test), axis=0)\n",
    "targets = np.concatenate((y_train, y_test), axis=0)\n",
    "fold_no = 1\n",
    "acc_per_fold2 = []\n",
    "loss_per_fold2 = []\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "    model = Sequential()\n",
    "\n",
    "          \n",
    "          \n",
    "    model.add(Conv2D(64, kernel_size = (3, 3)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "  \n",
    "   \n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    history = model.fit(inputs[train],targets[train],epochs = 20,batch_size = 60, validation_split = 0.01)\n",
    "    scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold2.append(scores[1] * 100)\n",
    "    loss_per_fold2.append(scores[0])\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "08bbcf75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 3s 68ms/step - loss: 2.1107 - accuracy: 0.4689 - val_loss: 1.0604 - val_accuracy: 0.3182\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 2s 60ms/step - loss: 1.6077 - accuracy: 0.5254 - val_loss: 1.0502 - val_accuracy: 0.3182\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 2s 59ms/step - loss: 1.3346 - accuracy: 0.5543 - val_loss: 1.0865 - val_accuracy: 0.2273\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 2s 48ms/step - loss: 1.1728 - accuracy: 0.5804 - val_loss: 1.0823 - val_accuracy: 0.3182\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 2s 54ms/step - loss: 1.0751 - accuracy: 0.6061 - val_loss: 1.0635 - val_accuracy: 0.3182\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 2s 59ms/step - loss: 1.0247 - accuracy: 0.5890 - val_loss: 1.0392 - val_accuracy: 0.3636\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 2s 59ms/step - loss: 0.9485 - accuracy: 0.6032 - val_loss: 1.0222 - val_accuracy: 0.4091\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 2s 52ms/step - loss: 0.9209 - accuracy: 0.6151 - val_loss: 0.9839 - val_accuracy: 0.4091\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.9025 - accuracy: 0.6194 - val_loss: 0.9795 - val_accuracy: 0.4091\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 2s 60ms/step - loss: 0.8335 - accuracy: 0.6569 - val_loss: 0.9369 - val_accuracy: 0.6364\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 2s 50ms/step - loss: 0.8151 - accuracy: 0.6474 - val_loss: 0.9404 - val_accuracy: 0.5455\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 2s 50ms/step - loss: 0.8077 - accuracy: 0.6668 - val_loss: 0.8934 - val_accuracy: 0.6818\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 2s 58ms/step - loss: 0.7935 - accuracy: 0.6749 - val_loss: 0.8577 - val_accuracy: 0.5909\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 2s 48ms/step - loss: 0.7815 - accuracy: 0.6820 - val_loss: 0.8353 - val_accuracy: 0.5909\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 2s 55ms/step - loss: 0.7364 - accuracy: 0.6981 - val_loss: 0.8465 - val_accuracy: 0.5455\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 2s 60ms/step - loss: 0.7052 - accuracy: 0.7091 - val_loss: 0.8343 - val_accuracy: 0.6364\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.7308 - accuracy: 0.6977 - val_loss: 0.8035 - val_accuracy: 0.5909\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 1s 30ms/step - loss: 0.6950 - accuracy: 0.6981 - val_loss: 0.7868 - val_accuracy: 0.7273\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.6552 - accuracy: 0.7366 - val_loss: 0.7628 - val_accuracy: 0.7273\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.6655 - accuracy: 0.7271 - val_loss: 0.8008 - val_accuracy: 0.6818\n",
      "Score for fold 1: loss of 0.7207091450691223; accuracy of 68.19671988487244%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 2s 28ms/step - loss: 2.3963 - accuracy: 0.4599 - val_loss: 0.9809 - val_accuracy: 0.6818\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 2s 63ms/step - loss: 1.8339 - accuracy: 0.5301 - val_loss: 0.9574 - val_accuracy: 0.7727\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 2s 66ms/step - loss: 1.4473 - accuracy: 0.5672 - val_loss: 0.9525 - val_accuracy: 0.7727\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 2s 64ms/step - loss: 1.2619 - accuracy: 0.5795 - val_loss: 0.9718 - val_accuracy: 0.5909\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 2s 67ms/step - loss: 1.1359 - accuracy: 0.5790 - val_loss: 0.9669 - val_accuracy: 0.6364\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 2s 68ms/step - loss: 0.9556 - accuracy: 0.6246 - val_loss: 0.9978 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 3s 79ms/step - loss: 0.8935 - accuracy: 0.6179 - val_loss: 0.9666 - val_accuracy: 0.5909\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 3s 70ms/step - loss: 0.8296 - accuracy: 0.6426 - val_loss: 0.9429 - val_accuracy: 0.7273\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 2s 69ms/step - loss: 0.8031 - accuracy: 0.6630 - val_loss: 0.9299 - val_accuracy: 0.7273\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 1s 29ms/step - loss: 0.8077 - accuracy: 0.6559 - val_loss: 0.9091 - val_accuracy: 0.5455\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.7597 - accuracy: 0.6749 - val_loss: 0.9028 - val_accuracy: 0.5455\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.7861 - accuracy: 0.6497 - val_loss: 0.8576 - val_accuracy: 0.5909\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.7322 - accuracy: 0.6963 - val_loss: 0.8249 - val_accuracy: 0.5909\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.7019 - accuracy: 0.7005 - val_loss: 0.8416 - val_accuracy: 0.5909\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.6958 - accuracy: 0.7029 - val_loss: 0.8032 - val_accuracy: 0.5909\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.6799 - accuracy: 0.7200 - val_loss: 0.7805 - val_accuracy: 0.5909\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.6836 - accuracy: 0.7129 - val_loss: 0.8042 - val_accuracy: 0.5455\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.6496 - accuracy: 0.7195 - val_loss: 0.7893 - val_accuracy: 0.5455\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.6603 - accuracy: 0.7252 - val_loss: 0.7553 - val_accuracy: 0.5455\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.6482 - accuracy: 0.7280 - val_loss: 0.7234 - val_accuracy: 0.6364\n",
      "Score for fold 2: loss of 0.718934178352356; accuracy of 70.81966996192932%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 3s 67ms/step - loss: 2.9405 - accuracy: 0.4507 - val_loss: 1.0082 - val_accuracy: 0.5455\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 2s 62ms/step - loss: 2.3653 - accuracy: 0.5081 - val_loss: 0.9640 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 2s 59ms/step - loss: 1.9383 - accuracy: 0.5465 - val_loss: 1.0019 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 2s 59ms/step - loss: 1.6510 - accuracy: 0.5669 - val_loss: 1.0368 - val_accuracy: 0.3182\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 2s 60ms/step - loss: 1.4155 - accuracy: 0.5897 - val_loss: 0.9997 - val_accuracy: 0.3182\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 2s 54ms/step - loss: 1.3039 - accuracy: 0.5935 - val_loss: 0.9619 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 1.1404 - accuracy: 0.6034 - val_loss: 0.9815 - val_accuracy: 0.4091\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 1.0405 - accuracy: 0.6229 - val_loss: 0.9925 - val_accuracy: 0.3636\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.9405 - accuracy: 0.6390 - val_loss: 0.9401 - val_accuracy: 0.5455\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.9439 - accuracy: 0.6452 - val_loss: 0.9936 - val_accuracy: 0.4091\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 1s 33ms/step - loss: 0.8674 - accuracy: 0.6509 - val_loss: 0.9322 - val_accuracy: 0.3636\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.8722 - accuracy: 0.6433 - val_loss: 0.9657 - val_accuracy: 0.5000\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.8133 - accuracy: 0.6632 - val_loss: 0.8583 - val_accuracy: 0.5455\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.7736 - accuracy: 0.6874 - val_loss: 0.8569 - val_accuracy: 0.5455\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.7989 - accuracy: 0.6603 - val_loss: 0.7830 - val_accuracy: 0.5455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.7603 - accuracy: 0.6912 - val_loss: 0.8496 - val_accuracy: 0.4545\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.7224 - accuracy: 0.7111 - val_loss: 0.8141 - val_accuracy: 0.5455\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.7182 - accuracy: 0.6912 - val_loss: 0.7660 - val_accuracy: 0.6818\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.6902 - accuracy: 0.6992 - val_loss: 0.6687 - val_accuracy: 0.6818\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.6970 - accuracy: 0.7116 - val_loss: 0.7073 - val_accuracy: 0.5909\n",
      "Score for fold 3: loss of 0.7711139917373657; accuracy of 63.15789222717285%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 3s 60ms/step - loss: 1.7452 - accuracy: 0.4564 - val_loss: 1.1296 - val_accuracy: 0.3182\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 1.3643 - accuracy: 0.5133 - val_loss: 1.0410 - val_accuracy: 0.5455\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 1.1955 - accuracy: 0.5351 - val_loss: 0.9844 - val_accuracy: 0.6364\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 1.0688 - accuracy: 0.5560 - val_loss: 0.9926 - val_accuracy: 0.5909\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.9698 - accuracy: 0.5878 - val_loss: 0.9949 - val_accuracy: 0.6364\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.9389 - accuracy: 0.5773 - val_loss: 0.9625 - val_accuracy: 0.5909\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.8822 - accuracy: 0.6010 - val_loss: 0.9493 - val_accuracy: 0.6364\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.8280 - accuracy: 0.6399 - val_loss: 0.8908 - val_accuracy: 0.7727\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 2s 47ms/step - loss: 0.8222 - accuracy: 0.6418 - val_loss: 0.8517 - val_accuracy: 0.7727\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 1s 36ms/step - loss: 0.7707 - accuracy: 0.6603 - val_loss: 0.8419 - val_accuracy: 0.5909\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.7484 - accuracy: 0.6879 - val_loss: 0.8613 - val_accuracy: 0.6364\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.7264 - accuracy: 0.6921 - val_loss: 0.8263 - val_accuracy: 0.5909\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.7184 - accuracy: 0.6860 - val_loss: 1.0645 - val_accuracy: 0.4091\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.7358 - accuracy: 0.6869 - val_loss: 0.9687 - val_accuracy: 0.5000\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 1s 22ms/step - loss: 0.6951 - accuracy: 0.7111 - val_loss: 0.8053 - val_accuracy: 0.6364\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 2s 49ms/step - loss: 0.6987 - accuracy: 0.7078 - val_loss: 0.9708 - val_accuracy: 0.5455\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 2s 49ms/step - loss: 0.6828 - accuracy: 0.7011 - val_loss: 0.8793 - val_accuracy: 0.5909\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 2s 45ms/step - loss: 0.6827 - accuracy: 0.6978 - val_loss: 0.9079 - val_accuracy: 0.5455\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 2s 62ms/step - loss: 0.6482 - accuracy: 0.7201 - val_loss: 0.7872 - val_accuracy: 0.5909\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 2s 48ms/step - loss: 0.6564 - accuracy: 0.7268 - val_loss: 0.8398 - val_accuracy: 0.6818\n",
      "Score for fold 4: loss of 0.9216330647468567; accuracy of 60.855263471603394%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 2s 38ms/step - loss: 1.8375 - accuracy: 0.4431 - val_loss: 1.0707 - val_accuracy: 0.2727\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 1s 27ms/step - loss: 1.3379 - accuracy: 0.5356 - val_loss: 1.1327 - val_accuracy: 0.1818\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 1.2097 - accuracy: 0.5636 - val_loss: 1.1212 - val_accuracy: 0.1818\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 1.0451 - accuracy: 0.5925 - val_loss: 1.0969 - val_accuracy: 0.2273\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 1s 20ms/step - loss: 0.9818 - accuracy: 0.5949 - val_loss: 1.0579 - val_accuracy: 0.2273\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.9787 - accuracy: 0.6044 - val_loss: 1.0411 - val_accuracy: 0.3182\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.8957 - accuracy: 0.6115 - val_loss: 1.0438 - val_accuracy: 0.2727\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.8725 - accuracy: 0.6338 - val_loss: 1.0260 - val_accuracy: 0.2727\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.8332 - accuracy: 0.6490 - val_loss: 0.9927 - val_accuracy: 0.4091\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.7869 - accuracy: 0.6622 - val_loss: 0.9735 - val_accuracy: 0.4545\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.7869 - accuracy: 0.6627 - val_loss: 0.9418 - val_accuracy: 0.4091\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.7609 - accuracy: 0.6879 - val_loss: 0.9460 - val_accuracy: 0.5000\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.7131 - accuracy: 0.6902 - val_loss: 0.9196 - val_accuracy: 0.5455\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 0.7273 - accuracy: 0.6869 - val_loss: 0.8823 - val_accuracy: 0.5909\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.7050 - accuracy: 0.7120 - val_loss: 0.8830 - val_accuracy: 0.5909\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.6996 - accuracy: 0.6917 - val_loss: 0.8991 - val_accuracy: 0.6364\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.7175 - accuracy: 0.6860 - val_loss: 0.8499 - val_accuracy: 0.6364\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.6824 - accuracy: 0.7249 - val_loss: 0.8287 - val_accuracy: 0.6364\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.6662 - accuracy: 0.7087 - val_loss: 0.8280 - val_accuracy: 0.5455\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 1s 19ms/step - loss: 0.6509 - accuracy: 0.7230 - val_loss: 0.8736 - val_accuracy: 0.6364\n",
      "Score for fold 5: loss of 0.7170459628105164; accuracy of 72.03947305679321%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 2s 28ms/step - loss: 2.1381 - accuracy: 0.4492 - val_loss: 1.0181 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 2s 65ms/step - loss: 1.5982 - accuracy: 0.5370 - val_loss: 1.0152 - val_accuracy: 0.6364\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 1.2253 - accuracy: 0.5550 - val_loss: 1.0199 - val_accuracy: 0.5909\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 2s 62ms/step - loss: 1.0582 - accuracy: 0.5835 - val_loss: 1.0153 - val_accuracy: 0.5000\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 2s 65ms/step - loss: 0.9702 - accuracy: 0.5939 - val_loss: 1.0097 - val_accuracy: 0.5455\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 2s 59ms/step - loss: 0.8933 - accuracy: 0.6262 - val_loss: 0.9776 - val_accuracy: 0.6364\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 2s 55ms/step - loss: 0.8385 - accuracy: 0.6238 - val_loss: 0.9512 - val_accuracy: 0.6818\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.8069 - accuracy: 0.6485 - val_loss: 0.9165 - val_accuracy: 0.6818\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.7936 - accuracy: 0.6750 - val_loss: 0.9019 - val_accuracy: 0.6818\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.7556 - accuracy: 0.6627 - val_loss: 0.8683 - val_accuracy: 0.7273\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.7561 - accuracy: 0.6917 - val_loss: 0.8699 - val_accuracy: 0.5909\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 1s 32ms/step - loss: 0.7061 - accuracy: 0.6969 - val_loss: 0.8140 - val_accuracy: 0.6364\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.6910 - accuracy: 0.7049 - val_loss: 0.7836 - val_accuracy: 0.7273\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 1s 18ms/step - loss: 0.6792 - accuracy: 0.7073 - val_loss: 0.7707 - val_accuracy: 0.7273\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.6838 - accuracy: 0.7144 - val_loss: 0.7608 - val_accuracy: 0.6818\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.6773 - accuracy: 0.7168 - val_loss: 0.7418 - val_accuracy: 0.7273\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 2s 58ms/step - loss: 0.6301 - accuracy: 0.7386 - val_loss: 0.7583 - val_accuracy: 0.7727\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.6253 - accuracy: 0.7381 - val_loss: 0.8276 - val_accuracy: 0.7273\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 2s 60ms/step - loss: 0.6160 - accuracy: 0.7429 - val_loss: 0.7163 - val_accuracy: 0.7727\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 2s 60ms/step - loss: 0.6286 - accuracy: 0.7334 - val_loss: 0.7602 - val_accuracy: 0.7273\n",
      "Score for fold 6: loss of 0.7880212664604187; accuracy of 68.42105388641357%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 2.2018 - accuracy: 0.4668 - val_loss: 1.0615 - val_accuracy: 0.1818\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 2s 49ms/step - loss: 1.6835 - accuracy: 0.5304 - val_loss: 1.0530 - val_accuracy: 0.2273\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 2s 59ms/step - loss: 1.2892 - accuracy: 0.5441 - val_loss: 1.0440 - val_accuracy: 0.2727\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 2s 58ms/step - loss: 1.0905 - accuracy: 0.5773 - val_loss: 1.0849 - val_accuracy: 0.1818\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 2s 60ms/step - loss: 0.9977 - accuracy: 0.6029 - val_loss: 1.0486 - val_accuracy: 0.2273\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 2s 59ms/step - loss: 0.9536 - accuracy: 0.6105 - val_loss: 1.0498 - val_accuracy: 0.1818\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 2s 58ms/step - loss: 0.8903 - accuracy: 0.6077 - val_loss: 0.9949 - val_accuracy: 0.3182\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 2s 59ms/step - loss: 0.8417 - accuracy: 0.6404 - val_loss: 0.9784 - val_accuracy: 0.3182\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 2s 62ms/step - loss: 0.8061 - accuracy: 0.6542 - val_loss: 0.9347 - val_accuracy: 0.4091\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 2s 58ms/step - loss: 0.8015 - accuracy: 0.6622 - val_loss: 0.9249 - val_accuracy: 0.4091\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 2s 59ms/step - loss: 0.7778 - accuracy: 0.6717 - val_loss: 0.8828 - val_accuracy: 0.4545\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 2s 60ms/step - loss: 0.7559 - accuracy: 0.6689 - val_loss: 0.8640 - val_accuracy: 0.5455\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 2s 63ms/step - loss: 0.7756 - accuracy: 0.6750 - val_loss: 0.8194 - val_accuracy: 0.5000\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 2s 59ms/step - loss: 0.7404 - accuracy: 0.6945 - val_loss: 0.8206 - val_accuracy: 0.5455\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.7303 - accuracy: 0.6893 - val_loss: 0.7817 - val_accuracy: 0.5000\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 2s 60ms/step - loss: 0.7043 - accuracy: 0.7030 - val_loss: 0.7131 - val_accuracy: 0.6364\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 2s 59ms/step - loss: 0.6847 - accuracy: 0.7154 - val_loss: 0.6596 - val_accuracy: 0.7273\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 2s 58ms/step - loss: 0.6787 - accuracy: 0.7163 - val_loss: 0.6728 - val_accuracy: 0.5909\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 2s 60ms/step - loss: 0.6730 - accuracy: 0.7173 - val_loss: 0.7631 - val_accuracy: 0.5909\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 2s 62ms/step - loss: 0.6549 - accuracy: 0.7320 - val_loss: 0.6437 - val_accuracy: 0.6818\n",
      "Score for fold 7: loss of 0.768012523651123; accuracy of 67.43420958518982%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 21ms/step - loss: 1.9581 - accuracy: 0.4298 - val_loss: 0.9973 - val_accuracy: 0.5909\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 2s 60ms/step - loss: 1.4150 - accuracy: 0.5223 - val_loss: 1.0126 - val_accuracy: 0.5909\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 1.1767 - accuracy: 0.5541 - val_loss: 0.9768 - val_accuracy: 0.6818\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 2s 62ms/step - loss: 1.0915 - accuracy: 0.5617 - val_loss: 0.9716 - val_accuracy: 0.7273\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 2s 60ms/step - loss: 1.0030 - accuracy: 0.5849 - val_loss: 0.9587 - val_accuracy: 0.7273\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 2s 61ms/step - loss: 0.9242 - accuracy: 0.6210 - val_loss: 0.9397 - val_accuracy: 0.7273\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 2s 59ms/step - loss: 0.8894 - accuracy: 0.6224 - val_loss: 0.9068 - val_accuracy: 0.7727\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 2s 61ms/step - loss: 0.8257 - accuracy: 0.6556 - val_loss: 0.9038 - val_accuracy: 0.7727\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 2s 62ms/step - loss: 0.8008 - accuracy: 0.6580 - val_loss: 0.8714 - val_accuracy: 0.6818\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 2s 60ms/step - loss: 0.7950 - accuracy: 0.6717 - val_loss: 0.8437 - val_accuracy: 0.6818\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 2s 60ms/step - loss: 0.7502 - accuracy: 0.6798 - val_loss: 0.8354 - val_accuracy: 0.7727\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.7139 - accuracy: 0.6997 - val_loss: 0.8191 - val_accuracy: 0.7273\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.7355 - accuracy: 0.6765 - val_loss: 0.8143 - val_accuracy: 0.7273\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 1s 31ms/step - loss: 0.6941 - accuracy: 0.7021 - val_loss: 0.7637 - val_accuracy: 0.7727\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 2s 60ms/step - loss: 0.6648 - accuracy: 0.7111 - val_loss: 0.7614 - val_accuracy: 0.7727\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 2s 61ms/step - loss: 0.6440 - accuracy: 0.7301 - val_loss: 0.7821 - val_accuracy: 0.5455\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 2s 61ms/step - loss: 0.6700 - accuracy: 0.7296 - val_loss: 0.7637 - val_accuracy: 0.6364\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 2s 59ms/step - loss: 0.6352 - accuracy: 0.7258 - val_loss: 0.7351 - val_accuracy: 0.6818\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 1s 39ms/step - loss: 0.6668 - accuracy: 0.7106 - val_loss: 0.7243 - val_accuracy: 0.7273\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 1s 16ms/step - loss: 0.6250 - accuracy: 0.7348 - val_loss: 0.7959 - val_accuracy: 0.5909\n",
      "Score for fold 8: loss of 0.6930128931999207; accuracy of 76.31579041481018%\n"
     ]
    }
   ],
   "source": [
    "fold_no = 1\n",
    "acc_per_fold3 = []\n",
    "loss_per_fold3 = []\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "    model = Sequential()\n",
    "\n",
    "          \n",
    "    model.add(Conv2D(128, kernel_size = (3, 3)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(Dropout(0.01))\n",
    "\n",
    "    \n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "    \n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    history = model.fit(inputs[train],targets[train],epochs = 20,batch_size = 60, validation_split = 0.01)\n",
    "    scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold3.append(scores[1] * 100)\n",
    "    loss_per_fold3.append(scores[0])\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f2674bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 1.2707 - accuracy: 0.4789 - val_loss: 0.9908 - val_accuracy: 0.4545\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 3s 75ms/step - loss: 0.8131 - accuracy: 0.6678 - val_loss: 0.9058 - val_accuracy: 0.5909\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 2s 46ms/step - loss: 0.6963 - accuracy: 0.7262 - val_loss: 0.6198 - val_accuracy: 0.8636\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 2s 53ms/step - loss: 0.5854 - accuracy: 0.7945 - val_loss: 0.8290 - val_accuracy: 0.5455\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 2s 48ms/step - loss: 0.5105 - accuracy: 0.8215 - val_loss: 0.5867 - val_accuracy: 0.9091\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 2s 46ms/step - loss: 0.4339 - accuracy: 0.8576 - val_loss: 0.6283 - val_accuracy: 0.8182\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 2s 58ms/step - loss: 0.3917 - accuracy: 0.8685 - val_loss: 0.6457 - val_accuracy: 0.7273\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 3s 83ms/step - loss: 0.3211 - accuracy: 0.9046 - val_loss: 0.6218 - val_accuracy: 0.8182\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.3047 - accuracy: 0.9041 - val_loss: 0.5971 - val_accuracy: 0.8182\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 3s 81ms/step - loss: 0.2754 - accuracy: 0.9231 - val_loss: 0.6308 - val_accuracy: 0.8182\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 3s 79ms/step - loss: 0.2247 - accuracy: 0.9402 - val_loss: 0.6141 - val_accuracy: 0.8182\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.1808 - accuracy: 0.9540 - val_loss: 0.6699 - val_accuracy: 0.8636\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 2s 55ms/step - loss: 0.1585 - accuracy: 0.9644 - val_loss: 0.6798 - val_accuracy: 0.8636\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 2s 47ms/step - loss: 0.1357 - accuracy: 0.9696 - val_loss: 0.6587 - val_accuracy: 0.8182\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 2s 68ms/step - loss: 0.1304 - accuracy: 0.9715 - val_loss: 0.6700 - val_accuracy: 0.8182\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.1234 - accuracy: 0.9706 - val_loss: 0.7853 - val_accuracy: 0.7727\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 3s 76ms/step - loss: 0.1049 - accuracy: 0.9772 - val_loss: 0.7380 - val_accuracy: 0.8182\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 2s 49ms/step - loss: 0.0924 - accuracy: 0.9805 - val_loss: 0.6254 - val_accuracy: 0.8636\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 0.0883 - accuracy: 0.9810 - val_loss: 0.7237 - val_accuracy: 0.8636\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 0.0834 - accuracy: 0.9839 - val_loss: 0.8936 - val_accuracy: 0.8182\n",
      "Score for fold 1: loss of 1.0181632041931152; accuracy of 67.86885261535645%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 1.0663 - accuracy: 0.4998 - val_loss: 0.8381 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 3s 73ms/step - loss: 0.8364 - accuracy: 0.6331 - val_loss: 0.7453 - val_accuracy: 0.6364\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 3s 83ms/step - loss: 0.6923 - accuracy: 0.7190 - val_loss: 0.6218 - val_accuracy: 0.6818\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 3s 74ms/step - loss: 0.5787 - accuracy: 0.7803 - val_loss: 0.6617 - val_accuracy: 0.6364\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 3s 79ms/step - loss: 0.4806 - accuracy: 0.8367 - val_loss: 0.7237 - val_accuracy: 0.6818\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 3s 79ms/step - loss: 0.4081 - accuracy: 0.8690 - val_loss: 0.6169 - val_accuracy: 0.7273\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 3s 79ms/step - loss: 0.3346 - accuracy: 0.9051 - val_loss: 0.6294 - val_accuracy: 0.6818\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.2980 - accuracy: 0.9008 - val_loss: 0.4513 - val_accuracy: 0.8636\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 3s 82ms/step - loss: 0.2474 - accuracy: 0.9231 - val_loss: 0.4628 - val_accuracy: 0.8182\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 4s 107ms/step - loss: 0.1985 - accuracy: 0.9554 - val_loss: 0.6942 - val_accuracy: 0.6818\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.1869 - accuracy: 0.9535 - val_loss: 0.5234 - val_accuracy: 0.7727\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.1602 - accuracy: 0.9592 - val_loss: 0.5713 - val_accuracy: 0.6364\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.1388 - accuracy: 0.9644 - val_loss: 0.5688 - val_accuracy: 0.6364\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 3s 81ms/step - loss: 0.1121 - accuracy: 0.9758 - val_loss: 0.5111 - val_accuracy: 0.7727\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 3s 80ms/step - loss: 0.1020 - accuracy: 0.9744 - val_loss: 0.4489 - val_accuracy: 0.7727\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.1035 - accuracy: 0.9791 - val_loss: 0.4507 - val_accuracy: 0.7727\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 2s 66ms/step - loss: 0.0926 - accuracy: 0.9753 - val_loss: 0.5734 - val_accuracy: 0.7273\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.0781 - accuracy: 0.9805 - val_loss: 0.4456 - val_accuracy: 0.8182\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.1058 - accuracy: 0.9744 - val_loss: 0.7750 - val_accuracy: 0.6364\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 3s 96ms/step - loss: 0.0827 - accuracy: 0.9767 - val_loss: 0.3929 - val_accuracy: 0.7273\n",
      "Score for fold 2: loss of 0.8625652194023132; accuracy of 74.75410103797913%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 4s 83ms/step - loss: 1.1711 - accuracy: 0.4715 - val_loss: 0.8098 - val_accuracy: 0.6364\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 3s 76ms/step - loss: 0.7950 - accuracy: 0.6812 - val_loss: 0.8503 - val_accuracy: 0.6364\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 2s 54ms/step - loss: 0.6661 - accuracy: 0.7263 - val_loss: 0.7758 - val_accuracy: 0.7273\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.5736 - accuracy: 0.7936 - val_loss: 0.8624 - val_accuracy: 0.6364\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.4865 - accuracy: 0.8340 - val_loss: 1.0890 - val_accuracy: 0.5000\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 3s 79ms/step - loss: 0.4504 - accuracy: 0.8515 - val_loss: 0.7414 - val_accuracy: 0.7727\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 3s 83ms/step - loss: 0.3753 - accuracy: 0.8786 - val_loss: 0.7153 - val_accuracy: 0.7273\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 3s 83ms/step - loss: 0.3270 - accuracy: 0.8985 - val_loss: 0.7763 - val_accuracy: 0.6818\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.2809 - accuracy: 0.9208 - val_loss: 0.7187 - val_accuracy: 0.7727\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.2546 - accuracy: 0.9260 - val_loss: 0.7228 - val_accuracy: 0.8182\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.2090 - accuracy: 0.9488 - val_loss: 0.7437 - val_accuracy: 0.7727\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.1865 - accuracy: 0.9492 - val_loss: 0.6970 - val_accuracy: 0.7727\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 3s 96ms/step - loss: 0.1554 - accuracy: 0.9654 - val_loss: 0.7485 - val_accuracy: 0.8182\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 3s 81ms/step - loss: 0.1391 - accuracy: 0.9663 - val_loss: 0.7137 - val_accuracy: 0.8182\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 2s 53ms/step - loss: 0.1217 - accuracy: 0.9730 - val_loss: 0.7335 - val_accuracy: 0.9091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "36/36 [==============================] - 2s 42ms/step - loss: 0.1143 - accuracy: 0.9720 - val_loss: 0.6819 - val_accuracy: 0.9091\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 2s 46ms/step - loss: 0.1219 - accuracy: 0.9768 - val_loss: 0.8308 - val_accuracy: 0.5909\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.0975 - accuracy: 0.9787 - val_loss: 0.6859 - val_accuracy: 0.9091\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 2s 42ms/step - loss: 0.0913 - accuracy: 0.9824 - val_loss: 0.9271 - val_accuracy: 0.5909\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 0.0845 - accuracy: 0.9839 - val_loss: 0.7448 - val_accuracy: 0.7727\n",
      "Score for fold 3: loss of 0.7663928270339966; accuracy of 76.97368264198303%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 4s 80ms/step - loss: 1.5178 - accuracy: 0.4246 - val_loss: 0.9939 - val_accuracy: 0.4091\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.8225 - accuracy: 0.6499 - val_loss: 0.8003 - val_accuracy: 0.6364\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.6954 - accuracy: 0.7215 - val_loss: 0.7440 - val_accuracy: 0.7273\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 3s 80ms/step - loss: 0.5762 - accuracy: 0.7870 - val_loss: 0.8037 - val_accuracy: 0.6364\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 3s 81ms/step - loss: 0.5063 - accuracy: 0.8183 - val_loss: 0.8336 - val_accuracy: 0.6364\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.4283 - accuracy: 0.8695 - val_loss: 0.7741 - val_accuracy: 0.7273\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.3880 - accuracy: 0.8762 - val_loss: 0.8507 - val_accuracy: 0.6818\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.3385 - accuracy: 0.8999 - val_loss: 0.7847 - val_accuracy: 0.7727\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.2926 - accuracy: 0.9170 - val_loss: 0.7648 - val_accuracy: 0.7727\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.2516 - accuracy: 0.9312 - val_loss: 0.7177 - val_accuracy: 0.8636\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.2385 - accuracy: 0.9374 - val_loss: 0.8921 - val_accuracy: 0.5909\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.2078 - accuracy: 0.9440 - val_loss: 0.7841 - val_accuracy: 0.7727\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 3s 81ms/step - loss: 0.1836 - accuracy: 0.9549 - val_loss: 0.9532 - val_accuracy: 0.6364\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 2s 64ms/step - loss: 0.1636 - accuracy: 0.9597 - val_loss: 0.9202 - val_accuracy: 0.5909\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 2s 58ms/step - loss: 0.1465 - accuracy: 0.9578 - val_loss: 0.9496 - val_accuracy: 0.7273\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 2s 48ms/step - loss: 0.1592 - accuracy: 0.9602 - val_loss: 0.7586 - val_accuracy: 0.9091\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 2s 47ms/step - loss: 0.1191 - accuracy: 0.9763 - val_loss: 0.7380 - val_accuracy: 0.9545\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 3s 71ms/step - loss: 0.1072 - accuracy: 0.9791 - val_loss: 0.8957 - val_accuracy: 0.6364\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 3s 93ms/step - loss: 0.1046 - accuracy: 0.9749 - val_loss: 0.7816 - val_accuracy: 0.8182\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.0929 - accuracy: 0.9787 - val_loss: 1.0020 - val_accuracy: 0.6364\n",
      "Score for fold 4: loss of 1.0080513954162598; accuracy of 71.38158082962036%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 3s 81ms/step - loss: 1.1669 - accuracy: 0.4957 - val_loss: 0.9071 - val_accuracy: 0.4545\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.7851 - accuracy: 0.6717 - val_loss: 0.8133 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 3s 70ms/step - loss: 0.6444 - accuracy: 0.7543 - val_loss: 0.9052 - val_accuracy: 0.5909\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.5661 - accuracy: 0.7941 - val_loss: 0.5980 - val_accuracy: 0.8182\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 2s 47ms/step - loss: 0.4975 - accuracy: 0.8145 - val_loss: 0.7329 - val_accuracy: 0.6364\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 3s 78ms/step - loss: 0.4218 - accuracy: 0.8582 - val_loss: 0.5807 - val_accuracy: 0.8182\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.3768 - accuracy: 0.8691 - val_loss: 0.8769 - val_accuracy: 0.6818\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 3s 90ms/step - loss: 0.3219 - accuracy: 0.8990 - val_loss: 0.5374 - val_accuracy: 0.7727\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.2557 - accuracy: 0.9298 - val_loss: 0.6666 - val_accuracy: 0.7727\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 4s 101ms/step - loss: 0.2203 - accuracy: 0.9369 - val_loss: 0.6000 - val_accuracy: 0.8636\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 4s 99ms/step - loss: 0.1965 - accuracy: 0.9488 - val_loss: 0.6797 - val_accuracy: 0.7727\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 3s 96ms/step - loss: 0.1758 - accuracy: 0.9602 - val_loss: 0.5977 - val_accuracy: 0.8182\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 3s 77ms/step - loss: 0.1654 - accuracy: 0.9568 - val_loss: 0.6131 - val_accuracy: 0.7727\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.1406 - accuracy: 0.9658 - val_loss: 0.7956 - val_accuracy: 0.6818 0s - loss: 0.1330 - \n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.1200 - accuracy: 0.9749 - val_loss: 0.8069 - val_accuracy: 0.7273\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 3s 79ms/step - loss: 0.1314 - accuracy: 0.9696 - val_loss: 0.6356 - val_accuracy: 0.8182\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.0997 - accuracy: 0.9777 - val_loss: 0.8450 - val_accuracy: 0.7273\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 2s 51ms/step - loss: 0.0928 - accuracy: 0.9777 - val_loss: 0.8335 - val_accuracy: 0.7727\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 2s 57ms/step - loss: 0.0955 - accuracy: 0.9787 - val_loss: 0.6557 - val_accuracy: 0.8636\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 2s 45ms/step - loss: 0.0880 - accuracy: 0.9810 - val_loss: 0.7398 - val_accuracy: 0.7727\n",
      "Score for fold 5: loss of 0.8634293079376221; accuracy of 74.67105388641357%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 4s 95ms/step - loss: 1.4828 - accuracy: 0.4559 - val_loss: 0.8065 - val_accuracy: 0.6818\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 3s 83ms/step - loss: 0.8220 - accuracy: 0.6404 - val_loss: 0.7804 - val_accuracy: 0.6364\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.7019 - accuracy: 0.7201 - val_loss: 0.6255 - val_accuracy: 0.8636\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 3s 92ms/step - loss: 0.6081 - accuracy: 0.7581 - val_loss: 0.9199 - val_accuracy: 0.5455\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.5296 - accuracy: 0.8126 - val_loss: 0.7864 - val_accuracy: 0.6364\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.4469 - accuracy: 0.8544 - val_loss: 0.8326 - val_accuracy: 0.6364\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 2s 49ms/step - loss: 0.3988 - accuracy: 0.8691 - val_loss: 0.7231 - val_accuracy: 0.7727\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 2s 48ms/step - loss: 0.3494 - accuracy: 0.8966 - val_loss: 1.0196 - val_accuracy: 0.6364\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 2s 46ms/step - loss: 0.3032 - accuracy: 0.9113 - val_loss: 0.8350 - val_accuracy: 0.7273\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 2s 44ms/step - loss: 0.2543 - accuracy: 0.9369 - val_loss: 0.8550 - val_accuracy: 0.6818\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 0.2438 - accuracy: 0.9312 - val_loss: 0.9189 - val_accuracy: 0.6364\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 1s 39ms/step - loss: 0.2282 - accuracy: 0.9288 - val_loss: 1.0941 - val_accuracy: 0.6818\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 2s 44ms/step - loss: 0.1954 - accuracy: 0.9511 - val_loss: 0.6759 - val_accuracy: 0.7727\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 2s 50ms/step - loss: 0.1736 - accuracy: 0.9502 - val_loss: 0.7658 - val_accuracy: 0.7727\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 2s 48ms/step - loss: 0.1584 - accuracy: 0.9611 - val_loss: 1.0081 - val_accuracy: 0.6364ss: 0.1522 - ac\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 3s 75ms/step - loss: 0.1285 - accuracy: 0.9734 - val_loss: 0.7183 - val_accuracy: 0.7727\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 3s 81ms/step - loss: 0.1256 - accuracy: 0.9725 - val_loss: 0.8328 - val_accuracy: 0.7727\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 3s 83ms/step - loss: 0.1095 - accuracy: 0.9730 - val_loss: 0.9734 - val_accuracy: 0.6818\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 3s 83ms/step - loss: 0.1187 - accuracy: 0.9706 - val_loss: 0.9436 - val_accuracy: 0.8182\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 2s 53ms/step - loss: 0.0937 - accuracy: 0.9791 - val_loss: 0.9391 - val_accuracy: 0.6818\n",
      "Score for fold 6: loss of 1.0580333471298218; accuracy of 67.43420958518982%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 4s 87ms/step - loss: 1.1086 - accuracy: 0.5066 - val_loss: 0.8939 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 3s 81ms/step - loss: 0.7783 - accuracy: 0.6907 - val_loss: 0.7518 - val_accuracy: 0.7273\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 3s 80ms/step - loss: 0.6768 - accuracy: 0.7306 - val_loss: 0.7805 - val_accuracy: 0.6818\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 3s 80ms/step - loss: 0.5999 - accuracy: 0.7704 - val_loss: 0.7408 - val_accuracy: 0.6818\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 3s 73ms/step - loss: 0.5340 - accuracy: 0.8112 - val_loss: 0.7112 - val_accuracy: 0.7727\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 3s 73ms/step - loss: 0.4486 - accuracy: 0.8515 - val_loss: 0.6256 - val_accuracy: 0.8636\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 2s 45ms/step - loss: 0.3947 - accuracy: 0.8643 - val_loss: 0.6012 - val_accuracy: 0.9091\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 0.3359 - accuracy: 0.9065 - val_loss: 0.6366 - val_accuracy: 0.8636\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 1s 41ms/step - loss: 0.2919 - accuracy: 0.9203 - val_loss: 0.6850 - val_accuracy: 0.7727\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 2s 45ms/step - loss: 0.2485 - accuracy: 0.9388 - val_loss: 0.6391 - val_accuracy: 0.8182\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 2s 54ms/step - loss: 0.2177 - accuracy: 0.9417 - val_loss: 0.6153 - val_accuracy: 0.8636\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 2s 70ms/step - loss: 0.1828 - accuracy: 0.9559 - val_loss: 0.7206 - val_accuracy: 0.7727\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 3s 84ms/step - loss: 0.1802 - accuracy: 0.9511 - val_loss: 0.7196 - val_accuracy: 0.7727\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 3s 79ms/step - loss: 0.1322 - accuracy: 0.9673 - val_loss: 0.6401 - val_accuracy: 0.8182\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 2s 67ms/step - loss: 0.1356 - accuracy: 0.9668 - val_loss: 0.7933 - val_accuracy: 0.7727\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 1s 40ms/step - loss: 0.1186 - accuracy: 0.9720 - val_loss: 0.6555 - val_accuracy: 0.8182\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 2s 46ms/step - loss: 0.1090 - accuracy: 0.9730 - val_loss: 0.8641 - val_accuracy: 0.8182\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 2s 47ms/step - loss: 0.1012 - accuracy: 0.9772 - val_loss: 0.5887 - val_accuracy: 0.8636\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 2s 46ms/step - loss: 0.0961 - accuracy: 0.9787 - val_loss: 0.6667 - val_accuracy: 0.8636\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 2s 43ms/step - loss: 0.0796 - accuracy: 0.9815 - val_loss: 0.6672 - val_accuracy: 0.8636\n",
      "Score for fold 7: loss of 0.9782873392105103; accuracy of 72.36841917037964%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 3s 76ms/step - loss: 1.6864 - accuracy: 0.4284 - val_loss: 0.7521 - val_accuracy: 0.5455\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 3s 89ms/step - loss: 0.8648 - accuracy: 0.6086 - val_loss: 0.6300 - val_accuracy: 0.8182\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 3s 91ms/step - loss: 0.7509 - accuracy: 0.6784 - val_loss: 0.6582 - val_accuracy: 0.8182\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 4s 97ms/step - loss: 0.6964 - accuracy: 0.7244 - val_loss: 0.7134 - val_accuracy: 0.7727\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.5743 - accuracy: 0.7751 - val_loss: 0.6672 - val_accuracy: 0.7273\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 3s 78ms/step - loss: 0.5281 - accuracy: 0.8131 - val_loss: 0.6841 - val_accuracy: 0.7727\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 2s 52ms/step - loss: 0.4646 - accuracy: 0.8487 - val_loss: 0.7344 - val_accuracy: 0.7273\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 2s 46ms/step - loss: 0.4338 - accuracy: 0.8520 - val_loss: 0.6095 - val_accuracy: 0.8636\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 2s 61ms/step - loss: 0.4024 - accuracy: 0.8686 - val_loss: 0.8517 - val_accuracy: 0.6818\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 3s 83ms/step - loss: 0.3437 - accuracy: 0.8952 - val_loss: 0.6504 - val_accuracy: 0.7273\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 2s 52ms/step - loss: 0.3225 - accuracy: 0.8994 - val_loss: 0.6800 - val_accuracy: 0.7273\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 2s 48ms/step - loss: 0.2882 - accuracy: 0.9213 - val_loss: 0.8733 - val_accuracy: 0.6818\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 2s 56ms/step - loss: 0.2639 - accuracy: 0.9217 - val_loss: 0.7137 - val_accuracy: 0.7273\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 2s 62ms/step - loss: 0.2291 - accuracy: 0.9402 - val_loss: 0.8167 - val_accuracy: 0.7273\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 2s 58ms/step - loss: 0.2112 - accuracy: 0.9426 - val_loss: 0.7400 - val_accuracy: 0.6818\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 2s 48ms/step - loss: 0.1946 - accuracy: 0.9478 - val_loss: 0.7418 - val_accuracy: 0.7273\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 2s 45ms/step - loss: 0.1744 - accuracy: 0.9597 - val_loss: 0.8186 - val_accuracy: 0.6364\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 2s 46ms/step - loss: 0.1652 - accuracy: 0.9597 - val_loss: 0.6478 - val_accuracy: 0.7727\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 2s 49ms/step - loss: 0.1609 - accuracy: 0.9526 - val_loss: 0.6418 - val_accuracy: 0.7273\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 2s 49ms/step - loss: 0.1549 - accuracy: 0.9573 - val_loss: 0.9301 - val_accuracy: 0.7273\n",
      "Score for fold 8: loss of 0.776526927947998; accuracy of 78.28947305679321%\n"
     ]
    }
   ],
   "source": [
    "fold_no = 1\n",
    "acc_per_fold4 = []\n",
    "loss_per_fold4 = []\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "    model = Sequential()\n",
    "\n",
    "        \n",
    "          \n",
    "\n",
    "    model.add(Conv2D(64, kernel_size = (3, 3)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.01))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    history = model.fit(inputs[train],targets[train],epochs = 20,batch_size = 60, validation_split = 0.01)\n",
    "    scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold4.append(scores[1] * 100)\n",
    "    loss_per_fold4.append(scores[0])\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0dc34844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [acc_per_fold1,acc_per_fold2,acc_per_fold3,acc_per_fold4]\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    " \n",
    "# Creating plot\n",
    "plt.boxplot(data)\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 100)\n",
    "plt.savefig('4_models.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "65db1b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "37/37 [==============================] - 6s 162ms/step - loss: 1.0583 - accuracy: 0.4400 - val_loss: 0.8906 - val_accuracy: 0.5455\n",
      "Epoch 2/25\n",
      "37/37 [==============================] - 6s 157ms/step - loss: 0.8328 - accuracy: 0.6292 - val_loss: 0.9987 - val_accuracy: 0.4545\n",
      "Epoch 3/25\n",
      "37/37 [==============================] - 6s 165ms/step - loss: 0.7524 - accuracy: 0.6887 - val_loss: 0.6623 - val_accuracy: 0.8182\n",
      "Epoch 4/25\n",
      "37/37 [==============================] - 6s 159ms/step - loss: 0.6788 - accuracy: 0.7279 - val_loss: 0.6404 - val_accuracy: 0.8636\n",
      "Epoch 5/25\n",
      "37/37 [==============================] - 6s 160ms/step - loss: 0.6316 - accuracy: 0.7542 - val_loss: 0.6200 - val_accuracy: 0.9091\n",
      "Epoch 6/25\n",
      "37/37 [==============================] - 6s 172ms/step - loss: 0.5859 - accuracy: 0.7708 - val_loss: 0.6871 - val_accuracy: 0.8182\n",
      "Epoch 7/25\n",
      "37/37 [==============================] - 6s 172ms/step - loss: 0.5499 - accuracy: 0.7855 - val_loss: 0.9563 - val_accuracy: 0.5000\n",
      "Epoch 8/25\n",
      "37/37 [==============================] - 7s 180ms/step - loss: 0.5508 - accuracy: 0.7878 - val_loss: 0.7329 - val_accuracy: 0.7727\n",
      "Epoch 9/25\n",
      "37/37 [==============================] - 7s 188ms/step - loss: 0.4679 - accuracy: 0.8100 - val_loss: 0.7117 - val_accuracy: 0.8182\n",
      "Epoch 10/25\n",
      "37/37 [==============================] - 7s 194ms/step - loss: 0.4097 - accuracy: 0.8450 - val_loss: 0.7801 - val_accuracy: 0.8182\n",
      "Epoch 11/25\n",
      "37/37 [==============================] - 7s 180ms/step - loss: 0.3646 - accuracy: 0.8667 - val_loss: 0.8536 - val_accuracy: 0.7727\n",
      "Epoch 12/25\n",
      "37/37 [==============================] - 7s 176ms/step - loss: 0.3384 - accuracy: 0.8768 - val_loss: 1.0575 - val_accuracy: 0.7727\n",
      "Epoch 13/25\n",
      "37/37 [==============================] - 6s 176ms/step - loss: 0.2982 - accuracy: 0.8861 - val_loss: 0.9642 - val_accuracy: 0.7273\n",
      "Epoch 14/25\n",
      "37/37 [==============================] - 6s 164ms/step - loss: 0.2817 - accuracy: 0.8999 - val_loss: 0.9624 - val_accuracy: 0.6818\n",
      "Epoch 15/25\n",
      "37/37 [==============================] - 6s 162ms/step - loss: 0.2361 - accuracy: 0.9151 - val_loss: 1.0277 - val_accuracy: 0.6818\n",
      "Epoch 16/25\n",
      "37/37 [==============================] - 6s 169ms/step - loss: 0.2095 - accuracy: 0.9257 - val_loss: 1.0909 - val_accuracy: 0.8182\n",
      "Epoch 17/25\n",
      "37/37 [==============================] - 6s 165ms/step - loss: 0.2024 - accuracy: 0.9271 - val_loss: 1.2289 - val_accuracy: 0.6818\n",
      "Epoch 18/25\n",
      "37/37 [==============================] - 6s 165ms/step - loss: 0.1808 - accuracy: 0.9350 - val_loss: 1.1803 - val_accuracy: 0.7727\n",
      "Epoch 19/25\n",
      "37/37 [==============================] - 6s 163ms/step - loss: 0.1387 - accuracy: 0.9530 - val_loss: 1.4038 - val_accuracy: 0.7727\n",
      "Epoch 20/25\n",
      "37/37 [==============================] - 6s 172ms/step - loss: 0.1203 - accuracy: 0.9645 - val_loss: 1.4608 - val_accuracy: 0.7727\n",
      "Epoch 21/25\n",
      "37/37 [==============================] - 7s 183ms/step - loss: 0.0975 - accuracy: 0.9714 - val_loss: 1.4900 - val_accuracy: 0.7727\n",
      "Epoch 22/25\n",
      "37/37 [==============================] - 7s 179ms/step - loss: 0.0804 - accuracy: 0.9797 - val_loss: 1.6789 - val_accuracy: 0.5909\n",
      "Epoch 23/25\n",
      "37/37 [==============================] - 7s 187ms/step - loss: 0.1041 - accuracy: 0.9677 - val_loss: 2.4972 - val_accuracy: 0.5455\n",
      "Epoch 24/25\n",
      "37/37 [==============================] - 6s 174ms/step - loss: 0.1920 - accuracy: 0.9262 - val_loss: 2.2450 - val_accuracy: 0.6364\n",
      "Epoch 25/25\n",
      "37/37 [==============================] - 6s 168ms/step - loss: 0.1150 - accuracy: 0.9613 - val_loss: 2.0763 - val_accuracy: 0.5909\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "        \n",
    "model.add(Conv2D(128, kernel_size = (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer = 'adam', metrics = ['accuracy'])\n",
    "history = model.fit(X_train,y_train,epochs = 25,batch_size = 60, validation_split = 0.01)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "a66b3bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEXCAYAAABGeIg9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABDXElEQVR4nO3dd3hUZfr/8ff09N4TeodQQ5ciICAmgCIKuCsgimX5yq7uooggv0VgWXR117ar6K6rsgKCVJEiCCJNCDXUIAkQQia9J5Mp5/dHIBoSQiCZTJK5X9fFxcw5Z+bcDxPymVOe51EpiqIghBBC/Ira0QUIIYSofyQchBBCVCDhIIQQogIJByGEEBVIOAghhKhAwkEIIUQFEg5C3IVnnnmGr7/+usptDh48SExMTLWXC1GfSDgIIYSoQOvoAoSwt4MHD/LWW28RFBREfHw8rq6uPP/883z++eckJCQwYsQI5syZA8DKlSv5/PPPUavVBAQEMG/ePFq0aIHRaGT27NmkpqYSFhZGRkZG2fv//PPPLFq0iOzsbKxWK48//jjjx4+vVm15eXn8+c9/5uzZs6hUKgYOHMiLL76IVqvlnXfeYfv27eh0Onx9ffnLX/5CUFDQLZcLUasUIRq5AwcOKB06dFBOnTqlKIqiPPnkk8qECRMUk8mkZGRkKJ06dVJSUlKUffv2Kffdd5+SkZGhKIqirFmzRhk1apRis9mU3/3ud8rbb7+tKIqiJCYmKt26dVPWrFmjmM1m5YEHHlDi4uIURVGU3NxcZdSoUcrRo0eVAwcOKNHR0ZXWc2P5Sy+9pLz++uuKzWZTTCaTMm3aNOXDDz9UkpOTlR49eigmk0lRFEX55JNPlO3bt99yuRC1TY4chFOIiIigY8eOADRt2hRPT0/0ej1+fn64u7uTk5PDnj17eOCBB/Dz8wNg3LhxLFq0iKSkJPbt28fLL78MQLNmzejTpw8AiYmJXL58uezIA6C4uJjTp0/TqlWr29b1ww8/8OWXX6JSqdDr9UycOJH//ve/PPXUU7Rv356HHnqIQYMGMWjQIPr164fNZqt0uRC1TcJBOAW9Xl/uuVZb8UdfqWSYMUVRsFgsqFSqcutvvN5qteLl5cX69evL1qWnp+Pp6cmxY8duW5fNZqvw3GKxoFar+eKLLzh58iT79+9n8eLF9OnTh7lz595yuRC1SS5IC3HdgAED2Lx5M5mZmQCsWbMGHx8fmjVrxsCBA1m5ciUAycnJHDx4EIAWLVpgMBjKwuHatWvExMQQFxdX7X0uX74cRVEoKSlh1apV9O/fn7NnzxITE0OrVq145plnmDp1KufOnbvlciFqmxw5CHHdPffcw9SpU5kyZQo2mw0/Pz8+/PBD1Go18+fP55VXXmHUqFGEhITQvn17oPSI5IMPPmDRokV8/PHHWCwWfv/73xMVFVUWIFWZO3cuCxcuZPTo0ZjNZgYOHMizzz6LXq9n1KhRPPzww7i5ueHi4sLcuXNp3759pcuFqG0qpbJjaSGEEE5NTisJIYSoQMJBCCFEBRIOQgghKpBwEEIIUUGDvFvJZrNRUFCATqdDpVI5uhwhhGgQFEXBbDbj7u6OWl31sUGDDIeCggLOnz/v6DKEEKJBatu2LZ6enlVu0yDDQafTAaUNvLnna3XExcURGRlZ22U1GM7cfmduOzh3+6XtkZSUlHD+/Pmy36FVaZDhcONUkl6vx2Aw3NV73O3rGgtnbr8ztx2cu/3S9lLVOR0vF6SFEEJUIOEghBCiggZ5WqkqNpuNpKQkCgoKbrmNVqvlzJkzdVhV/fLr9ru7uxMREXHbOxeEEM7FruHw3nvv8e233wIwePBgXnrppQrr16xZg5eXFwCPPvoov/nNb2q0z/T0dFQqFe3atbvlL7yCggLc3d1rtJ+G7Eb7bTYbV69eJT09XWYSE0KUY7dw2LdvHz/++CNr165FpVLx1FNPsX37doYPH162TVxcHG+99Rbdu3evtf1mZ2fTvHlz+SZcDWq1muDgYC5duiThIIQox27hEBgYyOzZs8tuNW3VqhXJycnltomLi2PZsmVcuXKFXr168fLLL9f4bgKr1Vqt27REKZ1Oh8VicXQZQoh6xm5fr9u0aUO3bt2A0qkUN2/ezODBg8vWFxQU0KFDB15++WXWrl1Lbm4uH3zwQa3sW3pNV5/8WwlRO/LP7OPy+7/Dkp/l6FJqhd3nc4iPj+eZZ57h+eef56GHHrrldqdPn2bOnDmsW7futu9pMpluOdOWVquldevWd1turcrLy2P+/Pm89dZb1dr+9OnTrF69mtdee83OlZV34cIFOXoQoobcTm7CcPUEptBOFHYd6+hyqhQZGXnbszR2vSAdGxvLzJkzmTNnDtHR0eXWJScns2/fPsaPHw+UjvlR2by+VamsgWfOnLntxea6uiCdlZVFfHx8tffVq1cvevXqZeeqKrZfr9fTtWtXu++3PoiNjSUqKsrRZTiMM7ff3m1POvolJSo1hmunaD70EVybd7bbvu7UjbZX9cX6ZnY7rXTt2jVmzJjBm2++WSEYAFxcXHjjjTe4cuUKiqKwfPnycherG4OFCxeSmprKjBkzuP/++5k0aRJTp04lPz+fmTNnMmHCBIYMGcKsWbNQFIWDBw/y+OOPA/D444+zdOlSJkyYwPDhw9m9e7eDWyOEuBXFaqYk7QpePe9H6xNM+paPUCxmR5dVI3Y7cvjkk08wmUwsWbKkbNnEiRPZuXMnM2fOpHPnzixYsIDnnnsOs9lMjx49eOKJJ2q1hp2HL7P9p8sVllutVjQaTY3ee3jvpgzt2bTKbebOncvkyZN55ZVXGDZsGB9//DERERFs2rSJDh068M4771BSUkJ0dDSnTp2q8Hqz2czKlSvZuXMn//jHP8pdsxFC1B8laUlgs+AS3g63Vj1IWbGQ7APr8R0w3tGl3TW7hcPcuXMrnfh80qRJZY9HjhzJyJEj7VVCveLv709ERAQAMTExnDhxgk8//ZSLFy+SnZ1NYWFhhdcMHDgQKL24n52dXZflCiHuQIkxAQB9SAv0/uG4t+9H9t41eHQagM43xMHV3Z1G10P614b2rPzbvSM6wbm4uJQ9/vzzz9m6dSuPPvoo/fv35/z581R2X8CN6ylyR5EQ9ZvJmIBKZygLAv/hT1B48SjpWz4mZOKrDfL/sPQUsyOtVlvpXUB79+5lwoQJjBkzBpVKxdmzZ7HZbA6oUAhRG0qMieiDmqNSl56u1nr54zd4EkUXj1Jw9oCDq7s7Eg525O/vT1hYGK+88kq55VOmTOG9997joYce4s9//jPdu3cnKSnJQVUKIWpCUWyYjIkYgpuXW+7VcxT64BZkbPs3NlORY4qrgUZ9WsnRdDodK1asqLC8X79+bN26tdLX9OnTByg99XRDREQEO3futE+RQogasWSnopgK0Ye0KLdcpdYQMOppkj+dQ+YPKwgYXrs33NibHDkIIUQNmG5cjA5uUWGdS3hbPLsPJ/fQZkwpCXVdWo1IOAghRA2UpCSCSo0+sEml6/2G/Aa1qwfp336IojSca4sSDkIIUQMlxgR0AeGodZUPR6Fx9cD/vimYkuPJO/pdHVd39yQchBCiBkzGBAyVnFL6NY/Iwbg060Tm919gLcipo8pqRsJBCCHukrUgB2teZqXXG35NpVIRcP/T2EpMZOz4rI6qqxkJByGEuEsmYyIAhpCqwwFAHxCBT98x5J/cRdGl6g1+50gSDkIIcZfKhs24qY/DrfgMGI/WJ4j0bz9CsdbvgfkkHOqJ2bNn8/XXX2M0Gpk+fXql27Rr167K97hy5Qpz5syxR3lCiEqYjAlovQLQuHpWa3u1zkDAyKcwZ1wl+8AGO1dXMxIO9UxwcDDLli27q9cmJydz5cqVWq5ICHErJSkJt73ecDO31lG4t+9L9o+rMWcb7VRZzTXqHtJ5J3aRd7xiz2Kr1UpODYfs9uw6FM8u91a5zf/93/8RExPD/fffD8C4ceOYPXs2b7/9NsXFxeTk5DBr1ixGjRpV9pqkpCQmT57Mzp07SUpKYtasWRQWFpabjMdoNDJnzhzy8vJIS0sjOjqaP/3pTyxcuJCkpCT+/Oc/M3/+fD766CO+/fZbrFYrAwYMYNasWQ1yADAh6iNbSTHmjGTcO95zx6/1Hz6NwovHSgfmmzCnXv6/lCMHOxo7diybN28GSufRNplMfPHFFyxcuJC1a9eyaNGiKufNfv311xk3bhzr16+nR48eZcs3bdpETEwMq1atYsOGDfzvf/8jMzOTuXPnEhkZyfz58/nhhx+Ii4tj9erVrFu3DqPRyIYN9fswVoiGpCTtMqBUGFOpOrRe/vgOmkjRz0coOFc/B+Zr1EcOnl3urfTbfV0N2T148GBef/118vPz2bRpE6NHj+aJJ57g+++/Z8uWLRw/fpyCgoJbvv6nn37ib3/7GwBjxowpmx/jySef5MCBA3zyySfEx8djNpspKio/sNf+/fs5ceIE48aNA6C4uJiwsDA7tVQI51OS8sscDnfDu9cD5J/cTfqmD9D5ht5VyNiTHDnYkV6v595772Xnzp1s2bKF0aNH89hjj3HixAkiIyN59tlnb/seN+Z5UKlUZYeeS5Ys4fPPPycsLIznnnsOX1/fCvNBWK1WpkyZwvr161m/fj1fffVVtfYnhKgekzEBtYsHWq/Au3q9Sq0h5JGXUeldSPnydcxZKbVcYc1IONjZ2LFj+c9//oO3tzfu7u4kJiby+9//nsGDB7N3716sVustX9u/f/+yU0Hbtm2jpKQEKJ0P4sknn2TUqFFcu3YNo9GIzWZDo9GUzR/Rt29f1q9fT0FBARaLhRkzZtxyJFghxJ0rMSaiD25eo+sFWu9AQie9hmKzcO1/C7DkZ9VihTUj4WBnUVFR5OXlMWbMGHx8fHjkkUeIjo7mwQcfJCMjg+Li4kqnCAV47bXX2Lp1K6NHj2b37t1lp8KeeeYZXnrpJcaNG8cnn3xCZGQkSUlJtGrViry8PGbNmsXQoUMZMWIEjz76KDExMbRv356HHnqoLpsuRKOl2KyUpF6qlVNB+sAmhEx4FWtBDilfLsRafOtTzXVJpVQ2P2U9ZzKZiIuLIzIysmwqzRvOnDlDhw4dqny9I6YJrU9ubn91/s0ai9jYWKKiohxdhsM4c/trs+0laVdI+ugPBI55Hs/O99bKexZePEbKyr/gEt6GkEnzbjmQ39240faqfnfeTI4chBDiDt2Yw+F2A+7dCbeW3QgaO5PiK2dJXfsWiu3Wp5zrgoSDEELcoRJjAiqNDp1/eK2+r0fHewi4/ykK4w+T9s0HDp3/oVHeyqooSr3sVFIfNcCzikI4XElKArrApqg0tf8r1CvqfqyFuWT9sBKNqyd+w6Y45PdZowsHjUaD2WxGr9c7upQGwWw2o9U2uh8DIexGURRMxkTc2/Wx2z58BjyCtTCPnIMb0bh54dN/nN32dSuN7rSSj49P2a2domo2mw2j0Yi3t7ejSxGiwbDmZWAryqv2SKx3Q6VS4T/iCTw6DSTz++XkHt1ut33dSqP7yhgQEEBSUhLnzp275TYlJSVOfWTx6/a7u7sTEBDg4IqEaDhM13tGV2cOh5pQqdQEjp6BtSif9G8/QuPqiXv7vnbd5681unBQq9U0bdq0ym1iY2PLDWTnbJy9/ULUROkcDir0Qc3svi+VRkfww3/i2v8WYFz3NqET5+LavLPd9wuN8LSSEELYk8mYiM4vFLXetU72p9a7EDLhFXR+oaR8tQRT8oW62W+d7EUIIRqJ0jkcmtfpPjWunoROnIfG1ZNrKxdhyU23+z4lHIQQopqsxQVYclLtfr2hMlovf0Ifew2dbyjWwlz778/uexBCiEbilzmj6z4cAHR+YYRPXVwn+5IjByGEqKYSYyLguHCoS3YNh/fee4/o6Giio6NZunRphfVnzpzh4YcfZuTIkbz66qtlw00LIUR9ZEpJQOPhi9bDx9Gl2J3dwmHfvn38+OOPrF27lnXr1nHq1Cm2by/fkWPWrFnMmzePrVu3oigKq1atslc5QghRYyXGur8Y7Sh2C4fAwEBmz56NXq9Hp9PRqlUrkpOTy9ZfvXqV4uJiunXrBsC4cePYsmWLvcoRQogaUSxmStKTanUk1vrMbhek27RpU/Y4MTGRzZs3s2LFirJlqampBAb+Mr1eYGAgRqPxjvYRFxd31/XFxsbe9WsbA2duvzO3HZy7/TVpuyYnBS+blaRChYQG+G94p223+91K8fHxPPPMM7z88ss0b968bHllo4He6ciD1ZmwojLOPOEJOHf7nbnt4Nztr2nbc499RzrQod8wdH6htVdYHbh5sp/qsOsF6djYWKZOncof//jHClNUBgcHk57+S0eOtLQ0goKC7FmOEELctRJjIiq9K1rfYEeXUifsFg7Xrl1jxowZvPnmm0RHR1dYHx4ejsFgKDvUWbduHYMGDbJXOUIIUSOmlAQMwc1RqZyjB4DdTit98sknmEwmlixZUrZs4sSJ7Ny5k5kzZ9K5c2fefPNN5s6dS0FBAR07dmTy5Mn2KkcIIe6aotgoSU3Es8sQR5dSZ+wWDnPnzmXu3LkVlk+aNKnscfv27Vm9erW9ShBCiFphyUpBKSl2is5vNzjH8ZEQQtSA6XrPaGe5jRUkHIQQ4rZKUhJArUEf2MTRpdQZCQchhLgNkzEBfUAEKq3O0aXUGQkHIYS4jZKUBPQOGKbbkSQchBCiCpb8LKwF2U51vQEkHIQQokrONEz3r0k4CCFEFX6Z4Ke5YwupYxIOQghRBVNKAlqfIDQu7o4upU5JOAghRBVKjIlOd0oJJByEEOKWbCVFmDOvOd3FaJBwEEKIWypJvQQoTne9ASQchBDilkwppRejDSEtHVxJ3ZNwEEKIWygxJqJ29UTj6efoUuqchIMQQtyCKSUBQ0iLO56lsjGQcBBCiEooVgvmtMtOeb0BJByEEKJS5oyrKFYzhmDnu94AEg5CCFEpk5P2jL5BwkEIISpRkpKASqtH5x/m6FIcQsJBCCEqYTImoA9qhkqtcXQpDiHhIIQQN1EUxWmHzbhBwkEIIW5SnHgSW3EBBieb4OfXJByEEOJXzNlGjGvfQucfhkenAY4ux2EkHIQQ4jpbSRHGr5aAYiP4kVdQG9wcXZLDSDgIIQSgKDZSN7xLSVoSQQ+9iN5J71K6QcJBCCGArB9WUXjuIP73TcGtZTdHl+NwEg5CCKeXf2Yf2T9+hWfXoXj1inZ0OfWChIMQwqmZUi6StuFdDBHtCLj/aaccZK8yEg5CCKdlyc8m5au/onb1JPjhl1BpdY4uqd6QcBBCOCXFasa45g1shbmEPDIbrYePo0uqVyQchBBOR1EU0r9dhinpLIGj/w9DqHOOvFoVCQchhNPJPfwtecd34HPPeDw63uPocuolCQchhFMpTDhOxvb/4Na2F76DJzi6nHrL7uGQn59PTEwMSUlJFda99957DBkyhLFjxzJ27FiWL19u73KEEE7MnJlM6tdvoQuIIGjM71Gp5PvxrWjt+ebHjx9n7ty5JCYmVro+Li6Ot956i+7du9uzDCGEAHMxKV/9FVQqQh6djdrg6uiK6jW7xuaqVauYP38+QUFBla6Pi4tj2bJljB49mgULFmAymexZjhDCSSk2K+4nNmDOvEbww39C5xPs6JLqPZWiKIq9dzJ06FA+++wzIiIiypYVFBTwhz/8gblz5xIeHs7s2bMJDw/nhRdeuO37mUwm4uLi7FmyEKKhs1nR5KejyTOiS72A3niWgo73U9K0h6Mrc7jIyEgMBkOV29j1tFJV3N3dWbZsWdnzadOmMWfOnGqFww3VaWBlYmNjiYqKuuPXNRbO3H5nbjs03vZbiwsoMSZSYkzAZEwsfZx2BWwWAFQ6A4Ut+tH5oekOrtQxbnzud/LF2mHhkJyczL59+xg/fjxQet+xVuuwcoQQDYTNVEjRpVOlQZCSQIkxEUtOatl6jbs3+uAW+LTqhj64Bfrg5uh8Qzhy9Jjjim6AHPbb2MXFhTfeeIM+ffoQERHB8uXLGT58uKPKEULUY4rNSlHCCfJO7qLw3E8olhJAhc4vFEN4G7x6DC8LAq2Hr6PLbRTqPBymT5/OzJkz6dy5MwsWLOC5557DbDbTo0cPnnjiibouRwhRj5mMieSf3E1+3A9YC7JRu3jg2XUo7h37YwhpiVovdxzZS52Ew86dO8se//o6w8iRIxk5cmRdlCCEaCAs+dnkn9pD/sndlBgTQK3BrXUUnp3vxa11Dxkcr47ISX4hhMPZLCUUnj9E/sndFP58FBQbhtDW+I94Eo9OA9C4eTm6RKcj4SCEcBib2UTmjs/Ij/sBm6kQjac/Pv0exKPzYPQBEbd/A2E3Eg5CCIfJ3Pk5ubFb8Og8GM/O9+LSrBMqtcbRZQkkHIQQDlJ48Ri5h7/Fq3cMAcPlZpT6plrDZ6Snp7Njxw4AFi1axOTJkzl79qxdCxNCNF7WojzSNr6PLiACv3sfc3Q5ohLVCofZs2dz5coV9u/fz8GDB3nwwQdZuHChvWsTQjRS6VuWYS3MIWjs71Hr7nyUA2F/1QqH7Oxspk6dyg8//EBMTAzjxo2jqKjI3rUJIRqh/FN7KDi9F99BEzCEyAxs9VW1wsFsNmM2m9mzZw/9+/enqKiIwsJCe9cmhGhkLLnppG9ZhiGiHT79HnR0OaIK1QqHYcOG0a9fP3x9fYmMjOSRRx4hJibG3rUJIRoRRbGRtvE9FKuVoDEz5a6keq5adyvNnDmTRx99lODg0jHQ33zzTdq3b2/XwoQQjUvu4W8pSjxJwAPPovMNcXQ54jaqfbfSqVOnUKlULFq0iMWLF8vdSkKIaitJu0Lmzi9Kh8Hodp+jyxHVIHcrCSHsSrGaSd3wDiq9CwHRz6FSqRxdkqgGuVtJCGFXWXtWU5JykcBRz8pw2g2I3K0khLCb4qRzZO/7Go8uQ3Bv38fR5Yg7IHcrCSHswlZSROqGd9B6+RMwYpqjyxF36I7uVgoJKb3DQO5WEqLxs5lNWLKN6AIiUKmq9T2ynIzvPsOSZST08T+jNrjZoUJhT9UKB5vNxsaNG/nhhx+wWCzcc889tG7dWuZ8FqKRMuekkrJiEeb0JDQevri17YV72964No9Epbn9ZDuF8bHkHd2Gd9+xuDbtVAcVi9pWrd/uf/vb3zh79ixTpkzBZrOxcuVKli5dypw5c+xdnxCijpmMiaSsWIhiNuF33xRMSefIP/kDeUe2oTK44da6B+5te+PWqgdqQ8VpOq2FuaR98wH6oKb4DZ7kgBaI2lCtcNizZw9r1qxBpyv9xnDvvfcyZswYCQchGpmihBOkrF6K2uBG2ORF6IOaQp/SU0xFiScpPHeQgvjDFJz6ETRaXJt3wb1db9za9ELr4YOiKKRt/hfW4nxCJs2TKT0bsGqFg6IoZcEAoNfryz0XQjR8+XF7SN34Hjr/MEInzkXr5V+2Tq0z4N6mJ+5tehJgs1KcdI7C8z9RcO4g6ZuPAB9iiGiH3j+cwnMH8Rv6OIbg5g5ri6i5aoVD+/btWbx4Mb/97W8B+OKLL2jbtq1dCxNC1A1FUcg5sJ7MnZ/j0qwTweNfRuPifsvtVWoNrk074tq0I37DplCSeul6UPxE3vEduDTtiHef0XXYAmEP1QqH+fPns3DhQiZNmoTNZmPAgAG89tpr9q5NCGFnis1KxnefkntoM+4d+pcOiHcHp4JUKhWG4OYYgpvjO/BRLLkZqF09ZFC9RqDKcBg9unz6+/n5AXD27Fl++9vfsnHjRvtVJoSwK5ulhLT171Bwdj/efUbjN2zyXd2y+mu/PhUlGrYqw2HevHl1VYcQog5Zi/IxfrWE4itn8LtvCj59xji6JFHPVBkOvXv3rqs6hBB1xJKTxrUVCzFnpRD04At4dBrg6JJEPSS92IRwIpq8VK5++i8UczGhk+bh2izS0SWJekrCQQgnUZR4Es+Dn4OrO2GTF6IPaubokkQ9JuEgRCOmKAqmq+fIPbKN/FN7sbn5ED51EVqvAEeXJuo5CQchGiGbqYj8uN3kHtlGSeolVHpXvLrfx2WfDhIMolqcLhwsVhupOWZHlyEaCHNOKhpXT9T6imMI1UemlITrRwk/oJQUow9uQcADz+LRaQBqvSuXYmMdXaJoIJwuHPafuMYH3xgJa5JG1zaBji5H1GOmlIskfzoHtYs7/vdNxb3TgHo5xaXNbKLgzD5yj2zDdPU8Kq0e94734NVjJIaw1vWyZlH/OV049OoUjL+Xlr+vOMp7fxqCu6uMESUqshUXYPz6b6hdPdF6+pK6/u+4HN1OwP1PoQ9s6ujyACjJSCbvyFbyTuzCVpyPzj8M/+FP4NF5MBpXT0eXJxq4mnWHvI38/HxiYmJISkqqsO7MmTM8/PDDjBw5kldffRWLxWLPUsq46LU81NePzNxiPlp3sk72KRoWRVFI3fQ+luxUgse9SNjUvxAw6hlK0i6R9PGfyPjuv9hMjplDXbFZKTh7kGvL/x9J/3qenMPf4tqiC6G/+X9EPPMO3r1jJBhErbBbOBw/fpxJkyaRmJhY6fpZs2Yxb948tm7diqIorFq1yl6lVBARoOeRYW3YefgK+08m19l+RcOQe+ib6yOL/haXJh1QqTV49RhBk2ffxbPLEHIObuDKv2aSf+pHFEWpk5qsBTlk7f2ay+//DuOapZRkXsN38CSaPv8hweP+iGvzznL6SNQqu4XDqlWrmD9/PkFBQRXWXb16leLiYrp16wbAuHHj2LJli71KqdSE+9rRKsKb91cfJzvPVOW2xVfOUpJ6qY4qE45UfPU8GTs+w61tL7xvGlJC4+ZFYPRzhE39CxoPH1LXvc215f+PkrQrdqwnntQN73Dp3afJ2rUcvV8oweNfoumMD/AdMB6th6/d9i2cm0qx81efoUOH8tlnnxEREVG27OjRoyxdupQvv/wSgEuXLvH000+zdevWar2nyWQiLi6uxrWlZpv5cIuR1mEuTBzoX/Gbl9WM67kduFw+gtXFm9xBz4HarmfihAOpSgrx2vdvFJWKvP7TUHRV3KGk2NBfOYrr+d2orCWYmvemqNUA0OprXojVgj7lNIZLsWhzr6Fo9JjCO2NqGoXNQ25DFTUXGRmJwWCochuHXJCuLI/u5pC4Og2sTGxsLFFRUQCYtBf4ZMMpsm1B3Nf7lwuNxckXSFv/D8yZybi26kHRz0do51aMR6eBd7y/+ubX7Xc2t2q7othIWbmYInMh4VMWYwhtdfs369kLa8EEMr//grzjO3FPP4//8Cdwb9/vrn6ezdmp5B7ZSt6xHdiK8tAFROA18ik8Ow9GbXC74/erjHz2zt32O/li7ZBwCA4OJj09vex5Wlpapaef6sKYga04eCqFj9adpEvrAAJ9DGTvXUPWnq/QePoR+pv/h0uzTiR9+Aey96/HvWP9vJ1R1Ez2vrUU/XyUgPunVy8YrtO4exMYMwPPbveRvmUZqV//DZcmHdD5hYJKDWp16TDYN/6+xWPTtZ8pvFDaB8GtbS+8e47CpVmk/KwJh3FIOISHh2MwGMrSbN26dQwaNMgRpaBWq/jDxB48/+ZO/r18J7/1+JGS5Hg8IgfhP/KpshmxvPuOJf2bDyhKOIFby64OqdURCi/EkrHjM4LHv4TeP9zR5dhFUeJJsnavwL3TADx7jLyr93CJaEf4tL+Se2QbuYe+wZxtBJsNRbGBYvvVY+WXxzYbUHoUrXbzwqffg3j1GIHWW/rfCMer03CYPn06M2fOpHPnzrz55pvMnTuXgoICOnbsyOTJk+uylHKCfF35Y1QeXmfWUVioI+yhF/HoeE+5bTwjB5G1+0tyDqxzmnCwmU2kb/kYS04qaevfIWzKIlSaxtU1xpKXReq6v6PzCyFw1LM1+qauUmvw7jkK756jqv0aRVFKw0OlqvFEO0LUJrv/T9+5c2fZ42XLlpU9bt++PatXr7b37m/Lkp9F+jf/JPBCLNcMzViW0ZsFfp3xuGk7lVaHd+8YMnd+junaRQyhLR1Sb13KObgRS04qXr0eIPfQZrL3fo3voEcdXVatUWxWUte9jc1USOhj81Eb6n6IDJVKBSqZUlPUP079VaXg3EGSlr1IUeJJ/EdMo8MzCzHrvXn7yyNYrLYK23t1H45K70r2gXV1X2wds+Rlkr1vLW7t+hAw4kk8IgeR9eNXFCdfcHRptSZr9wqKL58iYNTT6IPqR69nIeoL5wwHi4m0Te9jXL0Urac/4dOW4t0rGj8vN343visXknJY9d35Ci9Tu7jj1WMEBWf2l55TbsQyv1+OYrPgP6z0dJ//yKfQePiStv4f2MxV9wtpCAovxJK972s8uw7Ds8sQR5cjRL3jdOFgzk7Fa+8n5J3YhU//cYQ/8Rf0gU3K1t/TJYwhURGs/O485y9nVXi9d69oUKnJObixLsuuU8VXz5N/chc+fcag8w0BQOPiTtDo/8OcmUzmjs8cW2ANWXLSSN3wDvqg5viPfNLR5QhRLzldOFjzMrC5eBL2+Ov4DfkNKk3FgfeefqgLfp4G3vrfEUxma7l1Wi9/PCIHkXdsB9bC3Loqu84oio2Mbf9G4+6DT/9x5da5tuiCV+8YcmO3UPjzUQdVWEM2K8av/4ZitRL88B9R6+68n4wQzsDpwsGlSQfy+zyOS5P2t9zGw1XH7yd252paPp99c7rCep++Y1AsJeQertshP+pCftweTMnx+A35TaUXaP3ufQxdQARpm97HWpjngAprxvXcTkzJ8QTGzEDnF+bocoSot5wuHKqrW9sgYga0YMOeixyPTyu3Th/YBLc2Pck5vLlRnH+/wVZSRObOLzCEtsKjy72VbqPWGQga+3ushbmkb/mozgaeqynFaiHn0De4XDqEV68H8OjQz9ElCVGvSThUYUp0R8ID3fn7iqMUFJWfPc6n34PYivLIO77zFq9ueLL3rcOan4n/iGlV3nNvCGmJ76AJFJzZR8GpH+uwwjtnM5vIObSZKx/MIGPbvzH7NSu7yC6EuDUJhyq46LW8+FgUmbnFvP7vg1y8mlO2zhDRHkN4O3IObkCxWat4l4bBnJNKzsENeHQaiEvErU+53eDT70EM4e1I3/IRltz0225f12zFBaVDXL/3LBnbPkHjFUDIo3PI7/VYpdeZhBDlSTjcRtumvswY35XEa7n8/q1dLPnsEFeMeahUKnz6jcWSnUrB2QOOLrPGMnd8DoDf0N9Wa3uVWkPQmOdRbDZSN75XOhxEPWDJzybz+y+49N6zZO1ajiGkFaGPv074lEW4tYkCGatIiGppXGMh2MmIPs3o3yWMdbsusP6Hn9l/Ipl7o5owcXhHdH5hZO9fh3uH/g12kLSiy6coOLMP34ET0HpVf0honV8o/sOnkr75X+Qe2ox37xg7Vlk1c04qOfvXk3d8J4rFjHuHvvj0H4chpPH3ZBfCHiQcqsnDVcdvR3Vg9MCWrN4Zzzd7E9h9JIlp7XoQmbKJ4sSTuLbo4ugy75his5Kx7T9ovALw7jf2jl/v2e0+Cs8fInPnF7i26Fquz0hdKEm7Qvb+deSf2gOo8Ow8GO9+D6L3lzuRhKgJOa10h7w9DDw5JpJlc+5jRJ9mfHbOh1ybK6c2fEFOfsO7cynv+PeUGBPwH/r4Xd3zr1KpCIh+DpXBldQN76BYzbd/UQ0pikJx0llSVi8l6aM/UHB2P149R9F0xgcExvxOgkGIWiBHDnfJ39uV343vyrghrTm86iodM7/ntSUr6HVPbx68tzUervX/oqfNVEjW7v9hiGiP+02j0N4JrYcvgaOexbhmKVl7vsLv3sdqscpfKFYLBWcPkPPTJkzJ8ahdPPAZMB7vXtFo3Lzssk8hnJWEQw2F+Lsz6oknuPTOfh50u8Bb3/mwaW8C4+5tTcyAFri51N+QyPpxNdaCXEImvFrj6yXu7fvg0WVI6WB9rXtU646n6rIW5ZN37DtyDm3GmpdReq1j5HQ8u9yLWu9Sa/sRQvxCwqEWaFzc8e4xgmY/beIf06fyxd40Pv/2DGt3XSBmQEtGD2yJl3stzC1ci8yZyeT89A0eXYbc0cxnVQkYMY3iS3GkbniXiKfeRK2v2RDYN2rMO/E9itmES/POBIx6GrfWPWTuAyHsTMKhlnj3jiHn0Dd4Xd7Fa08+yfnLWXy14zwrtp9j7e4LjOzbjIcGtybAp+7nDKhMxnefodJq8RtSe6eA1AY3Asc8z7XP53Pty4W4NuuEzjcErW8wOp8QNJ6+t/2lrigKxZfiyPlpE4XxsaDR4NFpIN69YzAEN6+1WoUQVZNwqCWlA/INJO/YDnwHPErbpr68+kQfLqfksub7C2z6MYHNexMYEtWE8UPbEBZ483RCdVhregKF8YfwG/JbtB6+tfrerk074T98KjmHviF739rSWc6uU2n1aH2CrgdGCDqf4LLHWk/f0usJBzdRkppYOm3mgPF4RY2s9RqFELcn4VCLfPqMJf/ELnJjt+A78BEAmoZ48cKkHjw2sj1rd11g28FL7Dh0mf5dwnhkWFtahnvXaY2KzYrb2e1ofYLt1i/Bu3cM3r1jUKwWLDlpmLNSMGcZsWSnlD0uSjyJUsm4VLrAJgREP4dH5CDU2vp1Kk4IZyLhUIv0QU1xax1FzuHNePcdU+7W0GA/N54d14UJw9uy4YeLfLM3gR+PJxPVPohHhrWlU0v/OqkxN3Yrmvx0/Me/hEpr34vlKo0WnV8oOr/QCusURcGan10WGJacNAzh7XBt0aXBdiYUojGRcKhl3v3GUvj5a+Sf+B6vqPsrrPf1dGFKdEceHtqGzXsT2LDnZ2a//yMdW/jx8JA2dG8XhE5b+xdbLXlZ5B7ZSs5PmzD7NcOtbe9a38edUKlUaD190Xr64tKkg0NrEUJUJOFQy1yadMQQ1obsAxvw7D4clbryyeM9XHU8el9bxgxqyfaDl/l61wVe//dB3Fy09GgXRJ9OIfTsEIyHW81OrRQnXyD30Dfkn94HNiturXuQHdZHvp0LIaok4VDLSgfkexDjmjdIWvYiOv/w0lMrviGlf/xC0Xj6ld2146LXMnpgS+7v15wjZ438dNrIT6dT+PF4Mmq1isiW/vTuFEKfTiGE+LtXq4ayzmKHNmO6eg6V3hWvqJF49xyFzi+Uq7Gx9vwnEEI0AhIOduDWthd+Q35D8ZWzmNOTKLwQC1ZL2XqVVl96e6dvCDrf0uDQ+oXQIyKU3h07o9CV+CtZHDyVwsFTKXy8Po6P18fRNMSTPp1C6N0phLZNfFGry3/7txbkkHvsO3Jjt2DNy0TrG4L/iCdLO4sZ3Or6n0EI0YBJONiBSq0pN/+yYrNiyc3AnHUNS+aNO3auYc5KoejnY+XHI1Jr0HoH4uUTxCifYMbcE0Sexocz6WoOJFpY8308X+2Ix8fTQK8OwfTuFEIn7wKKj28lP24PitWMa8uueI96FtfW3aWzmBDirkg41AGVWoPOJwidTxC06FpunaLYsOZlYs4sDQtLdirmbGPpPBHnDmIrzAWg9fU/jwe5YjL4kWZx5+IZHTln0knTGTGjJS+0F2EDxxDapm3dN1II0ahIODiYSqVG6xWA1isA1+adK6y3mYquh4URc3YqlmwjrtmpuGcbiTAbsRq8iPccwebUCC6essCpMzQJvkLPDiH06hhMh+Z+aDVy9CCEuDMSDvWc2uCKIbh5pUNHKIoCQGuVipFAclo+h84YOXzayMY9P7N21wXcXbR0bxdEr44hRLUPwtvjzoflFkI4HwmHBuzm21HDAj0YG+jB2EGtKCw2c+x8GofPGDl8xsiPx5NRqUqnPQ3ysKC4GWnf3K9BDC0uhKh7Eg6NlJuLjv5dwujfJQybTeHnq9kcPm3k8FkjP57OY8+pA6hU0CzEiw4t/OjY3I+OLfwJ9HWVPhBCCAkHZ6BWq2jTxJc2TXyZNLI9+w8ewt2/OacTMjmTkMmu2CS+3ZcIgL+3Cx1b+NOxhR8dmvvRPMwbjVrCQghnI+HghPRaNV1aB9KldSAAVpvCpWu5nEnI4HRCJqcTMthz7CoArgYtLcNLA0JRwHb9OofNdv1vRYHryxVFQaF0INbwIA8mjWhHk2BPh7RRCFEzdg2HjRs38s9//hOz2czUqVP5zW9+U279e++9x5o1a/DyKp3i8dFHH62wjbA/jVpFy3BvWoZ7Ez2gJQCpWYXXjywyuJSSh8VqQ6VSoVKBWqVCo1ahvv5cddPfAIfPGNl7/CrDejVl0oj2BPrWj3kshBDVY7dwMBqNvP3223z99dfo9XomTpxInz59aN26ddk2cXFxvPXWW3Tv3t1eZYi7FOTrRpCvG/f2iLir1+fkm1i14zyb9yay60gSMQNa8siwNnjWcKwoIUTdsNsN8Pv27aNv3774+Pjg5ubGyJEj2bJlS7lt4uLiWLZsGaNHj2bBggWYTBXH9xcNk7eHgeljO/Ov2cMY2C2cdbsvMH3Rdr7acZ7iEsvt30AI4VB2C4fU1FQCAwPLngcFBWE0GsueFxQU0KFDB15++WXWrl1Lbm4uH3zwgb3KEQ4S7OfGC5N68M4fh9CpZQCfbT7DM3/5jm/3JWCx2m7/BkIIh1ApN3pS1bJ//etfFBUV8cILLwDw1VdfcfLkSRYsWFDp9qdPn2bOnDmsW7futu9tMpmIi4urzXJFHbmUauK74zlcSSvBz1PL0C5edGzqilpunxWizkRGRmIwVN0h1m7XHIKDgzl8+HDZ89TUVIKCgsqeJycns2/fPsaPHw+U9vbVau+snOo0sDKxsbFERUXd8esaC0e2Pwp46H6FQ6eN/HfzaVbvzaT1JW+mRHekW9ug276+puSzd972S9uj7uiLtd1OK/Xv35/9+/eTmZlJUVER27ZtY9CgQWXrXVxceOONN7hy5QqKorB8+XKGDx9ur3JEPaJSqejdKYR3/jiEP0zsTk5BCfM+3M8f3t7Fxj0XycmXa09COJpdjxxeeOEFJk+ejNlsZvz48XTp0oXp06czc+ZMOnfuzIIFC3juuecwm8306NGDJ554wl7liHpIo1YxrFdTBnYLZ/tPl9l28BIfrTvJvzfG0btTCMN6NSWqXRAaGThQiDpn134Oo0ePZvTo0eWWLVu2rOzxyJEjGTlypD1LEA2AXqch+p4WRN/TgoTkHHYcusKuI1fYd+IaPp4G7u0RwX29mtIs1MvRpQrhNKSHtKhXWoR589RYb6bGdCT2jJEdh6+wcc9F1u3+mdZNfLivZxMG9YiQ/hJC2JmEg6iXtBo1fSJD6RMZSk6+id1Hkthx6Ar/WnuSjzecok+nEIb2akK3NoHodRpHlytEoyPhIOo9bw8DYwa1YsygVly8msOOw5fZFZvE3hPJGPQaurYOpGeHIKI6BBPkK3NlC1EbJBxEg1I6BlRnpkZ34nh8GrFnjBw6Y+Sn0ykANAvxpGeHYHp2CKa9zIInxF2TcBANkk6rLguBpxWFpNR8Ys8aOXTayPoffmbN96Wz4HVrF0SvDsH0aB+Er6eLo8sWosGQcBANnkqlokmwJ02CPXlwcGsKi80cj0/j0GkjsWeN7D2eDECbJj4EeVrJ5QrNQryICPKQ6xVC3IKEg2h03Fx09OscRr/OYSiKQkJybtl0qfvPZrP39BEA1CoI8XenWagXTYM9aRriSbMQL8ICPdBp5XSUcG4SDqJRU6l+mavi0fva8tOhw4Q0actlYx6XU/K4lJLL5ZQ8Dp5KKZvASKNWERboTtNgL5qFeNKumR8dW/jhYpD/LsJ5yE+7cCoatYqmIV40DfGCrr8sN1usJKXmlwuMi1dz2HcyGUUBrUZFu2Z+dGkdQNc2gbRt6itHF6JRk3AQAtBpNbQI86ZFmHe55UUmC2cSMzkRn8bxC+ms2H6OL7edw6DX0KmFP11aB9ClTQAtw31krm3RqEg4CFEFV4OWHu2C6NGudMTY/MISTv6cwYkLaRyPT+fTb04D4O6qo3Mrf7q2CSSyVQAhfm5yGko0aPLTK8Qd8HDT069zKP06hwKQlVvMiQvpHI9P48SFdA7EpZRt6+6ixd/HFX8vF/y9XfH3din986tlXu561HLEIeohCQchasDXy4XBPSIYfH2u7ZSMAs4mZpKWXURmTjEZucWkZxdxKSWP7LxibDdNraXVqPDzciE80KO030bHYMICPBzQEiHKk3AQohaF+LsT4u9e6Tqr1UZ2vomMnGIycopIzy79OyO3mJ+Tslm2Po5l6+MID3SnZ4cQenUIpmNLf7nwLRxCwkGIOqLRqK+fXnIFfCusT8ko4PCZ0l7em/clsP6Hn3E1aOneLpBeHYKJ6hAsvbxFnZFwEKKeCPF3J2ZAS2IGtKTYZCnt5X09LPaduAZA6yY+9L5++knukBL2JOEgRD3kYtCWDVl+o5f3oTMpHDpt5Mvt5/jftnPodRqaBnvQNMSLZiFeNAst7eHt7+2CSiWhIWpGwkGIeu7Xvbwn3NeOnHwTR86l8nNSDpdScjl2PpWdh6+Ube/uor3e0c+zXGh4exgc2ArR0Eg4CNHAeHsYGBLVhCFRTcqW5RaUcDkll8vGPC5dy+VSSh57jyez9cClsm083fToNDZ8du/C1aDFoNfgqtfiYrjxtxYXveb631pcDRo83PSE+rsT5Osqc3k7GQkHIRoBL3c9ka0CiGwVULZMURSy8kxculYaGkmp+SQlG3Fzd6W4xEJeQQlpWYUUmayYSiwUmaxYrLZK31+tVhHs60ZogDsh/m6EBngQ6l/6PNjfHYOMbnvHFEXh2Pk0ALq1Dax3pwIlHIRopFSq0j4Ufl4udL/ewzs2NpaoqKhbvsZssWEqsVBcYqXIZCG3oIRr6QVcyygo+/vcpUwKii3lXhfg7UJIgDuh/u60buJD97ZBhAZUfkuvgItXc/hkQxwnLqQDpTcaTBrejl4dg+tNSEg4CCHK6LRqdFo9Hr+abbVTS/9y2yiKQl6hmZSMApLTC0i5ERzpBfx0OoXtP10GINjPje7tgujWNpCurQPwcNPXZVPqpazcYj7/9gzfHbqMh6uOZx7qjF6nYdV353n93wdpFeHNpOHt6N0pxOEhIeEghLgjKpUKL3c9Xu562jYt319DURSS0ws4ei6VY+fT2H3kClv2J6JWQZsmvnRrG0j3dkG0a+brVFO4msxW1u/+mdU7z2O22BgzsBUTh7ctC8yhPZuwK/YKK787z8L//ETLcG8mDm9H30jHhYSEgxCi1qhUKsIDPQgP9CBmQEssVhvnLmVx9HxpWHy14zwrvzuPq0FD51aBdGtb+icswL1RXvBWFIU9x67y329Ok5pVRJ9OIUwb3YmwwPJDpGg1au7r3Yx7o5qwKzaJVd+dZ/GnP9EizItJI9rRp1NonY/BJeEghLAbrUZNp5b+dGrpz2/v70B+YQknLqRz9Hwax86n8tPp0oEK1Srw83Yl0MeVIF83gvxKHwf6uhHoW7rMtYGNcnv+chYfr4/jTGImLcK8WDSxO11aB1b5mtKQaMqQqAh2H01ixfbzLP70EM1DvZg4oh39IusuJBrWv7YQokHzcNPTv0sY/buEAXAtvYBTF9NJySgkNauQtOwizlzK5MfjRVhvGqXQw1VH0I2w8HMjPMCd0OtHKQE+rvWmt3haVhGfbT7NriNJ+HgaeP7Rbgzr1fSO6tNo1Azt2ZTB3SPYffQqq747x5L/Xg+J4e3o3yXU7qebJByEEA4TGuBe6V1NVptCVm4xaVlFZaGRmlVIWlYRKRkFHI9Po7jEWra9VqMmNMCdsAB3wgM9CAv0ICyw9LGvp8Huv0jNFhvX0vPZcyyZr3ddQFEUHhnWhvFD2+Dmorvr9y0NiSYM7hHBnutHEks+O8TCZ/vTtU3VRyE1JeEghKh3NGoVAT6uBPi40qGFX4X1iqKQmVtMcnoByWn5JKcVcDUtn+T0AmLPppbrr+Fq0BAa4IFBXULslZMEeLsQ4FM6AGKAjyt+Xi7VGvlWURSy80wkpeVzNTWfq2n5JKWWPjZmFpQNxz6oWzhTojsS5OdW9Rve4b/HvVFNGNg9gvjLWbSK8L79i2pIwkEI0eCoVKqyEW47/6rjH5QedaRnF3E1LZ9raflcTS8NjivXCkj86TJFJstN7wU+Hgb8fVxLg8PbFX8fV3w8DGTkFpUFwNW0fAp/1b9Dr1UTFuhBywhvBnUPJyLIg5bh3qXzk9uJRq2iffOKYWkPEg5CiEZFo1YR7OdGsJ8bXO/8B790ACwsNpOeXUR6TulETBk3HucUcS29gJMX0st18gvwcSUi0IMhUU1K78QK8iDi+nWOxjyLn4SDEMKpuLnoaBqiq/IbfmGxmex8E36eLk47F7hztloIIarg5qKr0YXkxsCuvU42btzIAw88wPDhw1m+fHmF9WfOnOHhhx9m5MiRvPrqq1gslkreRQghRF2zWzgYjUbefvtt/ve//7F+/XpWrlzJhQsXym0za9Ys5s2bx9atW1EUhVWrVtmrHCGEEHfAbuGwb98++vbti4+PD25ubowcOZItW7aUrb969SrFxcV069YNgHHjxpVbL4QQwnHsFg6pqakEBv7SSSMoKAij0XjL9YGBgeXWCyGEcBy7XZBWFKXCsl/3Urzd+uqIi4u788Kui42NvevXNgbO3H5nbjs4d/ul7dVnt3AIDg7m8OHDZc9TU1MJCgoqtz49Pb3seVpaWrn11REZGYnBcOfz4t5uwpPGzpnb78xtB+duv7Q9CpPJVO0v1XYLh/79+/Puu++SmZmJq6sr27Zt4/XXXy9bHx4ejsFgKCt63bp1DBo0qFrvfeOoo6Sk5K7rM5lMd/3axsCZ2+/MbQfnbr+zt/3G78zKztzcTKVUZ6u7tHHjRj788EPMZjPjx49n+vTpTJ8+nZkzZ9K5c2fOnj3L3LlzKSgooGPHjvzlL39Br7/9bFF5eXmcP3/eXmULIUSj1rZtWzw9Pavcxq7hYC82m42CggJ0Op3Dp9ITQoiGQlEUzGYz7u7uqNVV34/UIMNBCCGEfTW+efmEEELUmISDEEKICiQchBBCVCDhIIQQogIJByGEEBVIOAghhKhAwkEIIUQFThcOt5uAqDGbPHky0dHRjB07lrFjx3L8+HFHl2R3+fn5xMTEkJSUBJQOJT969GhGjBjB22+/7eDq7O/m9r/yyiuMGDGi7Gdg+/btDq7QPt577z2io6OJjo5m6dKlgHN99pW1/44/e8WJpKSkKEOGDFGysrKUgoICZfTo0Up8fLyjy6oTNptNueeeexSz2ezoUurMsWPHlJiYGKVTp07KlStXlKKiImXw4MHK5cuXFbPZrEybNk3ZtWuXo8u0m5vbryiKEhMToxiNRgdXZl979+5VJkyYoJhMJqWkpESZPHmysnHjRqf57Ctr/7Zt2+74s3eqI4fbTUDUmF28eBGVSsX06dMZM2YMX3zxhaNLsrtVq1Yxf/78stF+T5w4QbNmzWjSpAlarZbRo0c36s//5vYXFhaSnJzMvHnzGD16NO+88w42m83BVda+wMBAZs+ejV6vR6fT0apVKxITE53ms6+s/cnJyXf82TtVONxuAqLGLDc3l379+vH+++/z6aefsmLFCvbu3evosuxq0aJF9OzZs+y5s33+N7c/IyODvn37snjxYlatWsXhw4dZvXq1Ayu0jzZt2pTNMJmYmMjmzZtRqVRO89lX1v6BAwfe8WfvVOGg1MIEQw1V9+7dWbp0KW5ubvj5+TF+/Hh2797t6LLqlDN//gBNmjTh/fffx9/fH1dXVx5//PFG/TMQHx/PtGnTePnll2natGmF9Y39s/91+1u2bHnHn71ThcPNEwzdPAFRY3b48GH2799f9lxRFLRau03nUS858+cPcO7cObZu3Vr2vDH/DMTGxjJ16lT++Mc/8tBDDzndZ39z++/ms3eqcOjfvz/79+8nMzOToqIitm3bVu0Jhhq6vLw8li5dislkIj8/n7Vr1zJ8+HBHl1WnunbtSkJCApcuXcJqtbJp0yan+fyh9BfC4sWLycnJwWw2s3Llykb5M3Dt2jVmzJjBm2++SXR0NOBcn31l7b+bz75xfm24heDgYF544QUmT55cNgFRly5dHF1WnRgyZAjHjx/nwQcfxGaz8dhjj9G9e3dHl1WnDAYDS5Ys4fnnn8dkMjF48GDuv/9+R5dVZ9q3b8/TTz/NpEmTsFgsjBgxgpiYGEeXVes++eQTTCYTS5YsKVs2ceJEp/nsb9X+O/3sZT4HIYQQFTjVaSUhhBDVI+EghBCiAgkHIYQQFUg4CCGEqEDCQQghRAUSDkI4yMGDBxvlraSicZBwEEIIUYFTdYIT4k7s3LmTf/7zn5jNZlxcXHj55Zf58ccfiY+PJz09nYyMDNq3b8+iRYvw8PAgPj6eBQsWkJ2djUqlYtq0aTz44IMArF69mv/85z+o1Wp8fX3561//CpSOlPrCCy9w8eJFTCYTCxcuLDdYnhAOU/ujiQvR8CUkJCgxMTFKZmamoiiKcv78eeWee+5RlixZogwaNEhJS0tTrFar8uKLLypLlixRzGazMmzYMGXr1q2KopTOHTJw4EDlyJEjypkzZ5Q+ffooycnJiqIoyn/+8x9l3rx5yoEDB5QOHToox44dK1s+efJkxzRYiJvIkYMQldi7dy+pqalMnTq1bJlKpeLy5cvcf//9BAQEADB+/HgWL17Mww8/jMlkYsSIEUDpUC0jRoxgz549eHp6MmDAAEJDQwHK3vPgwYM0adKErl27AqXDW6xZs6buGilEFSQchKiEzWajX79+/P3vfy9bdu3aNVauXElJSUm57dRqdaUTpyiKgsViQaPRlBseuri4mKtXrwKg0+nKlqtUqkqHFRfCEeSCtBCV6Nu3L3v37uXnn38GYPfu3YwZMwaTycSOHTvIy8vDZrOxatUqhgwZQosWLdDpdGzbtg0Ao9HI1q1b6d+/P3369GH//v2kpqYCsGLFCt544w2HtU2I6pAjByEq0aZNGxYsWMCLL75YNvb9P//5T/bv309AQADTp08nKyuLXr168eyzz6LT6fjggw9YuHAh7777LlarlRkzZtC3b18AZs2axVNPPQWUTuO4ePFiEhMTHdhCIaomo7IKcQfeffddsrKyeO211xxdihB2JaeVhBBCVCBHDkIIISqQIwchhBAVSDgIIYSoQMJBCCFEBRIOQgghKpBwEEIIUYGEgxBCiAr+P0kzvyJwSrc5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validate'], loc='upper left')\n",
    "plt.savefig('unregularized_accuracy_vs_epoch.png')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validate'], loc='upper left')\n",
    "plt.savefig('unregularized_loss_vs_epoch.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "b8875598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "37/37 [==============================] - 6s 166ms/step - loss: 2.5862 - accuracy: 0.3902 - val_loss: 1.9035 - val_accuracy: 0.4545\n",
      "Epoch 2/25\n",
      "37/37 [==============================] - 7s 179ms/step - loss: 1.6140 - accuracy: 0.5613 - val_loss: 1.3324 - val_accuracy: 0.6818\n",
      "Epoch 3/25\n",
      "37/37 [==============================] - 5s 143ms/step - loss: 1.2458 - accuracy: 0.6674 - val_loss: 1.2683 - val_accuracy: 0.5000\n",
      "Epoch 4/25\n",
      "37/37 [==============================] - 6s 172ms/step - loss: 1.0929 - accuracy: 0.6739 - val_loss: 1.0967 - val_accuracy: 0.5455\n",
      "Epoch 5/25\n",
      "37/37 [==============================] - 7s 193ms/step - loss: 1.0370 - accuracy: 0.6642 - val_loss: 0.9520 - val_accuracy: 0.6818\n",
      "Epoch 6/25\n",
      "37/37 [==============================] - 6s 169ms/step - loss: 0.9141 - accuracy: 0.7117 - val_loss: 0.9668 - val_accuracy: 0.5909\n",
      "Epoch 7/25\n",
      "37/37 [==============================] - 6s 161ms/step - loss: 0.8369 - accuracy: 0.7269 - val_loss: 0.7179 - val_accuracy: 0.7727\n",
      "Epoch 8/25\n",
      "37/37 [==============================] - 6s 153ms/step - loss: 0.8109 - accuracy: 0.7334 - val_loss: 0.8591 - val_accuracy: 0.6364\n",
      "Epoch 9/25\n",
      "37/37 [==============================] - 6s 171ms/step - loss: 0.7989 - accuracy: 0.7219 - val_loss: 0.9701 - val_accuracy: 0.5909\n",
      "Epoch 10/25\n",
      "37/37 [==============================] - 7s 180ms/step - loss: 0.7254 - accuracy: 0.7698 - val_loss: 0.7608 - val_accuracy: 0.7273\n",
      "Epoch 11/25\n",
      "37/37 [==============================] - 7s 177ms/step - loss: 0.7175 - accuracy: 0.7643 - val_loss: 0.9731 - val_accuracy: 0.5909\n",
      "Epoch 12/25\n",
      "37/37 [==============================] - 7s 182ms/step - loss: 0.6840 - accuracy: 0.7781 - val_loss: 0.9599 - val_accuracy: 0.5455\n",
      "Epoch 13/25\n",
      "37/37 [==============================] - 7s 182ms/step - loss: 0.6679 - accuracy: 0.7823 - val_loss: 0.8165 - val_accuracy: 0.7727\n",
      "Epoch 14/25\n",
      "37/37 [==============================] - 7s 181ms/step - loss: 0.6639 - accuracy: 0.7855 - val_loss: 0.9880 - val_accuracy: 0.6364\n",
      "Epoch 15/25\n",
      "37/37 [==============================] - 6s 162ms/step - loss: 0.6661 - accuracy: 0.7869 - val_loss: 0.6824 - val_accuracy: 0.8182\n",
      "Epoch 16/25\n",
      "37/37 [==============================] - 6s 158ms/step - loss: 0.6062 - accuracy: 0.8164 - val_loss: 0.7865 - val_accuracy: 0.8636\n",
      "Epoch 17/25\n",
      "37/37 [==============================] - 6s 160ms/step - loss: 0.5960 - accuracy: 0.8155 - val_loss: 0.7264 - val_accuracy: 0.8636\n",
      "Epoch 18/25\n",
      "37/37 [==============================] - 6s 155ms/step - loss: 0.6551 - accuracy: 0.7943 - val_loss: 0.6985 - val_accuracy: 0.8182\n",
      "Epoch 19/25\n",
      "37/37 [==============================] - 6s 160ms/step - loss: 0.5653 - accuracy: 0.8266 - val_loss: 1.0115 - val_accuracy: 0.6818\n",
      "Epoch 20/25\n",
      "37/37 [==============================] - 6s 167ms/step - loss: 0.5418 - accuracy: 0.8372 - val_loss: 0.9304 - val_accuracy: 0.6818\n",
      "Epoch 21/25\n",
      "37/37 [==============================] - 6s 163ms/step - loss: 0.5363 - accuracy: 0.8478 - val_loss: 0.7764 - val_accuracy: 0.8182\n",
      "Epoch 22/25\n",
      "37/37 [==============================] - 6s 163ms/step - loss: 0.5596 - accuracy: 0.8187 - val_loss: 1.2726 - val_accuracy: 0.6818\n",
      "Epoch 23/25\n",
      "37/37 [==============================] - 6s 158ms/step - loss: 0.5027 - accuracy: 0.8547 - val_loss: 0.7363 - val_accuracy: 0.8636\n",
      "Epoch 24/25\n",
      "37/37 [==============================] - 6s 162ms/step - loss: 0.4774 - accuracy: 0.8685 - val_loss: 0.7396 - val_accuracy: 0.8182\n",
      "Epoch 25/25\n",
      "37/37 [==============================] - 6s 159ms/step - loss: 0.4964 - accuracy: 0.8607 - val_loss: 1.0990 - val_accuracy: 0.7273\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "        \n",
    "model.add(Conv2D(128,\n",
    "                 kernel_size = (3, 3),\n",
    "                 kernel_regularizer=regularizers.L1(0.001),\n",
    "                 bias_regularizer=regularizers.L2(0.0001),\n",
    "                # activity_regularizer=regularizers.L2(1e-5)\n",
    "                )\n",
    "         )\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "\n",
    "model.add(Conv2D(64,\n",
    "                 kernel_size = (3, 3),\n",
    "                 kernel_regularizer=regularizers.L1(0.001),\n",
    "                 bias_regularizer=regularizers.L2(0.0001),\n",
    "                #activity_regularizer=regularizers.L2(1e-5)\n",
    "                )\n",
    "         )\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer = 'adam', metrics = ['accuracy'])\n",
    "history = model.fit(X_train,y_train,epochs = 25,batch_size = 60, validation_split = 0.01)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "f7c47ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validate'], loc='upper left')\n",
    "plt.savefig('regularized_accuracy_vs_epoch.png')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validate'], loc='upper left')\n",
    "plt.savefig('regularized_loss_vs_epoch.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "86e7ec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = []\n",
    "scores = model.evaluate(X_test,y_test,verbose=0)\n",
    "final_result.append(scores[1] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "401d6f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[75.0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "e417f843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/25\n",
      "36/36 [==============================] - 6s 146ms/step - loss: 1.0746 - accuracy: 0.4400 - val_loss: 0.9025 - val_accuracy: 0.5000\n",
      "Epoch 2/25\n",
      "36/36 [==============================] - 6s 166ms/step - loss: 0.8159 - accuracy: 0.6388 - val_loss: 0.8042 - val_accuracy: 0.5455\n",
      "Epoch 3/25\n",
      "36/36 [==============================] - 6s 176ms/step - loss: 0.7115 - accuracy: 0.7000 - val_loss: 0.7943 - val_accuracy: 0.5909\n",
      "Epoch 4/25\n",
      "36/36 [==============================] - 7s 191ms/step - loss: 0.6791 - accuracy: 0.7133 - val_loss: 0.7931 - val_accuracy: 0.5909\n",
      "Epoch 5/25\n",
      "36/36 [==============================] - 6s 175ms/step - loss: 0.6243 - accuracy: 0.7470 - val_loss: 0.6629 - val_accuracy: 0.5909\n",
      "Epoch 6/25\n",
      "36/36 [==============================] - 6s 159ms/step - loss: 0.5838 - accuracy: 0.7575 - val_loss: 0.6671 - val_accuracy: 0.7273\n",
      "Epoch 7/25\n",
      "36/36 [==============================] - 6s 165ms/step - loss: 0.5450 - accuracy: 0.7798 - val_loss: 0.6771 - val_accuracy: 0.6364\n",
      "Epoch 8/25\n",
      "36/36 [==============================] - 6s 164ms/step - loss: 0.5335 - accuracy: 0.7841 - val_loss: 0.6057 - val_accuracy: 0.6818\n",
      "Epoch 9/25\n",
      "36/36 [==============================] - 5s 150ms/step - loss: 0.4944 - accuracy: 0.8035 - val_loss: 0.5646 - val_accuracy: 0.6818\n",
      "Epoch 10/25\n",
      "36/36 [==============================] - 7s 195ms/step - loss: 0.4565 - accuracy: 0.8230 - val_loss: 0.5349 - val_accuracy: 0.7727\n",
      "Epoch 11/25\n",
      "36/36 [==============================] - 7s 192ms/step - loss: 0.4181 - accuracy: 0.8429 - val_loss: 0.5472 - val_accuracy: 0.7727\n",
      "Epoch 12/25\n",
      "36/36 [==============================] - 6s 175ms/step - loss: 0.4068 - accuracy: 0.8458 - val_loss: 0.6044 - val_accuracy: 0.6818\n",
      "Epoch 13/25\n",
      "36/36 [==============================] - 7s 186ms/step - loss: 0.4458 - accuracy: 0.8268 - val_loss: 0.5591 - val_accuracy: 0.6818\n",
      "Epoch 14/25\n",
      "36/36 [==============================] - 6s 162ms/step - loss: 0.3964 - accuracy: 0.8448 - val_loss: 0.6546 - val_accuracy: 0.7273\n",
      "Epoch 15/25\n",
      "36/36 [==============================] - 7s 191ms/step - loss: 0.3121 - accuracy: 0.8818 - val_loss: 0.5378 - val_accuracy: 0.7727\n",
      "Epoch 16/25\n",
      "36/36 [==============================] - 6s 168ms/step - loss: 0.2920 - accuracy: 0.8918 - val_loss: 0.5924 - val_accuracy: 0.8182\n",
      "Epoch 17/25\n",
      "36/36 [==============================] - 6s 163ms/step - loss: 0.2916 - accuracy: 0.8818 - val_loss: 0.4914 - val_accuracy: 0.7727\n",
      "Epoch 18/25\n",
      "36/36 [==============================] - 6s 164ms/step - loss: 0.2518 - accuracy: 0.9103 - val_loss: 0.6657 - val_accuracy: 0.7727\n",
      "Epoch 19/25\n",
      "36/36 [==============================] - 6s 161ms/step - loss: 0.2929 - accuracy: 0.8932 - val_loss: 0.6416 - val_accuracy: 0.6818\n",
      "Epoch 20/25\n",
      "36/36 [==============================] - 6s 166ms/step - loss: 0.2267 - accuracy: 0.9198 - val_loss: 0.5838 - val_accuracy: 0.7273\n",
      "Epoch 21/25\n",
      "36/36 [==============================] - 6s 160ms/step - loss: 0.1732 - accuracy: 0.9411 - val_loss: 0.5352 - val_accuracy: 0.7273\n",
      "Epoch 22/25\n",
      "36/36 [==============================] - 6s 163ms/step - loss: 0.1534 - accuracy: 0.9483 - val_loss: 0.6036 - val_accuracy: 0.6818\n",
      "Epoch 23/25\n",
      "36/36 [==============================] - 6s 164ms/step - loss: 0.1843 - accuracy: 0.9331 - val_loss: 0.5546 - val_accuracy: 0.7727\n",
      "Epoch 24/25\n",
      "36/36 [==============================] - 6s 162ms/step - loss: 0.1648 - accuracy: 0.9435 - val_loss: 0.8364 - val_accuracy: 0.7273\n",
      "Epoch 25/25\n",
      "36/36 [==============================] - 6s 161ms/step - loss: 0.1342 - accuracy: 0.9563 - val_loss: 0.9045 - val_accuracy: 0.7727\n",
      "Score for fold 1: loss of 1.3015071153640747; accuracy of 68.19671988487244%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/25\n",
      "36/36 [==============================] - 6s 156ms/step - loss: 1.0960 - accuracy: 0.3887 - val_loss: 0.9097 - val_accuracy: 0.4091\n",
      "Epoch 2/25\n",
      "36/36 [==============================] - 6s 170ms/step - loss: 0.8980 - accuracy: 0.5757 - val_loss: 1.0758 - val_accuracy: 0.5909\n",
      "Epoch 3/25\n",
      "36/36 [==============================] - 7s 183ms/step - loss: 0.8658 - accuracy: 0.6350 - val_loss: 0.7294 - val_accuracy: 0.6364\n",
      "Epoch 4/25\n",
      "36/36 [==============================] - 6s 174ms/step - loss: 0.7047 - accuracy: 0.7076 - val_loss: 0.5125 - val_accuracy: 0.8182\n",
      "Epoch 5/25\n",
      "36/36 [==============================] - 6s 175ms/step - loss: 0.6462 - accuracy: 0.7418 - val_loss: 0.4831 - val_accuracy: 0.7727\n",
      "Epoch 6/25\n",
      "36/36 [==============================] - 7s 181ms/step - loss: 0.5943 - accuracy: 0.7622 - val_loss: 0.4894 - val_accuracy: 0.7273\n",
      "Epoch 7/25\n",
      "36/36 [==============================] - 7s 181ms/step - loss: 0.5279 - accuracy: 0.7931 - val_loss: 0.4957 - val_accuracy: 0.7273\n",
      "Epoch 8/25\n",
      "36/36 [==============================] - 6s 173ms/step - loss: 0.4721 - accuracy: 0.8244 - val_loss: 0.5448 - val_accuracy: 0.7273\n",
      "Epoch 9/25\n",
      "36/36 [==============================] - 6s 164ms/step - loss: 0.4557 - accuracy: 0.8310 - val_loss: 0.4656 - val_accuracy: 0.7727\n",
      "Epoch 10/25\n",
      "36/36 [==============================] - 6s 165ms/step - loss: 0.3847 - accuracy: 0.8552 - val_loss: 0.4707 - val_accuracy: 0.8182\n",
      "Epoch 11/25\n",
      "36/36 [==============================] - 6s 166ms/step - loss: 0.3279 - accuracy: 0.8738 - val_loss: 0.5740 - val_accuracy: 0.7273\n",
      "Epoch 12/25\n",
      "36/36 [==============================] - 6s 160ms/step - loss: 0.3355 - accuracy: 0.8685 - val_loss: 0.5501 - val_accuracy: 0.7273\n",
      "Epoch 13/25\n",
      "36/36 [==============================] - 6s 166ms/step - loss: 0.2524 - accuracy: 0.9136 - val_loss: 0.4906 - val_accuracy: 0.7727\n",
      "Epoch 14/25\n",
      "36/36 [==============================] - 6s 161ms/step - loss: 0.2125 - accuracy: 0.9288 - val_loss: 0.5416 - val_accuracy: 0.7727\n",
      "Epoch 15/25\n",
      "36/36 [==============================] - 6s 162ms/step - loss: 0.1693 - accuracy: 0.9440 - val_loss: 0.5548 - val_accuracy: 0.8182\n",
      "Epoch 16/25\n",
      "36/36 [==============================] - 6s 167ms/step - loss: 0.1451 - accuracy: 0.9554 - val_loss: 0.7400 - val_accuracy: 0.8182\n",
      "Epoch 17/25\n",
      "36/36 [==============================] - 6s 171ms/step - loss: 0.1268 - accuracy: 0.9587 - val_loss: 0.5807 - val_accuracy: 0.7727\n",
      "Epoch 18/25\n",
      "36/36 [==============================] - 6s 165ms/step - loss: 0.1018 - accuracy: 0.9734 - val_loss: 0.7262 - val_accuracy: 0.7727\n",
      "Epoch 19/25\n",
      "36/36 [==============================] - 6s 168ms/step - loss: 0.1192 - accuracy: 0.9630 - val_loss: 0.7656 - val_accuracy: 0.8182\n",
      "Epoch 20/25\n",
      "36/36 [==============================] - 6s 174ms/step - loss: 0.1121 - accuracy: 0.9639 - val_loss: 0.7040 - val_accuracy: 0.7727\n",
      "Epoch 21/25\n",
      "36/36 [==============================] - 6s 165ms/step - loss: 0.0724 - accuracy: 0.9796 - val_loss: 0.6552 - val_accuracy: 0.8182\n",
      "Epoch 22/25\n",
      "36/36 [==============================] - 6s 165ms/step - loss: 0.0659 - accuracy: 0.9839 - val_loss: 0.8279 - val_accuracy: 0.8182\n",
      "Epoch 23/25\n",
      "36/36 [==============================] - 6s 160ms/step - loss: 0.0652 - accuracy: 0.9820 - val_loss: 0.9473 - val_accuracy: 0.7273\n",
      "Epoch 24/25\n",
      "36/36 [==============================] - 6s 167ms/step - loss: 0.0512 - accuracy: 0.9881 - val_loss: 0.9033 - val_accuracy: 0.6818\n",
      "Epoch 25/25\n",
      "36/36 [==============================] - 6s 161ms/step - loss: 0.0415 - accuracy: 0.9881 - val_loss: 0.8540 - val_accuracy: 0.7727\n",
      "Score for fold 2: loss of 1.7751476764678955; accuracy of 72.13114500045776%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/25\n",
      "36/36 [==============================] - 6s 142ms/step - loss: 1.1222 - accuracy: 0.3899 - val_loss: 1.0396 - val_accuracy: 0.3182\n",
      "Epoch 2/25\n",
      "36/36 [==============================] - 6s 167ms/step - loss: 0.9503 - accuracy: 0.5261 - val_loss: 0.7635 - val_accuracy: 0.6364\n",
      "Epoch 3/25\n",
      "36/36 [==============================] - 6s 171ms/step - loss: 0.7686 - accuracy: 0.6769 - val_loss: 0.6516 - val_accuracy: 0.7727\n",
      "Epoch 4/25\n",
      "36/36 [==============================] - 6s 170ms/step - loss: 0.6933 - accuracy: 0.7272 - val_loss: 0.6091 - val_accuracy: 0.7727\n",
      "Epoch 5/25\n",
      "36/36 [==============================] - 6s 161ms/step - loss: 0.6474 - accuracy: 0.7415 - val_loss: 0.6875 - val_accuracy: 0.7273\n",
      "Epoch 6/25\n",
      "36/36 [==============================] - 6s 163ms/step - loss: 0.5983 - accuracy: 0.7571 - val_loss: 0.5184 - val_accuracy: 0.8182\n",
      "Epoch 7/25\n",
      "36/36 [==============================] - 6s 165ms/step - loss: 0.5521 - accuracy: 0.7861 - val_loss: 0.4621 - val_accuracy: 0.8182\n",
      "Epoch 8/25\n",
      "36/36 [==============================] - 6s 160ms/step - loss: 0.5732 - accuracy: 0.7619 - val_loss: 0.4929 - val_accuracy: 0.7727\n",
      "Epoch 9/25\n",
      "36/36 [==============================] - 6s 162ms/step - loss: 0.4966 - accuracy: 0.8027 - val_loss: 0.5419 - val_accuracy: 0.8182\n",
      "Epoch 10/25\n",
      "36/36 [==============================] - 6s 170ms/step - loss: 0.4719 - accuracy: 0.8155 - val_loss: 0.4934 - val_accuracy: 0.8182\n",
      "Epoch 11/25\n",
      "36/36 [==============================] - 6s 174ms/step - loss: 0.4459 - accuracy: 0.8302 - val_loss: 0.5252 - val_accuracy: 0.8182\n",
      "Epoch 12/25\n",
      "36/36 [==============================] - 6s 177ms/step - loss: 0.4174 - accuracy: 0.8273 - val_loss: 0.5911 - val_accuracy: 0.8182\n",
      "Epoch 13/25\n",
      "36/36 [==============================] - 6s 179ms/step - loss: 0.3606 - accuracy: 0.8624 - val_loss: 0.4912 - val_accuracy: 0.7727\n",
      "Epoch 14/25\n",
      "36/36 [==============================] - 6s 177ms/step - loss: 0.3831 - accuracy: 0.8539 - val_loss: 0.5459 - val_accuracy: 0.7727\n",
      "Epoch 15/25\n",
      "36/36 [==============================] - 7s 183ms/step - loss: 0.3132 - accuracy: 0.8843 - val_loss: 0.5541 - val_accuracy: 0.8182\n",
      "Epoch 16/25\n",
      "36/36 [==============================] - 6s 167ms/step - loss: 0.2706 - accuracy: 0.8994 - val_loss: 0.4987 - val_accuracy: 0.8182\n",
      "Epoch 17/25\n",
      "36/36 [==============================] - 6s 160ms/step - loss: 0.2398 - accuracy: 0.9103 - val_loss: 0.5882 - val_accuracy: 0.8182\n",
      "Epoch 18/25\n",
      "36/36 [==============================] - 6s 167ms/step - loss: 0.2340 - accuracy: 0.9146 - val_loss: 0.4666 - val_accuracy: 0.8636\n",
      "Epoch 19/25\n",
      "36/36 [==============================] - 6s 160ms/step - loss: 0.2499 - accuracy: 0.9037 - val_loss: 0.6992 - val_accuracy: 0.8182\n",
      "Epoch 20/25\n",
      "36/36 [==============================] - 6s 167ms/step - loss: 0.1901 - accuracy: 0.9326 - val_loss: 0.8724 - val_accuracy: 0.7273\n",
      "Epoch 21/25\n",
      "36/36 [==============================] - 6s 163ms/step - loss: 0.1871 - accuracy: 0.9279 - val_loss: 0.8218 - val_accuracy: 0.8182\n",
      "Epoch 22/25\n",
      "36/36 [==============================] - 6s 161ms/step - loss: 0.1388 - accuracy: 0.9564 - val_loss: 0.7126 - val_accuracy: 0.8636\n",
      "Epoch 23/25\n",
      "36/36 [==============================] - 6s 165ms/step - loss: 0.1362 - accuracy: 0.9564 - val_loss: 0.7735 - val_accuracy: 0.8636\n",
      "Epoch 24/25\n",
      "36/36 [==============================] - 6s 161ms/step - loss: 0.1118 - accuracy: 0.9654 - val_loss: 0.6800 - val_accuracy: 0.8636\n",
      "Epoch 25/25\n",
      "36/36 [==============================] - 6s 162ms/step - loss: 0.1125 - accuracy: 0.9625 - val_loss: 1.0408 - val_accuracy: 0.8182\n",
      "Score for fold 3: loss of 1.3856276273727417; accuracy of 71.05262875556946%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/25\n",
      "36/36 [==============================] - 6s 154ms/step - loss: 1.0625 - accuracy: 0.4507 - val_loss: 0.8282 - val_accuracy: 0.5909\n",
      "Epoch 2/25\n",
      "36/36 [==============================] - 6s 159ms/step - loss: 0.8413 - accuracy: 0.6328 - val_loss: 0.5576 - val_accuracy: 0.8182\n",
      "Epoch 3/25\n",
      "36/36 [==============================] - 6s 175ms/step - loss: 0.7617 - accuracy: 0.6883 - val_loss: 0.5639 - val_accuracy: 0.6818\n",
      "Epoch 4/25\n",
      "36/36 [==============================] - 6s 172ms/step - loss: 0.7033 - accuracy: 0.7154 - val_loss: 0.5811 - val_accuracy: 0.7273\n",
      "Epoch 5/25\n",
      "36/36 [==============================] - 6s 163ms/step - loss: 0.6762 - accuracy: 0.7177 - val_loss: 0.5934 - val_accuracy: 0.7273\n",
      "Epoch 6/25\n",
      "36/36 [==============================] - 7s 187ms/step - loss: 0.6136 - accuracy: 0.7457 - val_loss: 0.5316 - val_accuracy: 0.8182\n",
      "Epoch 7/25\n",
      "36/36 [==============================] - 6s 176ms/step - loss: 0.6154 - accuracy: 0.7500 - val_loss: 0.4944 - val_accuracy: 0.8182\n",
      "Epoch 8/25\n",
      "36/36 [==============================] - 6s 162ms/step - loss: 0.5555 - accuracy: 0.7770 - val_loss: 0.4932 - val_accuracy: 0.8182\n",
      "Epoch 9/25\n",
      "36/36 [==============================] - 6s 165ms/step - loss: 0.5153 - accuracy: 0.7965 - val_loss: 0.3600 - val_accuracy: 0.8182\n",
      "Epoch 10/25\n",
      "36/36 [==============================] - 6s 163ms/step - loss: 0.5067 - accuracy: 0.8065 - val_loss: 0.3823 - val_accuracy: 0.7727\n",
      "Epoch 11/25\n",
      "36/36 [==============================] - 6s 170ms/step - loss: 0.4500 - accuracy: 0.8240 - val_loss: 0.4317 - val_accuracy: 0.7727\n",
      "Epoch 12/25\n",
      "36/36 [==============================] - 6s 166ms/step - loss: 0.4147 - accuracy: 0.8378 - val_loss: 0.3434 - val_accuracy: 0.8182\n",
      "Epoch 13/25\n",
      "36/36 [==============================] - 6s 165ms/step - loss: 0.3722 - accuracy: 0.8634 - val_loss: 0.3878 - val_accuracy: 0.8636\n",
      "Epoch 14/25\n",
      "36/36 [==============================] - 6s 163ms/step - loss: 0.3467 - accuracy: 0.8752 - val_loss: 0.5352 - val_accuracy: 0.7273\n",
      "Epoch 15/25\n",
      "36/36 [==============================] - 5s 140ms/step - loss: 0.3193 - accuracy: 0.8876 - val_loss: 0.3824 - val_accuracy: 0.8182\n",
      "Epoch 16/25\n",
      "36/36 [==============================] - 6s 178ms/step - loss: 0.2901 - accuracy: 0.8942 - val_loss: 0.3781 - val_accuracy: 0.8182\n",
      "Epoch 17/25\n",
      "36/36 [==============================] - 7s 192ms/step - loss: 0.2341 - accuracy: 0.9222 - val_loss: 0.3899 - val_accuracy: 0.7727\n",
      "Epoch 18/25\n",
      "36/36 [==============================] - 7s 182ms/step - loss: 0.2219 - accuracy: 0.9241 - val_loss: 0.3437 - val_accuracy: 0.8182\n",
      "Epoch 19/25\n",
      "36/36 [==============================] - 7s 185ms/step - loss: 0.1871 - accuracy: 0.9374 - val_loss: 0.4228 - val_accuracy: 0.8636\n",
      "Epoch 20/25\n",
      "36/36 [==============================] - 6s 179ms/step - loss: 0.1951 - accuracy: 0.9322 - val_loss: 0.3853 - val_accuracy: 0.8636\n",
      "Epoch 21/25\n",
      "36/36 [==============================] - 7s 181ms/step - loss: 0.1478 - accuracy: 0.9530 - val_loss: 0.5775 - val_accuracy: 0.8182\n",
      "Epoch 22/25\n",
      "36/36 [==============================] - 6s 175ms/step - loss: 0.1689 - accuracy: 0.9374 - val_loss: 0.4249 - val_accuracy: 0.7727\n",
      "Epoch 23/25\n",
      "36/36 [==============================] - 6s 166ms/step - loss: 0.1223 - accuracy: 0.9578 - val_loss: 0.4505 - val_accuracy: 0.8182\n",
      "Epoch 24/25\n",
      "36/36 [==============================] - 6s 163ms/step - loss: 0.1296 - accuracy: 0.9625 - val_loss: 0.4905 - val_accuracy: 0.8636\n",
      "Epoch 25/25\n",
      "36/36 [==============================] - 6s 171ms/step - loss: 0.0737 - accuracy: 0.9820 - val_loss: 0.5178 - val_accuracy: 0.8636\n",
      "Score for fold 4: loss of 1.4334542751312256; accuracy of 68.75%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/25\n",
      "36/36 [==============================] - 6s 151ms/step - loss: 1.1040 - accuracy: 0.3999 - val_loss: 0.8482 - val_accuracy: 0.5909\n",
      "Epoch 2/25\n",
      "36/36 [==============================] - 7s 193ms/step - loss: 0.8968 - accuracy: 0.6044 - val_loss: 0.6871 - val_accuracy: 0.6364\n",
      "Epoch 3/25\n",
      "36/36 [==============================] - 7s 190ms/step - loss: 0.7771 - accuracy: 0.6722 - val_loss: 0.6915 - val_accuracy: 0.7727\n",
      "Epoch 4/25\n",
      "36/36 [==============================] - 7s 188ms/step - loss: 0.7296 - accuracy: 0.6893 - val_loss: 0.5616 - val_accuracy: 0.6364\n",
      "Epoch 5/25\n",
      "36/36 [==============================] - 6s 163ms/step - loss: 0.6996 - accuracy: 0.7125 - val_loss: 0.5753 - val_accuracy: 0.7273\n",
      "Epoch 6/25\n",
      "36/36 [==============================] - 6s 160ms/step - loss: 0.6484 - accuracy: 0.7453 - val_loss: 0.5251 - val_accuracy: 0.7727\n",
      "Epoch 7/25\n",
      "36/36 [==============================] - 6s 171ms/step - loss: 0.6154 - accuracy: 0.7571 - val_loss: 0.4993 - val_accuracy: 0.7727\n",
      "Epoch 8/25\n",
      "36/36 [==============================] - 6s 162ms/step - loss: 0.5909 - accuracy: 0.7694 - val_loss: 0.5236 - val_accuracy: 0.7273\n",
      "Epoch 9/25\n",
      "36/36 [==============================] - 6s 178ms/step - loss: 0.5587 - accuracy: 0.7804 - val_loss: 0.5601 - val_accuracy: 0.7727\n",
      "Epoch 10/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 6s 159ms/step - loss: 0.5526 - accuracy: 0.7799 - val_loss: 0.5695 - val_accuracy: 0.7727\n",
      "Epoch 11/25\n",
      "36/36 [==============================] - 6s 163ms/step - loss: 0.5149 - accuracy: 0.8036 - val_loss: 0.5651 - val_accuracy: 0.7273\n",
      "Epoch 12/25\n",
      "36/36 [==============================] - 6s 169ms/step - loss: 0.4791 - accuracy: 0.8174 - val_loss: 0.5124 - val_accuracy: 0.7727\n",
      "Epoch 13/25\n",
      "36/36 [==============================] - 6s 168ms/step - loss: 0.4541 - accuracy: 0.8292 - val_loss: 0.5202 - val_accuracy: 0.8182\n",
      "Epoch 14/25\n",
      "36/36 [==============================] - 6s 160ms/step - loss: 0.4453 - accuracy: 0.8311 - val_loss: 0.7413 - val_accuracy: 0.8182\n",
      "Epoch 15/25\n",
      "36/36 [==============================] - 6s 162ms/step - loss: 0.4348 - accuracy: 0.8321 - val_loss: 0.5875 - val_accuracy: 0.7727\n",
      "Epoch 16/25\n",
      "36/36 [==============================] - 6s 162ms/step - loss: 0.4008 - accuracy: 0.8601 - val_loss: 0.6985 - val_accuracy: 0.8182\n",
      "Epoch 17/25\n",
      "36/36 [==============================] - 6s 164ms/step - loss: 0.3386 - accuracy: 0.8861 - val_loss: 0.8879 - val_accuracy: 0.7273\n",
      "Epoch 18/25\n",
      "36/36 [==============================] - 6s 158ms/step - loss: 0.3104 - accuracy: 0.8899 - val_loss: 0.7233 - val_accuracy: 0.7727\n",
      "Epoch 19/25\n",
      "36/36 [==============================] - 6s 161ms/step - loss: 0.3168 - accuracy: 0.8880 - val_loss: 0.8808 - val_accuracy: 0.7727\n",
      "Epoch 20/25\n",
      "36/36 [==============================] - 6s 162ms/step - loss: 0.2655 - accuracy: 0.9089 - val_loss: 1.0301 - val_accuracy: 0.7727\n",
      "Epoch 21/25\n",
      "36/36 [==============================] - 6s 160ms/step - loss: 0.2786 - accuracy: 0.8971 - val_loss: 0.7341 - val_accuracy: 0.7273\n",
      "Epoch 22/25\n",
      "36/36 [==============================] - 6s 177ms/step - loss: 0.2540 - accuracy: 0.9103 - val_loss: 1.0261 - val_accuracy: 0.7273\n",
      "Epoch 23/25\n",
      "36/36 [==============================] - 6s 180ms/step - loss: 0.2030 - accuracy: 0.9369 - val_loss: 1.2129 - val_accuracy: 0.7273\n",
      "Epoch 24/25\n",
      "36/36 [==============================] - 6s 171ms/step - loss: 0.1887 - accuracy: 0.9374 - val_loss: 1.2122 - val_accuracy: 0.6818\n",
      "Epoch 25/25\n",
      "36/36 [==============================] - 7s 191ms/step - loss: 0.1642 - accuracy: 0.9545 - val_loss: 1.2705 - val_accuracy: 0.7273\n",
      "Score for fold 5: loss of 1.3731848001480103; accuracy of 72.03947305679321%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/25\n",
      "36/36 [==============================] - 7s 169ms/step - loss: 1.1305 - accuracy: 0.3852 - val_loss: 1.0700 - val_accuracy: 0.3636\n",
      "Epoch 2/25\n",
      "36/36 [==============================] - 6s 167ms/step - loss: 0.9747 - accuracy: 0.5176 - val_loss: 0.7868 - val_accuracy: 0.6818\n",
      "Epoch 3/25\n",
      "36/36 [==============================] - 7s 189ms/step - loss: 0.8204 - accuracy: 0.6537 - val_loss: 0.8165 - val_accuracy: 0.7273\n",
      "Epoch 4/25\n",
      "36/36 [==============================] - 7s 196ms/step - loss: 0.7638 - accuracy: 0.6694 - val_loss: 0.7619 - val_accuracy: 0.6818\n",
      "Epoch 5/25\n",
      "36/36 [==============================] - 6s 178ms/step - loss: 0.7111 - accuracy: 0.6945 - val_loss: 0.6833 - val_accuracy: 0.6818\n",
      "Epoch 6/25\n",
      "36/36 [==============================] - 5s 149ms/step - loss: 0.6522 - accuracy: 0.7324 - val_loss: 0.7471 - val_accuracy: 0.6818\n",
      "Epoch 7/25\n",
      "36/36 [==============================] - 6s 171ms/step - loss: 0.6518 - accuracy: 0.7272 - val_loss: 0.7310 - val_accuracy: 0.5909\n",
      "Epoch 8/25\n",
      "36/36 [==============================] - 6s 177ms/step - loss: 0.5898 - accuracy: 0.7728 - val_loss: 0.6527 - val_accuracy: 0.7273\n",
      "Epoch 9/25\n",
      "36/36 [==============================] - 6s 166ms/step - loss: 0.5798 - accuracy: 0.7680 - val_loss: 0.6590 - val_accuracy: 0.6364\n",
      "Epoch 10/25\n",
      "36/36 [==============================] - 6s 166ms/step - loss: 0.5540 - accuracy: 0.7770 - val_loss: 0.6634 - val_accuracy: 0.6818\n",
      "Epoch 11/25\n",
      "36/36 [==============================] - 6s 164ms/step - loss: 0.5297 - accuracy: 0.7998 - val_loss: 0.6776 - val_accuracy: 0.6818\n",
      "Epoch 12/25\n",
      "36/36 [==============================] - 6s 170ms/step - loss: 0.4910 - accuracy: 0.8145 - val_loss: 0.7423 - val_accuracy: 0.6364\n",
      "Epoch 13/25\n",
      "36/36 [==============================] - 6s 170ms/step - loss: 0.4669 - accuracy: 0.8197 - val_loss: 0.5865 - val_accuracy: 0.7273\n",
      "Epoch 14/25\n",
      "36/36 [==============================] - 6s 166ms/step - loss: 0.4262 - accuracy: 0.8439 - val_loss: 0.6379 - val_accuracy: 0.7273\n",
      "Epoch 15/25\n",
      "36/36 [==============================] - 6s 174ms/step - loss: 0.4005 - accuracy: 0.8515 - val_loss: 0.5547 - val_accuracy: 0.8182\n",
      "Epoch 16/25\n",
      "36/36 [==============================] - 6s 173ms/step - loss: 0.4042 - accuracy: 0.8406 - val_loss: 0.6003 - val_accuracy: 0.7727\n",
      "Epoch 17/25\n",
      "36/36 [==============================] - 6s 162ms/step - loss: 0.3471 - accuracy: 0.8705 - val_loss: 0.6474 - val_accuracy: 0.7727\n",
      "Epoch 18/25\n",
      "36/36 [==============================] - 6s 171ms/step - loss: 0.3172 - accuracy: 0.8800 - val_loss: 0.5645 - val_accuracy: 0.8636\n",
      "Epoch 19/25\n",
      "36/36 [==============================] - 6s 168ms/step - loss: 0.3124 - accuracy: 0.8828 - val_loss: 0.6514 - val_accuracy: 0.8182\n",
      "Epoch 20/25\n",
      "36/36 [==============================] - 6s 162ms/step - loss: 0.2842 - accuracy: 0.8952 - val_loss: 0.6746 - val_accuracy: 0.8182\n",
      "Epoch 21/25\n",
      "36/36 [==============================] - 6s 166ms/step - loss: 0.2406 - accuracy: 0.9127 - val_loss: 0.7923 - val_accuracy: 0.7727\n",
      "Epoch 22/25\n",
      "36/36 [==============================] - 6s 166ms/step - loss: 0.2468 - accuracy: 0.9103 - val_loss: 0.7390 - val_accuracy: 0.7727\n",
      "Epoch 23/25\n",
      "36/36 [==============================] - 6s 174ms/step - loss: 0.2169 - accuracy: 0.9222 - val_loss: 0.7191 - val_accuracy: 0.7273\n",
      "Epoch 24/25\n",
      "36/36 [==============================] - 6s 163ms/step - loss: 0.2056 - accuracy: 0.9265 - val_loss: 0.6880 - val_accuracy: 0.8636\n",
      "Epoch 25/25\n",
      "36/36 [==============================] - 6s 167ms/step - loss: 0.1831 - accuracy: 0.9355 - val_loss: 0.7478 - val_accuracy: 0.8182\n",
      "Score for fold 6: loss of 1.1586271524429321; accuracy of 71.71052694320679%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/25\n",
      "36/36 [==============================] - 7s 184ms/step - loss: 1.0446 - accuracy: 0.4848 - val_loss: 0.9645 - val_accuracy: 0.6364\n",
      "Epoch 2/25\n",
      "36/36 [==============================] - 6s 168ms/step - loss: 0.8509 - accuracy: 0.6319 - val_loss: 0.8907 - val_accuracy: 0.6364\n",
      "Epoch 3/25\n",
      "36/36 [==============================] - 7s 191ms/step - loss: 0.7430 - accuracy: 0.6893 - val_loss: 0.8980 - val_accuracy: 0.6818\n",
      "Epoch 4/25\n",
      "36/36 [==============================] - 7s 187ms/step - loss: 0.7215 - accuracy: 0.7030 - val_loss: 0.8402 - val_accuracy: 0.6818\n",
      "Epoch 5/25\n",
      "36/36 [==============================] - 6s 174ms/step - loss: 0.6419 - accuracy: 0.7438 - val_loss: 0.7927 - val_accuracy: 0.6364\n",
      "Epoch 6/25\n",
      "36/36 [==============================] - 6s 175ms/step - loss: 0.6190 - accuracy: 0.7538 - val_loss: 0.7786 - val_accuracy: 0.7273\n",
      "Epoch 7/25\n",
      "36/36 [==============================] - 6s 165ms/step - loss: 0.5963 - accuracy: 0.7628 - val_loss: 0.7246 - val_accuracy: 0.6818\n",
      "Epoch 8/25\n",
      "36/36 [==============================] - 8s 216ms/step - loss: 0.5377 - accuracy: 0.7917 - val_loss: 0.5991 - val_accuracy: 0.7273\n",
      "Epoch 9/25\n",
      "36/36 [==============================] - 9s 260ms/step - loss: 0.4678 - accuracy: 0.8159 - val_loss: 0.5915 - val_accuracy: 0.7727\n",
      "Epoch 10/25\n",
      "36/36 [==============================] - 8s 210ms/step - loss: 0.4209 - accuracy: 0.8416 - val_loss: 0.6333 - val_accuracy: 0.7273\n",
      "Epoch 11/25\n",
      "36/36 [==============================] - 7s 203ms/step - loss: 0.3632 - accuracy: 0.8615 - val_loss: 0.6107 - val_accuracy: 0.7273\n",
      "Epoch 12/25\n",
      "36/36 [==============================] - 7s 191ms/step - loss: 0.3542 - accuracy: 0.8605 - val_loss: 0.4958 - val_accuracy: 0.7273\n",
      "Epoch 13/25\n",
      "36/36 [==============================] - 7s 179ms/step - loss: 0.3073 - accuracy: 0.8871 - val_loss: 0.4182 - val_accuracy: 0.7727\n",
      "Epoch 14/25\n",
      "36/36 [==============================] - 6s 178ms/step - loss: 0.2589 - accuracy: 0.9084 - val_loss: 0.5256 - val_accuracy: 0.7727\n",
      "Epoch 15/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 6s 176ms/step - loss: 0.2248 - accuracy: 0.9260 - val_loss: 0.4681 - val_accuracy: 0.8182\n",
      "Epoch 16/25\n",
      "36/36 [==============================] - 6s 164ms/step - loss: 0.1975 - accuracy: 0.9326 - val_loss: 0.4377 - val_accuracy: 0.7727\n",
      "Epoch 17/25\n",
      "36/36 [==============================] - 6s 171ms/step - loss: 0.1667 - accuracy: 0.9492 - val_loss: 0.5017 - val_accuracy: 0.7727\n",
      "Epoch 18/25\n",
      "36/36 [==============================] - 6s 173ms/step - loss: 0.1238 - accuracy: 0.9654 - val_loss: 0.4797 - val_accuracy: 0.8182\n",
      "Epoch 19/25\n",
      "36/36 [==============================] - 6s 173ms/step - loss: 0.1036 - accuracy: 0.9692 - val_loss: 0.6511 - val_accuracy: 0.6818\n",
      "Epoch 20/25\n",
      "36/36 [==============================] - 6s 175ms/step - loss: 0.1282 - accuracy: 0.9597 - val_loss: 0.6398 - val_accuracy: 0.8182\n",
      "Epoch 21/25\n",
      "36/36 [==============================] - 6s 172ms/step - loss: 0.1217 - accuracy: 0.9658 - val_loss: 0.7268 - val_accuracy: 0.8182\n",
      "Epoch 22/25\n",
      "36/36 [==============================] - 6s 173ms/step - loss: 0.0916 - accuracy: 0.9734 - val_loss: 0.7342 - val_accuracy: 0.8182\n",
      "Epoch 23/25\n",
      "36/36 [==============================] - 6s 178ms/step - loss: 0.0686 - accuracy: 0.9810 - val_loss: 0.4847 - val_accuracy: 0.8182\n",
      "Epoch 24/25\n",
      "36/36 [==============================] - 6s 168ms/step - loss: 0.0601 - accuracy: 0.9858 - val_loss: 0.5911 - val_accuracy: 0.7727\n",
      "Epoch 25/25\n",
      "36/36 [==============================] - 6s 176ms/step - loss: 0.0489 - accuracy: 0.9891 - val_loss: 0.5652 - val_accuracy: 0.7727\n",
      "Score for fold 7: loss of 1.606253981590271; accuracy of 73.3552634716034%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/25\n",
      "36/36 [==============================] - 7s 172ms/step - loss: 1.0821 - accuracy: 0.4440 - val_loss: 0.9070 - val_accuracy: 0.4091\n",
      "Epoch 2/25\n",
      "36/36 [==============================] - 6s 167ms/step - loss: 0.8489 - accuracy: 0.6333 - val_loss: 0.8226 - val_accuracy: 0.7273\n",
      "Epoch 3/25\n",
      "36/36 [==============================] - 6s 172ms/step - loss: 0.7896 - accuracy: 0.6622 - val_loss: 0.7323 - val_accuracy: 0.7273\n",
      "Epoch 4/25\n",
      "36/36 [==============================] - 6s 178ms/step - loss: 0.6940 - accuracy: 0.7182 - val_loss: 0.8688 - val_accuracy: 0.6364\n",
      "Epoch 5/25\n",
      "36/36 [==============================] - 7s 181ms/step - loss: 0.6617 - accuracy: 0.7306 - val_loss: 0.8151 - val_accuracy: 0.6818\n",
      "Epoch 6/25\n",
      "36/36 [==============================] - 6s 179ms/step - loss: 0.6333 - accuracy: 0.7391 - val_loss: 0.6537 - val_accuracy: 0.6818\n",
      "Epoch 7/25\n",
      "36/36 [==============================] - 6s 166ms/step - loss: 0.5994 - accuracy: 0.7690 - val_loss: 0.6357 - val_accuracy: 0.7273\n",
      "Epoch 8/25\n",
      "36/36 [==============================] - 6s 171ms/step - loss: 0.5972 - accuracy: 0.7557 - val_loss: 0.5955 - val_accuracy: 0.6818\n",
      "Epoch 9/25\n",
      "36/36 [==============================] - 5s 143ms/step - loss: 0.5518 - accuracy: 0.7903 - val_loss: 0.6462 - val_accuracy: 0.7273\n",
      "Epoch 10/25\n",
      "36/36 [==============================] - 6s 172ms/step - loss: 0.5189 - accuracy: 0.8050 - val_loss: 0.5327 - val_accuracy: 0.7273\n",
      "Epoch 11/25\n",
      "36/36 [==============================] - 6s 168ms/step - loss: 0.5107 - accuracy: 0.8060 - val_loss: 0.5534 - val_accuracy: 0.7727\n",
      "Epoch 12/25\n",
      "36/36 [==============================] - 6s 173ms/step - loss: 0.4315 - accuracy: 0.8420 - val_loss: 0.5525 - val_accuracy: 0.7727\n",
      "Epoch 13/25\n",
      "36/36 [==============================] - 6s 179ms/step - loss: 0.4283 - accuracy: 0.8354 - val_loss: 0.5612 - val_accuracy: 0.6364\n",
      "Epoch 14/25\n",
      "36/36 [==============================] - 7s 191ms/step - loss: 0.4192 - accuracy: 0.8368 - val_loss: 0.5542 - val_accuracy: 0.7727\n",
      "Epoch 15/25\n",
      "36/36 [==============================] - 7s 192ms/step - loss: 0.3855 - accuracy: 0.8548 - val_loss: 0.7262 - val_accuracy: 0.5909\n",
      "Epoch 16/25\n",
      "36/36 [==============================] - 7s 185ms/step - loss: 0.3778 - accuracy: 0.8553 - val_loss: 0.5220 - val_accuracy: 0.7727\n",
      "Epoch 17/25\n",
      "36/36 [==============================] - 7s 188ms/step - loss: 0.3142 - accuracy: 0.8828 - val_loss: 0.7210 - val_accuracy: 0.8182\n",
      "Epoch 18/25\n",
      "36/36 [==============================] - 7s 205ms/step - loss: 0.2803 - accuracy: 0.8966 - val_loss: 0.4706 - val_accuracy: 0.7727\n",
      "Epoch 19/25\n",
      "36/36 [==============================] - 7s 190ms/step - loss: 0.2616 - accuracy: 0.9089 - val_loss: 0.6001 - val_accuracy: 0.7727\n",
      "Epoch 20/25\n",
      "36/36 [==============================] - 7s 192ms/step - loss: 0.2457 - accuracy: 0.9070 - val_loss: 0.5909 - val_accuracy: 0.7727\n",
      "Epoch 21/25\n",
      "36/36 [==============================] - 7s 187ms/step - loss: 0.2055 - accuracy: 0.9317 - val_loss: 0.4626 - val_accuracy: 0.7727\n",
      "Epoch 22/25\n",
      "36/36 [==============================] - 7s 193ms/step - loss: 0.1944 - accuracy: 0.9317 - val_loss: 0.5169 - val_accuracy: 0.7727\n",
      "Epoch 23/25\n",
      "36/36 [==============================] - 7s 182ms/step - loss: 0.1990 - accuracy: 0.9326 - val_loss: 0.5242 - val_accuracy: 0.8182\n",
      "Epoch 24/25\n",
      "36/36 [==============================] - 6s 170ms/step - loss: 0.1493 - accuracy: 0.9583 - val_loss: 0.6081 - val_accuracy: 0.8182\n",
      "Epoch 25/25\n",
      "36/36 [==============================] - 6s 173ms/step - loss: 0.1396 - accuracy: 0.9554 - val_loss: 0.9215 - val_accuracy: 0.7727\n",
      "Score for fold 8: loss of 1.1515579223632812; accuracy of 68.09210777282715%\n"
     ]
    }
   ],
   "source": [
    "inputs = np.concatenate((X_train, X_test), axis=0)\n",
    "targets = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "num_folds = 8\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "fold_no = 1\n",
    "acc_per_fold1 = []\n",
    "loss_per_fold1 = []\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "    model = Sequential()\n",
    "\n",
    "        \n",
    "    model.add(Conv2D(128, kernel_size = (3, 3)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "\n",
    "    model.add(Conv2D(64, kernel_size = (3, 3)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "    \n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    history = model.fit(inputs[train],targets[train],epochs = 25,batch_size = 60, validation_split = 0.01)\n",
    "    scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold1.append(scores[1] * 100)\n",
    "    loss_per_fold1.append(scores[0])\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "78d8a648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/25\n",
      "36/36 [==============================] - 5s 128ms/step - loss: 2.4942 - accuracy: 0.4528 - val_loss: 1.6739 - val_accuracy: 0.7273\n",
      "Epoch 2/25\n",
      "36/36 [==============================] - 6s 175ms/step - loss: 1.4701 - accuracy: 0.6179 - val_loss: 1.2043 - val_accuracy: 0.7273\n",
      "Epoch 3/25\n",
      "36/36 [==============================] - 6s 172ms/step - loss: 1.1660 - accuracy: 0.6820 - val_loss: 1.0130 - val_accuracy: 0.6818\n",
      "Epoch 4/25\n",
      "36/36 [==============================] - 7s 198ms/step - loss: 1.0496 - accuracy: 0.6877 - val_loss: 0.9147 - val_accuracy: 0.7273\n",
      "Epoch 5/25\n",
      "36/36 [==============================] - 7s 195ms/step - loss: 0.9559 - accuracy: 0.6986 - val_loss: 0.8852 - val_accuracy: 0.6818\n",
      "Epoch 6/25\n",
      "36/36 [==============================] - 7s 197ms/step - loss: 0.8955 - accuracy: 0.7105 - val_loss: 0.9447 - val_accuracy: 0.6818\n",
      "Epoch 7/25\n",
      "36/36 [==============================] - 7s 194ms/step - loss: 0.8413 - accuracy: 0.7290 - val_loss: 0.7548 - val_accuracy: 0.7727\n",
      "Epoch 8/25\n",
      "36/36 [==============================] - 7s 199ms/step - loss: 0.8121 - accuracy: 0.7247 - val_loss: 0.7435 - val_accuracy: 0.7727\n",
      "Epoch 9/25\n",
      "36/36 [==============================] - 7s 192ms/step - loss: 0.7641 - accuracy: 0.7537 - val_loss: 0.7218 - val_accuracy: 0.7727\n",
      "Epoch 10/25\n",
      "36/36 [==============================] - 7s 186ms/step - loss: 0.7162 - accuracy: 0.7727 - val_loss: 0.7198 - val_accuracy: 0.7727\n",
      "Epoch 11/25\n",
      "36/36 [==============================] - 7s 194ms/step - loss: 0.7467 - accuracy: 0.7546 - val_loss: 0.7021 - val_accuracy: 0.7273\n",
      "Epoch 12/25\n",
      "36/36 [==============================] - 7s 185ms/step - loss: 0.6912 - accuracy: 0.7784 - val_loss: 0.6754 - val_accuracy: 0.8182\n",
      "Epoch 13/25\n",
      "36/36 [==============================] - 7s 192ms/step - loss: 0.6420 - accuracy: 0.8011 - val_loss: 0.6602 - val_accuracy: 0.7273\n",
      "Epoch 14/25\n",
      "36/36 [==============================] - 7s 181ms/step - loss: 0.6382 - accuracy: 0.8078 - val_loss: 0.6016 - val_accuracy: 0.7727\n",
      "Epoch 15/25\n",
      "36/36 [==============================] - 6s 178ms/step - loss: 0.6256 - accuracy: 0.8078 - val_loss: 0.6137 - val_accuracy: 0.8182\n",
      "Epoch 16/25\n",
      "36/36 [==============================] - 7s 184ms/step - loss: 0.5994 - accuracy: 0.8182 - val_loss: 0.6336 - val_accuracy: 0.6818\n",
      "Epoch 17/25\n",
      "36/36 [==============================] - 6s 165ms/step - loss: 0.5726 - accuracy: 0.8287 - val_loss: 0.6282 - val_accuracy: 0.7727\n",
      "Epoch 18/25\n",
      "36/36 [==============================] - 6s 164ms/step - loss: 0.5609 - accuracy: 0.8382 - val_loss: 0.6292 - val_accuracy: 0.7727\n",
      "Epoch 19/25\n",
      "36/36 [==============================] - 6s 164ms/step - loss: 0.5532 - accuracy: 0.8486 - val_loss: 0.7643 - val_accuracy: 0.7273\n",
      "Epoch 20/25\n",
      "36/36 [==============================] - 6s 165ms/step - loss: 0.5067 - accuracy: 0.8652 - val_loss: 0.6782 - val_accuracy: 0.7727\n",
      "Epoch 21/25\n",
      "36/36 [==============================] - 6s 165ms/step - loss: 0.5013 - accuracy: 0.8719 - val_loss: 0.7016 - val_accuracy: 0.7273\n",
      "Epoch 22/25\n",
      "36/36 [==============================] - 6s 162ms/step - loss: 0.4844 - accuracy: 0.8723 - val_loss: 0.6364 - val_accuracy: 0.7273\n",
      "Epoch 23/25\n",
      "36/36 [==============================] - 6s 161ms/step - loss: 0.4592 - accuracy: 0.8842 - val_loss: 0.5976 - val_accuracy: 0.7727\n",
      "Epoch 24/25\n",
      "36/36 [==============================] - 6s 175ms/step - loss: 0.4853 - accuracy: 0.8652 - val_loss: 0.6477 - val_accuracy: 0.7727\n",
      "Epoch 25/25\n",
      "36/36 [==============================] - 6s 162ms/step - loss: 0.4170 - accuracy: 0.9093 - val_loss: 0.6720 - val_accuracy: 0.7273\n",
      "Score for fold 1: loss of 1.0710316896438599; accuracy of 70.49180269241333%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/25\n",
      "36/36 [==============================] - 7s 170ms/step - loss: 2.6657 - accuracy: 0.4328 - val_loss: 1.8474 - val_accuracy: 0.6364\n",
      "Epoch 2/25\n",
      "36/36 [==============================] - 6s 168ms/step - loss: 1.7270 - accuracy: 0.5619 - val_loss: 1.3093 - val_accuracy: 0.6818\n",
      "Epoch 3/25\n",
      "36/36 [==============================] - 6s 173ms/step - loss: 1.3108 - accuracy: 0.6469 - val_loss: 1.0505 - val_accuracy: 0.7273\n",
      "Epoch 4/25\n",
      "36/36 [==============================] - 6s 175ms/step - loss: 1.1283 - accuracy: 0.6773 - val_loss: 0.9184 - val_accuracy: 0.7273\n",
      "Epoch 5/25\n",
      "36/36 [==============================] - 6s 169ms/step - loss: 0.9883 - accuracy: 0.6934 - val_loss: 0.8173 - val_accuracy: 0.7727\n",
      "Epoch 6/25\n",
      "36/36 [==============================] - 6s 166ms/step - loss: 0.9110 - accuracy: 0.7029 - val_loss: 0.8245 - val_accuracy: 0.7727\n",
      "Epoch 7/25\n",
      "36/36 [==============================] - 6s 167ms/step - loss: 0.8467 - accuracy: 0.7224 - val_loss: 0.6761 - val_accuracy: 0.7273\n",
      "Epoch 8/25\n",
      "36/36 [==============================] - 6s 164ms/step - loss: 0.7863 - accuracy: 0.7442 - val_loss: 0.7222 - val_accuracy: 0.7273\n",
      "Epoch 9/25\n",
      "36/36 [==============================] - 6s 165ms/step - loss: 0.7691 - accuracy: 0.7485 - val_loss: 0.6663 - val_accuracy: 0.6818\n",
      "Epoch 10/25\n",
      "36/36 [==============================] - 6s 164ms/step - loss: 0.7416 - accuracy: 0.7570 - val_loss: 0.6122 - val_accuracy: 0.6818\n",
      "Epoch 11/25\n",
      "36/36 [==============================] - 6s 169ms/step - loss: 0.7311 - accuracy: 0.7513 - val_loss: 0.6871 - val_accuracy: 0.7727\n",
      "Epoch 12/25\n",
      "36/36 [==============================] - 6s 173ms/step - loss: 0.6921 - accuracy: 0.7788 - val_loss: 0.6140 - val_accuracy: 0.7727\n",
      "Epoch 13/25\n",
      "36/36 [==============================] - 6s 169ms/step - loss: 0.6897 - accuracy: 0.7693 - val_loss: 0.6195 - val_accuracy: 0.7727\n",
      "Epoch 14/25\n",
      "36/36 [==============================] - 6s 175ms/step - loss: 0.6800 - accuracy: 0.7812 - val_loss: 0.6673 - val_accuracy: 0.7727\n",
      "Epoch 15/25\n",
      "36/36 [==============================] - 6s 165ms/step - loss: 0.6444 - accuracy: 0.7926 - val_loss: 0.5566 - val_accuracy: 0.8182\n",
      "Epoch 16/25\n",
      "36/36 [==============================] - 6s 172ms/step - loss: 0.6227 - accuracy: 0.7964 - val_loss: 0.5199 - val_accuracy: 0.8182\n",
      "Epoch 17/25\n",
      "36/36 [==============================] - 7s 184ms/step - loss: 0.6380 - accuracy: 0.7912 - val_loss: 0.5650 - val_accuracy: 0.8182\n",
      "Epoch 18/25\n",
      "36/36 [==============================] - 7s 181ms/step - loss: 0.6230 - accuracy: 0.8021 - val_loss: 0.5246 - val_accuracy: 0.8182\n",
      "Epoch 19/25\n",
      "36/36 [==============================] - 6s 178ms/step - loss: 0.5955 - accuracy: 0.8168 - val_loss: 0.4856 - val_accuracy: 0.8182\n",
      "Epoch 20/25\n",
      "36/36 [==============================] - 7s 182ms/step - loss: 0.5821 - accuracy: 0.8149 - val_loss: 0.5543 - val_accuracy: 0.7727\n",
      "Epoch 21/25\n",
      "36/36 [==============================] - 6s 175ms/step - loss: 0.5871 - accuracy: 0.8187 - val_loss: 0.4857 - val_accuracy: 0.8182\n",
      "Epoch 22/25\n",
      "36/36 [==============================] - 6s 172ms/step - loss: 0.5542 - accuracy: 0.8306 - val_loss: 0.5200 - val_accuracy: 0.8636\n",
      "Epoch 23/25\n",
      "36/36 [==============================] - 6s 170ms/step - loss: 0.5370 - accuracy: 0.8391 - val_loss: 0.5233 - val_accuracy: 0.8182\n",
      "Epoch 24/25\n",
      "36/36 [==============================] - 6s 164ms/step - loss: 0.5572 - accuracy: 0.8230 - val_loss: 0.6353 - val_accuracy: 0.8182\n",
      "Epoch 25/25\n",
      "36/36 [==============================] - 6s 168ms/step - loss: 0.5583 - accuracy: 0.8234 - val_loss: 0.5382 - val_accuracy: 0.8636\n",
      "Score for fold 2: loss of 0.8827611804008484; accuracy of 72.13114500045776%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/25\n",
      "36/36 [==============================] - 6s 143ms/step - loss: 2.6457 - accuracy: 0.3928 - val_loss: 2.0035 - val_accuracy: 0.4091\n",
      "Epoch 2/25\n",
      "36/36 [==============================] - 7s 184ms/step - loss: 1.6299 - accuracy: 0.5916 - val_loss: 1.3758 - val_accuracy: 0.6818\n",
      "Epoch 3/25\n",
      "36/36 [==============================] - 6s 178ms/step - loss: 1.2995 - accuracy: 0.6442 - val_loss: 1.2336 - val_accuracy: 0.6364\n",
      "Epoch 4/25\n",
      "36/36 [==============================] - 6s 181ms/step - loss: 1.1388 - accuracy: 0.6746 - val_loss: 1.0824 - val_accuracy: 0.6364\n",
      "Epoch 5/25\n",
      "36/36 [==============================] - 6s 180ms/step - loss: 1.0198 - accuracy: 0.6926 - val_loss: 0.9862 - val_accuracy: 0.6818\n",
      "Epoch 6/25\n",
      "36/36 [==============================] - 7s 188ms/step - loss: 0.9343 - accuracy: 0.7144 - val_loss: 0.9503 - val_accuracy: 0.6818\n",
      "Epoch 7/25\n",
      "36/36 [==============================] - 7s 195ms/step - loss: 0.8995 - accuracy: 0.7097 - val_loss: 0.8703 - val_accuracy: 0.6364\n",
      "Epoch 8/25\n",
      "36/36 [==============================] - 7s 181ms/step - loss: 0.8054 - accuracy: 0.7457 - val_loss: 0.8656 - val_accuracy: 0.7273\n",
      "Epoch 9/25\n",
      "36/36 [==============================] - 7s 182ms/step - loss: 0.7835 - accuracy: 0.7538 - val_loss: 1.0396 - val_accuracy: 0.5455\n",
      "Epoch 10/25\n",
      "36/36 [==============================] - 7s 183ms/step - loss: 0.7871 - accuracy: 0.7301 - val_loss: 0.7895 - val_accuracy: 0.6818\n",
      "Epoch 11/25\n",
      "36/36 [==============================] - 6s 171ms/step - loss: 0.7670 - accuracy: 0.7457 - val_loss: 0.7938 - val_accuracy: 0.6364\n",
      "Epoch 12/25\n",
      "36/36 [==============================] - 6s 162ms/step - loss: 0.7223 - accuracy: 0.7657 - val_loss: 0.8025 - val_accuracy: 0.5909\n",
      "Epoch 13/25\n",
      "36/36 [==============================] - 6s 165ms/step - loss: 0.6985 - accuracy: 0.7685 - val_loss: 0.7748 - val_accuracy: 0.7273\n",
      "Epoch 14/25\n",
      "36/36 [==============================] - 6s 157ms/step - loss: 0.6767 - accuracy: 0.7794 - val_loss: 0.7799 - val_accuracy: 0.6364\n",
      "Epoch 15/25\n",
      "36/36 [==============================] - 6s 169ms/step - loss: 0.6661 - accuracy: 0.7751 - val_loss: 0.7641 - val_accuracy: 0.6364\n",
      "Epoch 16/25\n",
      "36/36 [==============================] - 6s 162ms/step - loss: 0.6605 - accuracy: 0.7908 - val_loss: 0.7573 - val_accuracy: 0.6818\n",
      "Epoch 17/25\n",
      "36/36 [==============================] - 6s 165ms/step - loss: 0.6197 - accuracy: 0.8060 - val_loss: 0.6999 - val_accuracy: 0.6818\n",
      "Epoch 18/25\n",
      "36/36 [==============================] - 6s 159ms/step - loss: 0.6136 - accuracy: 0.8036 - val_loss: 0.7309 - val_accuracy: 0.6818\n",
      "Epoch 19/25\n",
      "36/36 [==============================] - 6s 157ms/step - loss: 0.5993 - accuracy: 0.8126 - val_loss: 0.7082 - val_accuracy: 0.6818\n",
      "Epoch 20/25\n",
      "36/36 [==============================] - 6s 172ms/step - loss: 0.5787 - accuracy: 0.8155 - val_loss: 0.7409 - val_accuracy: 0.6818\n",
      "Epoch 21/25\n",
      "36/36 [==============================] - 7s 206ms/step - loss: 0.5680 - accuracy: 0.8283 - val_loss: 0.7696 - val_accuracy: 0.7273s: 0.5686 - accuracy: \n",
      "Epoch 22/25\n",
      "36/36 [==============================] - 7s 189ms/step - loss: 0.5552 - accuracy: 0.8330 - val_loss: 0.6962 - val_accuracy: 0.6818\n",
      "Epoch 23/25\n",
      "36/36 [==============================] - 6s 176ms/step - loss: 0.5431 - accuracy: 0.8406 - val_loss: 0.6886 - val_accuracy: 0.7273\n",
      "Epoch 24/25\n",
      "36/36 [==============================] - 6s 179ms/step - loss: 0.5118 - accuracy: 0.8496 - val_loss: 0.9430 - val_accuracy: 0.5909\n",
      "Epoch 25/25\n",
      "36/36 [==============================] - 7s 185ms/step - loss: 0.5033 - accuracy: 0.8610 - val_loss: 0.7894 - val_accuracy: 0.6818\n",
      "Score for fold 3: loss of 0.8971937894821167; accuracy of 72.69737124443054%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/25\n",
      "36/36 [==============================] - 8s 198ms/step - loss: 2.5204 - accuracy: 0.4336 - val_loss: 1.7597 - val_accuracy: 0.7727\n",
      "Epoch 2/25\n",
      "36/36 [==============================] - 7s 185ms/step - loss: 1.4957 - accuracy: 0.5830 - val_loss: 1.1205 - val_accuracy: 0.8636\n",
      "Epoch 3/25\n",
      "36/36 [==============================] - 6s 171ms/step - loss: 1.1281 - accuracy: 0.6869 - val_loss: 0.9511 - val_accuracy: 0.7727\n",
      "Epoch 4/25\n",
      "36/36 [==============================] - 5s 148ms/step - loss: 0.9755 - accuracy: 0.7078 - val_loss: 0.8650 - val_accuracy: 0.7273\n",
      "Epoch 5/25\n",
      "36/36 [==============================] - 5s 150ms/step - loss: 0.9551 - accuracy: 0.6812 - val_loss: 0.9340 - val_accuracy: 0.7727\n",
      "Epoch 6/25\n",
      "36/36 [==============================] - 6s 168ms/step - loss: 0.8723 - accuracy: 0.7168 - val_loss: 0.7560 - val_accuracy: 0.7727\n",
      "Epoch 7/25\n",
      "36/36 [==============================] - 7s 181ms/step - loss: 0.8047 - accuracy: 0.7429 - val_loss: 0.6904 - val_accuracy: 0.7727\n",
      "Epoch 8/25\n",
      "36/36 [==============================] - 6s 174ms/step - loss: 0.7975 - accuracy: 0.7343 - val_loss: 0.6900 - val_accuracy: 0.7727\n",
      "Epoch 9/25\n",
      "36/36 [==============================] - 6s 167ms/step - loss: 0.7476 - accuracy: 0.7571 - val_loss: 0.6767 - val_accuracy: 0.7727\n",
      "Epoch 10/25\n",
      "36/36 [==============================] - 6s 176ms/step - loss: 0.7090 - accuracy: 0.7775 - val_loss: 0.6638 - val_accuracy: 0.8182\n",
      "Epoch 11/25\n",
      "36/36 [==============================] - 6s 168ms/step - loss: 0.7347 - accuracy: 0.7633 - val_loss: 0.5820 - val_accuracy: 0.9091\n",
      "Epoch 12/25\n",
      "36/36 [==============================] - 6s 167ms/step - loss: 0.6745 - accuracy: 0.7927 - val_loss: 0.5635 - val_accuracy: 0.8636\n",
      "Epoch 13/25\n",
      "36/36 [==============================] - 7s 185ms/step - loss: 0.6230 - accuracy: 0.8107 - val_loss: 0.4985 - val_accuracy: 0.9091\n",
      "Epoch 14/25\n",
      "36/36 [==============================] - 6s 171ms/step - loss: 0.6172 - accuracy: 0.8193 - val_loss: 0.6109 - val_accuracy: 0.8182\n",
      "Epoch 15/25\n",
      "36/36 [==============================] - 6s 176ms/step - loss: 0.6194 - accuracy: 0.8145 - val_loss: 0.6168 - val_accuracy: 0.8182\n",
      "Epoch 16/25\n",
      "36/36 [==============================] - 6s 165ms/step - loss: 0.6322 - accuracy: 0.8069 - val_loss: 0.5483 - val_accuracy: 0.8636\n",
      "Epoch 17/25\n",
      "36/36 [==============================] - 6s 168ms/step - loss: 0.5658 - accuracy: 0.8420 - val_loss: 0.5579 - val_accuracy: 0.8636\n",
      "Epoch 18/25\n",
      "36/36 [==============================] - 6s 170ms/step - loss: 0.5261 - accuracy: 0.8506 - val_loss: 0.4834 - val_accuracy: 0.9091\n",
      "Epoch 19/25\n",
      "36/36 [==============================] - 6s 165ms/step - loss: 0.4979 - accuracy: 0.8620 - val_loss: 0.4616 - val_accuracy: 0.8636\n",
      "Epoch 20/25\n",
      "36/36 [==============================] - 6s 166ms/step - loss: 0.4657 - accuracy: 0.8843 - val_loss: 0.4393 - val_accuracy: 0.9091\n",
      "Epoch 21/25\n",
      "36/36 [==============================] - 6s 171ms/step - loss: 0.4416 - accuracy: 0.8933 - val_loss: 0.4125 - val_accuracy: 0.9091\n",
      "Epoch 22/25\n",
      "36/36 [==============================] - 6s 166ms/step - loss: 0.4482 - accuracy: 0.8861 - val_loss: 0.4968 - val_accuracy: 0.8636\n",
      "Epoch 23/25\n",
      "36/36 [==============================] - 6s 173ms/step - loss: 0.4354 - accuracy: 0.8880 - val_loss: 0.5435 - val_accuracy: 0.8182\n",
      "Epoch 24/25\n",
      "36/36 [==============================] - 6s 165ms/step - loss: 0.4025 - accuracy: 0.9070 - val_loss: 0.4783 - val_accuracy: 0.8636\n",
      "Epoch 25/25\n",
      "36/36 [==============================] - 6s 160ms/step - loss: 0.3687 - accuracy: 0.9274 - val_loss: 0.4602 - val_accuracy: 0.8182\n",
      "Score for fold 4: loss of 1.1698840856552124; accuracy of 69.40789222717285%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/25\n",
      "36/36 [==============================] - 7s 160ms/step - loss: 2.5550 - accuracy: 0.4559 - val_loss: 1.9271 - val_accuracy: 0.5000\n",
      "Epoch 2/25\n",
      "36/36 [==============================] - 6s 160ms/step - loss: 1.5119 - accuracy: 0.6309 - val_loss: 1.3786 - val_accuracy: 0.6364\n",
      "Epoch 3/25\n",
      "36/36 [==============================] - 7s 194ms/step - loss: 1.2077 - accuracy: 0.6504 - val_loss: 1.1181 - val_accuracy: 0.6818\n",
      "Epoch 4/25\n",
      "36/36 [==============================] - 7s 207ms/step - loss: 1.0215 - accuracy: 0.6950 - val_loss: 1.0657 - val_accuracy: 0.6364\n",
      "Epoch 5/25\n",
      "36/36 [==============================] - 7s 201ms/step - loss: 0.9431 - accuracy: 0.7102 - val_loss: 0.9309 - val_accuracy: 0.6818\n",
      "Epoch 6/25\n",
      "36/36 [==============================] - 7s 188ms/step - loss: 0.8692 - accuracy: 0.7263 - val_loss: 0.9622 - val_accuracy: 0.6818\n",
      "Epoch 7/25\n",
      "36/36 [==============================] - 7s 186ms/step - loss: 0.8569 - accuracy: 0.7291 - val_loss: 0.8748 - val_accuracy: 0.6818\n",
      "Epoch 8/25\n",
      "36/36 [==============================] - 7s 190ms/step - loss: 0.8067 - accuracy: 0.7343 - val_loss: 0.8246 - val_accuracy: 0.7273\n",
      "Epoch 9/25\n",
      "36/36 [==============================] - 7s 188ms/step - loss: 0.7484 - accuracy: 0.7642 - val_loss: 0.8650 - val_accuracy: 0.6818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/25\n",
      "36/36 [==============================] - 7s 190ms/step - loss: 0.7427 - accuracy: 0.7628 - val_loss: 0.8484 - val_accuracy: 0.6364\n",
      "Epoch 11/25\n",
      "36/36 [==============================] - 7s 188ms/step - loss: 0.7285 - accuracy: 0.7761 - val_loss: 0.8192 - val_accuracy: 0.6364\n",
      "Epoch 12/25\n",
      "36/36 [==============================] - 7s 191ms/step - loss: 0.6915 - accuracy: 0.7880 - val_loss: 0.7066 - val_accuracy: 0.7273\n",
      "Epoch 13/25\n",
      "36/36 [==============================] - 7s 189ms/step - loss: 0.6683 - accuracy: 0.7998 - val_loss: 0.7539 - val_accuracy: 0.7273\n",
      "Epoch 14/25\n",
      "36/36 [==============================] - 7s 188ms/step - loss: 0.6488 - accuracy: 0.8126 - val_loss: 0.7577 - val_accuracy: 0.6364\n",
      "Epoch 15/25\n",
      "36/36 [==============================] - 7s 182ms/step - loss: 0.6438 - accuracy: 0.8107 - val_loss: 0.7565 - val_accuracy: 0.6364\n",
      "Epoch 16/25\n",
      "36/36 [==============================] - 6s 164ms/step - loss: 0.6435 - accuracy: 0.8079 - val_loss: 0.6804 - val_accuracy: 0.7727\n",
      "Epoch 17/25\n",
      "36/36 [==============================] - 6s 173ms/step - loss: 0.6073 - accuracy: 0.8316 - val_loss: 0.6925 - val_accuracy: 0.6818\n",
      "Epoch 18/25\n",
      "36/36 [==============================] - 6s 159ms/step - loss: 0.5651 - accuracy: 0.8430 - val_loss: 0.7587 - val_accuracy: 0.7273\n",
      "Epoch 19/25\n",
      "36/36 [==============================] - 6s 162ms/step - loss: 0.5860 - accuracy: 0.8330 - val_loss: 0.6531 - val_accuracy: 0.6818\n",
      "Epoch 20/25\n",
      "36/36 [==============================] - 6s 162ms/step - loss: 0.5502 - accuracy: 0.8439 - val_loss: 0.7377 - val_accuracy: 0.7273\n",
      "Epoch 21/25\n",
      "36/36 [==============================] - 6s 158ms/step - loss: 0.5117 - accuracy: 0.8657 - val_loss: 0.7225 - val_accuracy: 0.7727\n",
      "Epoch 22/25\n",
      "36/36 [==============================] - 6s 172ms/step - loss: 0.5019 - accuracy: 0.8686 - val_loss: 0.7008 - val_accuracy: 0.7727\n",
      "Epoch 23/25\n",
      "36/36 [==============================] - 6s 169ms/step - loss: 0.4936 - accuracy: 0.8771 - val_loss: 0.7792 - val_accuracy: 0.6818\n",
      "Epoch 24/25\n",
      "36/36 [==============================] - 6s 161ms/step - loss: 0.5017 - accuracy: 0.8667 - val_loss: 0.7058 - val_accuracy: 0.7273\n",
      "Epoch 25/25\n",
      "36/36 [==============================] - 6s 169ms/step - loss: 0.4929 - accuracy: 0.8672 - val_loss: 0.7434 - val_accuracy: 0.7273\n",
      "Score for fold 5: loss of 1.0425987243652344; accuracy of 72.03947305679321%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 6 ...\n",
      "Epoch 1/25\n",
      "36/36 [==============================] - 6s 148ms/step - loss: 2.6271 - accuracy: 0.4454 - val_loss: 1.8801 - val_accuracy: 0.5909\n",
      "Epoch 2/25\n",
      "36/36 [==============================] - 6s 156ms/step - loss: 1.6574 - accuracy: 0.6082 - val_loss: 1.3837 - val_accuracy: 0.5909\n",
      "Epoch 3/25\n",
      "36/36 [==============================] - 5s 149ms/step - loss: 1.2906 - accuracy: 0.6589 - val_loss: 1.1205 - val_accuracy: 0.7273\n",
      "Epoch 4/25\n",
      "36/36 [==============================] - 6s 156ms/step - loss: 1.1086 - accuracy: 0.6812 - val_loss: 1.0437 - val_accuracy: 0.6818\n",
      "Epoch 5/25\n",
      "36/36 [==============================] - 6s 157ms/step - loss: 0.9487 - accuracy: 0.7249 - val_loss: 0.8847 - val_accuracy: 0.7727\n",
      "Epoch 6/25\n",
      "36/36 [==============================] - 6s 172ms/step - loss: 0.8612 - accuracy: 0.7343 - val_loss: 0.9031 - val_accuracy: 0.7273\n",
      "Epoch 7/25\n",
      "36/36 [==============================] - 6s 160ms/step - loss: 0.8543 - accuracy: 0.7391 - val_loss: 0.7970 - val_accuracy: 0.7727\n",
      "Epoch 8/25\n",
      "36/36 [==============================] - 6s 152ms/step - loss: 0.7867 - accuracy: 0.7543 - val_loss: 0.7066 - val_accuracy: 0.7727\n",
      "Epoch 9/25\n",
      "36/36 [==============================] - 6s 157ms/step - loss: 0.7282 - accuracy: 0.7747 - val_loss: 0.7707 - val_accuracy: 0.7727\n",
      "Epoch 10/25\n",
      "36/36 [==============================] - 6s 162ms/step - loss: 0.6869 - accuracy: 0.7932 - val_loss: 0.7193 - val_accuracy: 0.6364\n",
      "Epoch 11/25\n",
      "36/36 [==============================] - 6s 174ms/step - loss: 0.6804 - accuracy: 0.7903 - val_loss: 0.6674 - val_accuracy: 0.7727\n",
      "Epoch 12/25\n",
      "36/36 [==============================] - 6s 180ms/step - loss: 0.6461 - accuracy: 0.8069 - val_loss: 0.7392 - val_accuracy: 0.6818\n",
      "Epoch 13/25\n",
      "36/36 [==============================] - 7s 183ms/step - loss: 0.6147 - accuracy: 0.8212 - val_loss: 0.7316 - val_accuracy: 0.7727\n",
      "Epoch 14/25\n",
      "36/36 [==============================] - 7s 183ms/step - loss: 0.6349 - accuracy: 0.8107 - val_loss: 0.6518 - val_accuracy: 0.8182\n",
      "Epoch 15/25\n",
      "36/36 [==============================] - 7s 182ms/step - loss: 0.6255 - accuracy: 0.8022 - val_loss: 0.6859 - val_accuracy: 0.8182\n",
      "Epoch 16/25\n",
      "36/36 [==============================] - 7s 192ms/step - loss: 0.5614 - accuracy: 0.8363 - val_loss: 0.8583 - val_accuracy: 0.6818\n",
      "Epoch 17/25\n",
      "36/36 [==============================] - 7s 185ms/step - loss: 0.5890 - accuracy: 0.8188 - val_loss: 0.8381 - val_accuracy: 0.7727\n",
      "Epoch 18/25\n",
      "36/36 [==============================] - 6s 169ms/step - loss: 0.5621 - accuracy: 0.8378 - val_loss: 0.7204 - val_accuracy: 0.8182\n",
      "Epoch 19/25\n",
      "36/36 [==============================] - 6s 169ms/step - loss: 0.5051 - accuracy: 0.8620 - val_loss: 0.7965 - val_accuracy: 0.6818\n",
      "Epoch 20/25\n",
      "36/36 [==============================] - 7s 181ms/step - loss: 0.4933 - accuracy: 0.8667 - val_loss: 0.8215 - val_accuracy: 0.7273\n",
      "Epoch 21/25\n",
      "36/36 [==============================] - 6s 166ms/step - loss: 0.4725 - accuracy: 0.8790 - val_loss: 0.9897 - val_accuracy: 0.7273\n",
      "Epoch 22/25\n",
      "36/36 [==============================] - 6s 162ms/step - loss: 0.4509 - accuracy: 0.8871 - val_loss: 0.9159 - val_accuracy: 0.7273\n",
      "Epoch 23/25\n",
      "36/36 [==============================] - 6s 169ms/step - loss: 0.4179 - accuracy: 0.9037 - val_loss: 0.9284 - val_accuracy: 0.7273\n",
      "Epoch 24/25\n",
      "36/36 [==============================] - 6s 169ms/step - loss: 0.4340 - accuracy: 0.8928 - val_loss: 1.1923 - val_accuracy: 0.7273\n",
      "Epoch 25/25\n",
      "36/36 [==============================] - 6s 158ms/step - loss: 0.4302 - accuracy: 0.8971 - val_loss: 0.8882 - val_accuracy: 0.7273\n",
      "Score for fold 6: loss of 1.224822998046875; accuracy of 66.11841917037964%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 7 ...\n",
      "Epoch 1/25\n",
      "36/36 [==============================] - 6s 147ms/step - loss: 2.5313 - accuracy: 0.4208 - val_loss: 1.7969 - val_accuracy: 0.3636\n",
      "Epoch 2/25\n",
      "36/36 [==============================] - 6s 176ms/step - loss: 1.4645 - accuracy: 0.6267 - val_loss: 1.2270 - val_accuracy: 0.7273\n",
      "Epoch 3/25\n",
      "36/36 [==============================] - 6s 167ms/step - loss: 1.1349 - accuracy: 0.6803 - val_loss: 1.1582 - val_accuracy: 0.6818\n",
      "Epoch 4/25\n",
      "36/36 [==============================] - 6s 177ms/step - loss: 0.9994 - accuracy: 0.6992 - val_loss: 0.9530 - val_accuracy: 0.6818\n",
      "Epoch 5/25\n",
      "36/36 [==============================] - 6s 173ms/step - loss: 0.9076 - accuracy: 0.7158 - val_loss: 1.1628 - val_accuracy: 0.5909\n",
      "Epoch 6/25\n",
      "36/36 [==============================] - 6s 175ms/step - loss: 0.9018 - accuracy: 0.6983 - val_loss: 0.8553 - val_accuracy: 0.6818\n",
      "Epoch 7/25\n",
      "36/36 [==============================] - 6s 165ms/step - loss: 0.8087 - accuracy: 0.7424 - val_loss: 0.7839 - val_accuracy: 0.6818\n",
      "Epoch 8/25\n",
      "36/36 [==============================] - 6s 169ms/step - loss: 0.7492 - accuracy: 0.7747 - val_loss: 0.8922 - val_accuracy: 0.6818\n",
      "Epoch 9/25\n",
      "36/36 [==============================] - 6s 165ms/step - loss: 0.7779 - accuracy: 0.7524 - val_loss: 0.7219 - val_accuracy: 0.7727\n",
      "Epoch 10/25\n",
      "36/36 [==============================] - 6s 168ms/step - loss: 0.7273 - accuracy: 0.7694 - val_loss: 0.7393 - val_accuracy: 0.7273\n",
      "Epoch 11/25\n",
      "36/36 [==============================] - 6s 166ms/step - loss: 0.6771 - accuracy: 0.7894 - val_loss: 0.7642 - val_accuracy: 0.7273\n",
      "Epoch 12/25\n",
      "36/36 [==============================] - 6s 168ms/step - loss: 0.6847 - accuracy: 0.7965 - val_loss: 0.6893 - val_accuracy: 0.6818\n",
      "Epoch 13/25\n",
      "36/36 [==============================] - 6s 165ms/step - loss: 0.6412 - accuracy: 0.8083 - val_loss: 0.7574 - val_accuracy: 0.7273\n",
      "Epoch 14/25\n",
      "36/36 [==============================] - 6s 164ms/step - loss: 0.6170 - accuracy: 0.8155 - val_loss: 0.7356 - val_accuracy: 0.7273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/25\n",
      "36/36 [==============================] - 6s 172ms/step - loss: 0.6000 - accuracy: 0.8231 - val_loss: 0.8011 - val_accuracy: 0.7273\n",
      "Epoch 16/25\n",
      "36/36 [==============================] - 6s 172ms/step - loss: 0.5756 - accuracy: 0.8430 - val_loss: 0.7840 - val_accuracy: 0.8182\n",
      "Epoch 17/25\n",
      "36/36 [==============================] - 6s 173ms/step - loss: 0.5827 - accuracy: 0.8321 - val_loss: 0.7153 - val_accuracy: 0.7727\n",
      "Epoch 18/25\n",
      "36/36 [==============================] - 6s 178ms/step - loss: 0.5362 - accuracy: 0.8463 - val_loss: 0.7141 - val_accuracy: 0.8182\n",
      "Epoch 19/25\n",
      "36/36 [==============================] - 6s 170ms/step - loss: 0.5328 - accuracy: 0.8572 - val_loss: 0.7670 - val_accuracy: 0.6818\n",
      "Epoch 20/25\n",
      "36/36 [==============================] - 7s 190ms/step - loss: 0.5134 - accuracy: 0.8648 - val_loss: 0.8662 - val_accuracy: 0.6818\n",
      "Epoch 21/25\n",
      "36/36 [==============================] - 7s 187ms/step - loss: 0.5015 - accuracy: 0.8639 - val_loss: 0.6726 - val_accuracy: 0.7273\n",
      "Epoch 22/25\n",
      "36/36 [==============================] - 7s 189ms/step - loss: 0.4455 - accuracy: 0.8857 - val_loss: 0.8258 - val_accuracy: 0.7727\n",
      "Epoch 23/25\n",
      "36/36 [==============================] - 7s 187ms/step - loss: 0.4782 - accuracy: 0.8752 - val_loss: 0.7099 - val_accuracy: 0.7273\n",
      "Epoch 24/25\n",
      "36/36 [==============================] - 7s 186ms/step - loss: 0.4463 - accuracy: 0.8937 - val_loss: 0.8081 - val_accuracy: 0.7727\n",
      "Epoch 25/25\n",
      "36/36 [==============================] - 6s 175ms/step - loss: 0.4336 - accuracy: 0.9023 - val_loss: 0.7643 - val_accuracy: 0.7727\n",
      "Score for fold 7: loss of 1.1071686744689941; accuracy of 71.38158082962036%\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 8 ...\n",
      "Epoch 1/25\n",
      "36/36 [==============================] - 8s 206ms/step - loss: 2.5398 - accuracy: 0.4497 - val_loss: 1.8558 - val_accuracy: 0.5909\n",
      "Epoch 2/25\n",
      "36/36 [==============================] - 7s 201ms/step - loss: 1.5332 - accuracy: 0.5726 - val_loss: 1.2754 - val_accuracy: 0.6364\n",
      "Epoch 3/25\n",
      "36/36 [==============================] - 6s 172ms/step - loss: 1.1648 - accuracy: 0.6603 - val_loss: 1.0963 - val_accuracy: 0.7727\n",
      "Epoch 4/25\n",
      "36/36 [==============================] - 6s 169ms/step - loss: 1.0283 - accuracy: 0.6826 - val_loss: 0.9500 - val_accuracy: 0.8182\n",
      "Epoch 5/25\n",
      "36/36 [==============================] - 6s 163ms/step - loss: 0.9370 - accuracy: 0.7016 - val_loss: 0.9771 - val_accuracy: 0.7273\n",
      "Epoch 6/25\n",
      "36/36 [==============================] - 6s 163ms/step - loss: 0.8597 - accuracy: 0.7268 - val_loss: 0.8346 - val_accuracy: 0.7727\n",
      "Epoch 7/25\n",
      "36/36 [==============================] - 6s 166ms/step - loss: 0.8082 - accuracy: 0.7282 - val_loss: 0.8053 - val_accuracy: 0.7727\n",
      "Epoch 8/25\n",
      "36/36 [==============================] - 6s 158ms/step - loss: 0.7961 - accuracy: 0.7320 - val_loss: 0.7659 - val_accuracy: 0.6818\n",
      "Epoch 9/25\n",
      "36/36 [==============================] - 6s 162ms/step - loss: 0.7438 - accuracy: 0.7538 - val_loss: 0.7206 - val_accuracy: 0.7273\n",
      "Epoch 10/25\n",
      "36/36 [==============================] - 6s 171ms/step - loss: 0.7191 - accuracy: 0.7619 - val_loss: 0.7056 - val_accuracy: 0.7727\n",
      "Epoch 11/25\n",
      "36/36 [==============================] - 6s 162ms/step - loss: 0.7063 - accuracy: 0.7804 - val_loss: 0.7078 - val_accuracy: 0.6818\n",
      "Epoch 12/25\n",
      "36/36 [==============================] - 6s 164ms/step - loss: 0.6776 - accuracy: 0.7823 - val_loss: 0.6988 - val_accuracy: 0.7273\n",
      "Epoch 13/25\n",
      "36/36 [==============================] - 6s 161ms/step - loss: 0.6930 - accuracy: 0.7657 - val_loss: 0.7430 - val_accuracy: 0.7273\n",
      "Epoch 14/25\n",
      "36/36 [==============================] - 6s 165ms/step - loss: 0.6544 - accuracy: 0.7941 - val_loss: 0.6625 - val_accuracy: 0.7727\n",
      "Epoch 15/25\n",
      "36/36 [==============================] - 6s 171ms/step - loss: 0.6254 - accuracy: 0.8012 - val_loss: 0.6749 - val_accuracy: 0.7727\n",
      "Epoch 16/25\n",
      "36/36 [==============================] - 6s 172ms/step - loss: 0.6151 - accuracy: 0.8093 - val_loss: 0.6336 - val_accuracy: 0.7727\n",
      "Epoch 17/25\n",
      "36/36 [==============================] - 6s 167ms/step - loss: 0.6209 - accuracy: 0.8060 - val_loss: 0.7125 - val_accuracy: 0.7727\n",
      "Epoch 18/25\n",
      "36/36 [==============================] - 6s 170ms/step - loss: 0.5835 - accuracy: 0.8169 - val_loss: 0.6577 - val_accuracy: 0.8182\n",
      "Epoch 19/25\n",
      "36/36 [==============================] - 6s 169ms/step - loss: 0.5821 - accuracy: 0.8235 - val_loss: 0.7837 - val_accuracy: 0.7727\n",
      "Epoch 20/25\n",
      "36/36 [==============================] - 6s 171ms/step - loss: 0.5731 - accuracy: 0.8226 - val_loss: 0.7248 - val_accuracy: 0.8182\n",
      "Epoch 21/25\n",
      "36/36 [==============================] - 6s 161ms/step - loss: 0.5522 - accuracy: 0.8359 - val_loss: 0.8529 - val_accuracy: 0.6818\n",
      "Epoch 22/25\n",
      "36/36 [==============================] - 6s 165ms/step - loss: 0.6040 - accuracy: 0.8136 - val_loss: 0.7827 - val_accuracy: 0.7273\n",
      "Epoch 23/25\n",
      "36/36 [==============================] - 6s 171ms/step - loss: 0.5230 - accuracy: 0.8496 - val_loss: 0.8159 - val_accuracy: 0.7273\n",
      "Epoch 24/25\n",
      "36/36 [==============================] - 6s 163ms/step - loss: 0.4975 - accuracy: 0.8629 - val_loss: 0.7322 - val_accuracy: 0.8182\n",
      "Epoch 25/25\n",
      "36/36 [==============================] - 6s 172ms/step - loss: 0.4937 - accuracy: 0.8710 - val_loss: 0.8002 - val_accuracy: 0.7727\n",
      "Score for fold 8: loss of 0.9553148150444031; accuracy of 73.3552634716034%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fold_no = 1\n",
    "acc_per_fold_new = []\n",
    "loss_per_fold_new = []\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "    model = Sequential()\n",
    "\n",
    "        \n",
    "    model.add(Conv2D(128,\n",
    "                     kernel_size = (3, 3),\n",
    "                     kernel_regularizer=regularizers.L1(0.001),\n",
    "                     bias_regularizer=regularizers.L2(0.0001),\n",
    "                    # activity_regularizer=regularizers.L2(1e-5)\n",
    "                    )\n",
    "             )\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "\n",
    "    model.add(Conv2D(64,\n",
    "                     kernel_size = (3, 3),\n",
    "                     kernel_regularizer=regularizers.L1(0.001),\n",
    "                     bias_regularizer=regularizers.L2(0.0001),\n",
    "                    #activity_regularizer=regularizers.L2(1e-5)\n",
    "                    )\n",
    "             )\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer = 'adam', metrics = ['accuracy'])\n",
    "    \n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    history = model.fit(inputs[train],targets[train],epochs = 25,batch_size = 60, validation_split = 0.01)\n",
    "    scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold_new.append(scores[1] * 100)\n",
    "    loss_per_fold_new.append(scores[0])\n",
    "    fold_no = fold_no + 1\n",
    "\n",
    "# show plot\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "c93b0ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "comp = [acc_per_fold1,acc_per_fold_new]\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    " \n",
    "# Creating plot\n",
    "plt.boxplot(comp)\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('comparison_Boxplot.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e2143b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(acc_per_fold_new)\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('final_model_box.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "1b414491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "37/37 [==============================] - 8s 209ms/step - loss: 2.5395 - accuracy: 0.4700 - val_loss: 1.7973 - val_accuracy: 0.6364\n",
      "Epoch 2/25\n",
      "37/37 [==============================] - 8s 210ms/step - loss: 1.4897 - accuracy: 0.5982 - val_loss: 1.3204 - val_accuracy: 0.5909\n",
      "Epoch 3/25\n",
      "37/37 [==============================] - 7s 184ms/step - loss: 1.1566 - accuracy: 0.6522 - val_loss: 1.0022 - val_accuracy: 0.6818\n",
      "Epoch 4/25\n",
      "37/37 [==============================] - 7s 192ms/step - loss: 0.9767 - accuracy: 0.6933 - val_loss: 1.0321 - val_accuracy: 0.6364\n",
      "Epoch 5/25\n",
      "37/37 [==============================] - 7s 183ms/step - loss: 0.9037 - accuracy: 0.6854 - val_loss: 0.8673 - val_accuracy: 0.6364\n",
      "Epoch 6/25\n",
      "37/37 [==============================] - 7s 180ms/step - loss: 0.8644 - accuracy: 0.7131 - val_loss: 0.9174 - val_accuracy: 0.6818\n",
      "Epoch 7/25\n",
      "37/37 [==============================] - 7s 183ms/step - loss: 0.8167 - accuracy: 0.7283 - val_loss: 0.9335 - val_accuracy: 0.5455\n",
      "Epoch 8/25\n",
      "37/37 [==============================] - 7s 182ms/step - loss: 0.7809 - accuracy: 0.7325 - val_loss: 0.8658 - val_accuracy: 0.6818\n",
      "Epoch 9/25\n",
      "37/37 [==============================] - 7s 186ms/step - loss: 0.7247 - accuracy: 0.7685 - val_loss: 0.9082 - val_accuracy: 0.6364\n",
      "Epoch 10/25\n",
      "37/37 [==============================] - 6s 169ms/step - loss: 0.7241 - accuracy: 0.7625 - val_loss: 0.8708 - val_accuracy: 0.6364\n",
      "Epoch 11/25\n",
      "37/37 [==============================] - 6s 169ms/step - loss: 0.6983 - accuracy: 0.7698 - val_loss: 0.9042 - val_accuracy: 0.5909\n",
      "Epoch 12/25\n",
      "37/37 [==============================] - 6s 163ms/step - loss: 0.6799 - accuracy: 0.7777 - val_loss: 0.9667 - val_accuracy: 0.6364\n",
      "Epoch 13/25\n",
      "37/37 [==============================] - 6s 165ms/step - loss: 0.6597 - accuracy: 0.7883 - val_loss: 1.1290 - val_accuracy: 0.6818\n",
      "Epoch 14/25\n",
      "37/37 [==============================] - 6s 170ms/step - loss: 0.6394 - accuracy: 0.7920 - val_loss: 1.0144 - val_accuracy: 0.6364\n",
      "Epoch 15/25\n",
      "37/37 [==============================] - 6s 168ms/step - loss: 0.6297 - accuracy: 0.8063 - val_loss: 0.9914 - val_accuracy: 0.6364\n",
      "Epoch 16/25\n",
      "37/37 [==============================] - 6s 173ms/step - loss: 0.6296 - accuracy: 0.7984 - val_loss: 0.9841 - val_accuracy: 0.6364\n",
      "Epoch 17/25\n",
      "37/37 [==============================] - 6s 162ms/step - loss: 0.5994 - accuracy: 0.8123 - val_loss: 0.9699 - val_accuracy: 0.6364\n",
      "Epoch 18/25\n",
      "37/37 [==============================] - 6s 161ms/step - loss: 0.5841 - accuracy: 0.8229 - val_loss: 1.1058 - val_accuracy: 0.5455\n",
      "Epoch 19/25\n",
      "37/37 [==============================] - 6s 166ms/step - loss: 0.5800 - accuracy: 0.8252 - val_loss: 1.1180 - val_accuracy: 0.5000\n",
      "Epoch 20/25\n",
      "37/37 [==============================] - 6s 156ms/step - loss: 0.5663 - accuracy: 0.8321 - val_loss: 1.0972 - val_accuracy: 0.5455\n",
      "Epoch 21/25\n",
      "37/37 [==============================] - 6s 163ms/step - loss: 0.5727 - accuracy: 0.8215 - val_loss: 1.1065 - val_accuracy: 0.5909\n",
      "Epoch 22/25\n",
      "37/37 [==============================] - 6s 166ms/step - loss: 0.5328 - accuracy: 0.8492 - val_loss: 1.4343 - val_accuracy: 0.5455\n",
      "Epoch 23/25\n",
      "37/37 [==============================] - 6s 163ms/step - loss: 0.5559 - accuracy: 0.8344 - val_loss: 1.3714 - val_accuracy: 0.5909\n",
      "Epoch 24/25\n",
      "37/37 [==============================] - 6s 167ms/step - loss: 0.5347 - accuracy: 0.8413 - val_loss: 1.2810 - val_accuracy: 0.5455\n",
      "Epoch 25/25\n",
      "37/37 [==============================] - 6s 167ms/step - loss: 0.4858 - accuracy: 0.8621 - val_loss: 1.4248 - val_accuracy: 0.5455\n"
     ]
    }
   ],
   "source": [
    "final_model = Sequential()\n",
    "\n",
    "        \n",
    "final_model.add(Conv2D(128,\n",
    "                 kernel_size = (3, 3),\n",
    "                 kernel_regularizer=regularizers.L1(0.001),\n",
    "                 bias_regularizer=regularizers.L2(0.0001),\n",
    "                # activity_regularizer=regularizers.L2(1e-5)\n",
    "                )\n",
    "         )\n",
    "final_model.add(Activation(\"relu\"))\n",
    "final_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "\n",
    "final_model.add(Conv2D(64,\n",
    "                 kernel_size = (3, 3),\n",
    "                 kernel_regularizer=regularizers.L1(0.001),\n",
    "                 bias_regularizer=regularizers.L2(0.0001),\n",
    "                #activity_regularizer=regularizers.L2(1e-5)\n",
    "                )\n",
    "         )\n",
    "final_model.add(Activation(\"relu\"))\n",
    "final_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "\n",
    "final_model.add(Flatten())\n",
    "final_model.add(Dense(64))\n",
    "\n",
    "final_model.add(Dense(3))\n",
    "final_model.add(Activation('sigmoid'))\n",
    "\n",
    "final_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer = 'adam', metrics = ['accuracy'])\n",
    "history = final_model.fit(X_train,y_train,epochs = 25,batch_size = 60, validation_split = 0.01)\n",
    "final_result = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "bc99c1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 30ms/step - loss: 0.4847 - accuracy: 0.8689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.48474380373954773, 0.868852436542511]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "68cbc462",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'acc_per_fold_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [76]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m Ovar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvar(acc_per_fold1)\n\u001b[0;32m      3\u001b[0m Ostd \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstd(acc_per_fold1)\n\u001b[1;32m----> 5\u001b[0m ave \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(\u001b[43macc_per_fold_new\u001b[49m)\n\u001b[0;32m      6\u001b[0m var \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvar(acc_per_fold_new)\n\u001b[0;32m      7\u001b[0m std \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstd(acc_per_fold_new)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'acc_per_fold_new' is not defined"
     ]
    }
   ],
   "source": [
    "Oave = np.average(acc_per_fold1)\n",
    "Ovar = np.var(acc_per_fold1)\n",
    "Ostd = np.std(acc_per_fold1)\n",
    "\n",
    "ave = np.average(acc_per_fold_new)\n",
    "var = np.var(acc_per_fold_new)\n",
    "std = np.std(acc_per_fold_new)\n",
    "\n",
    "\n",
    "print(\"***************************************************\")\n",
    "print(\"***************************************************\")\n",
    "print(\"**                                               **\")\n",
    "print(\"**   Old Average Accuracy:   \",Oave,\"%**\")\n",
    "print(\"**   Old Accuracy Variance:  \", Ovar,\" **\")\n",
    "print(\"**   Old Standard Deviation: \", Ostd,\"**\")\n",
    "print(\"**                                               **\")\n",
    "print(\"***************************************************\")\n",
    "print(\"***************************************************\")\n",
    "print(\"\\n\")\n",
    "ave = np.average(acc_per_fold_new)\n",
    "var = np.var(acc_per_fold_new)\n",
    "std = np.std(acc_per_fold_new)\n",
    "print(\"**************************************************\")\n",
    "print(\"**************************************************\")\n",
    "print(\"**                                              **\")\n",
    "print(\"**   Average Accuracy:   \",ave,\"%   **\")\n",
    "print(\"**   Accuracy Variance:  \", var,\"    **\")\n",
    "print(\"**   Standard Deviation: \", std,\"   **\")\n",
    "print(\"**                                              **\")\n",
    "print(\"**************************************************\")\n",
    "print(\"**************************************************\")\n",
    "print(\"\\n\")\n",
    "print(\"Final Model Summary: \\n\")\n",
    "print(final_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bca0dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb9c366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
